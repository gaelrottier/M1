<?xml version="1.0" encoding="UTF-8"?>
<raweb xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="en" year="2006"><identification id="algorille" isproject="false"><shortname>AlGorille</shortname><projectName>Algorithms for the Grid</projectName><theme>NUM</theme><team id="uid1"><participants category="Team_Leader"><person><firstname>Jens</firstname><lastname>Gustedt</lastname><affiliation>INRIA</affiliation><categoryPro>Chercheur</categoryPro><moreinfo>research director, <span class="smallcap" align="left">INRIA</span></moreinfo><hdr>oui</hdr></person></participants><participants category="Administrative_Assistant"><person><firstname>Josiane</firstname><lastname>Reffort</lastname><affiliation>UnivFr</affiliation><categoryPro>Assistant</categoryPro><moreinfo>UHP</moreinfo></person></participants><participants category="Staff_Members"><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation>INRIA</affiliation><categoryPro>Chercheur</categoryPro><moreinfo>[Temporary assignment as Chargé de Recherche, INRIA, between
01/01/06 and 31/08/06. Chargé de Recherche, INRIA, since 01/09/05</moreinfo></person><person><firstname>Martin</firstname><lastname>Quinson</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>Maître de Conférences, UHP/ESIAL</moreinfo></person><person><firstname>Frédéric</firstname><lastname>Suter</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>Maître de Conférences, UHP</moreinfo></person></participants><participants category="External_Collaborator"><person><firstname>Stéphane</firstname><lastname>Vialle</lastname><affiliation>EtablissementPrive</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>professor,
Supélec Metz Campus</moreinfo><hdr>oui</hdr></person></participants><participants category="Engineer"><person><firstname>Xavier</firstname><lastname>Delaruelle</lastname><affiliation>INRIA</affiliation><categoryPro>Technique</categoryPro><moreinfo>Ingénieur associé, INRIA</moreinfo></person><person><firstname>Abdelmalek</firstname><lastname>Cherier</lastname><affiliation>INRIA</affiliation><categoryPro>Technique</categoryPro><moreinfo>Ingénieur associé, INRIA, since 01/10/06</moreinfo></person></participants><participants category="Teaching_Assistant"><person><firstname>Luiz Angelo</firstname><lastname>Steffenel</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>Nancy 2</moreinfo></person><person><firstname>Pierre-François</firstname><lastname>Dutot</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>UHP/ESIAL, until 31/08/06</moreinfo></person><person><firstname>Flavien</firstname><lastname>Vernier</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>UHP, until 31/08/06</moreinfo></person></participants><participants category="Ph._D._Students"><person><firstname>Tchimou</firstname><lastname>N'Takpé</lastname><affiliation>UnivFr</affiliation><categoryPro>PhD</categoryPro><moreinfo>joint regional/Ivorian goverment grant
since 01/10/05</moreinfo></person><person><firstname>Pierre-Nicolas</firstname><lastname>Clauss</lastname><affiliation>UnivFr</affiliation><categoryPro>PhD</categoryPro><moreinfo>Allocataire de recherche
MENESR since 01/10/06</moreinfo></person></participants><participants category="Student_Intern"><person><firstname>Pierre-Nicolas</firstname><lastname>Clauss</lastname><affiliation>UnivFr</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>M2R student between 01/02/2006 and 01/08/2006</moreinfo></person><person><firstname>Ahmed</firstname><lastname>Harbaoui</lastname><affiliation>UnivFr</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>M2R student between 01/02/2006 and 01/08/2006</moreinfo></person><person><firstname>Christophe</firstname><lastname>Thiery</lastname><affiliation>UnivFr</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>Internship between 12/06/2006 and 18/08/2006</moreinfo></person></participants><moreinfo><p>AlGorille is a team at the
<ref xlink:href="http://www.loria.fr/index.php?lg=en" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="819355650031"><i>Laboratoire lorrain de recherche en
informatique et ses
applications</i></ref> (<span class="smallcap" align="left">LORIA</span>)
in common with <ref xlink:href="http://www.cnrs.fr/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3020567311008"><i>Centre National de
Recherche Scientifique</i></ref> (CNRS),
<ref xlink:href="http://www.inria.fr/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="4089937493020"><i>Institut National de Recherche en
Informatique et Automatique</i></ref> (<span class="smallcap" align="left">INRIA</span>),
<ref xlink:href="http://www.uhp-nancy.fr/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2229444849015"><i>Université Henri Poincaré
Nancy 1</i></ref> (UHP),
<ref xlink:href="http://www.univ-nancy2.fr/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1513198163016"><i>Université
Nancy 2</i></ref> and
<ref xlink:href="http://www.inpl-nancy.fr/interntl.htm" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2289768725004"><i>Institut National Polytechnique de
Lorraine</i></ref> (INPL).</p></moreinfo></team><UR name="Lorraine"/></identification><topic id="t_1">Structuring of applications for scalability</topic><topic id="t_2">Transparent resource management</topic><topic id="t_3">Experimental validation</topic><presentation id="uid3"><bodyTitle>Overall Objectives</bodyTitle><subsection id="uid4"><bodyTitle>Overall Objectives</bodyTitle><keyword>algorithms</keyword><keyword>Grid computing</keyword><keyword>experiments</keyword><keyword>data distribution</keyword><keyword>data
redistribution</keyword><keyword>parallel and distributed computing</keyword><keyword>scheduling</keyword><p>The possible access to distributed computing resources over the
Internet allows a new type of applications that use the power of
the machines and the network. The transparent and efficient access
to these distributed resources that form <i>the Grid</i> is one of
the major challenges of information technology. It needs the
implementation of specific techniques and algorithms to make
computers communicate with each other, let applications work
together, allocate resources and improve the quality of service and
the security of the transactions.</p><descriptionlist><label>Challenge:</label><li id="uid5"><p>We tackle several problems related to the first of
the major challenges that INRIA has identified in its strategic
plan:</p><p rend="quoted">Design and master the future network infrastructures and
communication services platforms.</p></li><label>Originality:</label><li id="uid6"><p>Our approach emphasizes on <i>algorithmic
aspects</i> of grid computing, in particular it addresses the
problems of organizing the computation <i>efficiently</i>, be it
on the side of a service provider, be it within the application
program of a customer.</p></li><label>Research themes:</label><li id="uid7"><p/><simplelist><li id="uid8"><p>Structuring of applications for scalability: modeling of
size, locality and granularity of computation and data.</p></li><li id="uid9"><p>Transparent resource management: sequential and parallel
task scheduling; migration of computations; data exchange;
distribution and redistribution of data.</p></li><li id="uid10"><p>Experimental validation: reproducibility, extendability
and applicability of simulations, emulations and <i>in
situ</i> experiments.</p></li></simplelist></li><label>Methods:</label><li id="uid11"><p>Our methodology is based upon three points (1)
modeling, (2) design and (3) engineering of algorithms. These
three points interact strongly to form a feedback loop.</p><orderedlist><li id="uid12"><p>With models we obtain an abstraction of the physical,
technical or social reality.</p></li><li id="uid13"><p>This abstraction allows us to design techniques for the
resolution of specific problems.</p></li><li id="uid14"><p>These techniques are implemented to validate the models
with experiments and by applying them to real world problems.</p></li></orderedlist></li></descriptionlist></subsection></presentation><fondements id="uid15"><bodyTitle>Scientific Foundations</bodyTitle><subsection id="uid16" topic="t_1"><bodyTitle>Structuring of Applications for Scalability</bodyTitle><participants category="None"><person><firstname>Jens</firstname><lastname>Gustedt</lastname><affiliation/><categoryPro/></person><person><firstname>Frédéric</firstname><lastname>Suter</lastname><affiliation/><categoryPro/></person><person><firstname>Stéphane</firstname><lastname>Vialle</lastname><affiliation/><categoryPro/></person></participants><keyword>models for parallel and distributed computing</keyword><keyword>performance
evaluation</keyword><keyword>message passing</keyword><keyword>shared memory</keyword><moreinfo><p>Our approach is based on a ``<i>good</i>'' separation of the different
problem levels that we encounter with Grid problems.
Simultaneously this has to ensure a good data locality (a
computation will use data that are ``<i>close</i>'') and a good
granularity (the computation is divided into non preemptive tasks
of reasonable size). For problems for which there is no natural
data parallelism or control parallelism such a division (into data
and tasks) is indispensable when tackling the issues related to
spatial and temporal distances as we encounter them in the Grid.</p></moreinfo><p>Several parallel models offering simplified frameworks that ease the
design and the implementation of algorithms have been proposed.
The best known of these provide a modeling that is called ``<i>fined
grained</i>'', <i>i.e., </i>at the instruction level. Their lack of realism
with respect to the existing parallel architectures and their
inability to predict the behavior of implementations, has triggered
the development of new models that allow a switch to a <i>coarse
grained</i> paradigm. In the framework of parallel and distributed
(but homogeneous) computing they started with the fundamental work
of Valiant <ref xlink:href="#bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>. Their common characteristics are:</p><simplelist><li id="uid17"><p>to maximally exploit the data that is located on a particular
node by a local computation,</p></li><li id="uid18"><p>to collect all requests for other nodes during the
computation, and</p></li><li id="uid19"><p>to only transmit these requests if the computation can't
progress anymore.</p></li></simplelist><p>The coarse grained models aim at being realistic with regard to two
different aspects: algorithms and architectures. In fact, the
coarseness of these models uses the common characteristic of today's
parallel settings: the size of the input is orders of magnitude
larger than the number of processors that are available. In
contrast to the PRAM (Parallel Random Access Machine) model, the
coarse grained models are able to integrate the cost of
communications between different processors. This allows them to
give realistic predictions about the overall execution time of a
parallel program. As examples we refer to BSP (Bulk Synchronous
Parallel model) <ref xlink:href="#bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, <span class="smallcap" align="left">LogP</span> (Latency overhead
gap Procs) <ref xlink:href="#bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, CGM (Coarse Grained
Multicomputer) <ref xlink:href="#bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/> and <i>PRO</i> (Parallel Resource
Optimal Model) <ref xlink:href="#bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p><p>The assumptions on the architecture are very similar: <hi rend="italic">p</hi>
homogeneous processors with local memory distributed on a
point-to-point interconnection network. They also have similar
models for program execution that are based on <i>supersteps</i>;
an alternation of computation and communication phases. For the
algorithmics, this takes the distribution of the data on the
different processors into account. But, all the mentioned models
do not allow the design of algorithms for the Grid since they all
assume homogeneity, for the processors as well as for the
interconnection network.</p><p>Our approach is algorithmic. We try to provide a modeling of a
computation on grids that allows an easy design of algorithms and
realistic performing implementations. Even if there are problems
for which the existing sequential algorithms may be easily
parallelized, an extension to other more complex problems such as
computing on large discrete structures (<i>e.g., </i>web graphs or social
networks) is desirable. Such an extension will only be possible
if we accept a paradigm change. We have to explicitly decompose
data and tasks.</p><p>We are convinced that this new paradigm should:</p><orderedlist><li id="uid20"><p>be guided by the idea of <b>supersteps</b> (BSP). This is to
enforce a concentration of the computation to the local data,</p></li><li id="uid21"><p>ensure an economic use of all available resources.</p></li></orderedlist><p>On the other hand, we have to be careful that the model (and the
design of algorithms) remains simple. The number of supersteps
and the minimization thereof should by themselves not be a goal.
It has to be constraint by other more ``<i>natural</i>'' parameters
coming from the architecture and the problem instance.</p><p>A first solution that uses (<ref xlink:href="#uid20" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>) to combine these
objectives for homogeneous environments has been given in
<ref xlink:href="#bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/> with PRO.</p><p>In a complementary approach we have addressed (<ref xlink:href="#uid21" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>) to
develop a simple interface that gives a consistent view of the
data services that are exported to an application, see
<ref xlink:href="#bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p><p>Starting from this model, we try to design high level algorithms
for grids. It will be based upon an abstract view of the
architecture and as far as possible be independent of the
intermediate levels. It aims at being robust with regard to the
different hardware constraints and should be sufficiently
expressive. The applications for which our approach will be
feasible are those that fulfill certain constraints:</p><simplelist><li id="uid22"><p>they need a lot of computing power</p></li><li id="uid23"><p>they need a lot of data that is distributed upon several
resources, or,</p></li><li id="uid24"><p>they need a lot of temporary storage exceeding the capacity
of a single machine.</p></li></simplelist><p>To become useful on grids, coarse grained models (and the
algorithms designed for them) must first of all overcome a
principle constraint: the assumption of homogeneity of the
processors and connections. The long term goal should be
arbitrarily mixed architectures but it would not be realistic to
assume to be able to achieve this in one step.
</p></subsection><subsection id="uid25" topic="t_2"><bodyTitle>Transparent Resource Management</bodyTitle><participants category="None"><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation/><categoryPro/></person><person><firstname>Frédéric</firstname><lastname>Suter</lastname><affiliation/><categoryPro/></person><person><firstname>Luiz Angelo</firstname><lastname>Steffenel</lastname><affiliation/><categoryPro/></person></participants><keyword>data redistribution</keyword><keyword>parallel and distributed computing</keyword><keyword>scheduling</keyword><keyword>approximating algorithms</keyword><moreinfo><p>We think of the future Grid as of a medium to access resources.
This access has to be as transparent as possible to a user of such
a Grid and the management of these resources has not to be imposed
to him/her, but entirely done by a ``<i>system</i>'', so called
<i>middleware</i>. This middleware has to be able to manage all
resources in a satisfactory way. Currently, numerous
<i>algorithmic</i> problems hinder such an efficient resource
management and thus the transparent use of the Grid.</p><p>By their nature, distributed applications use different types of
resources; the most important being these of computing power and
network connections. The management and optimization of those
resources is essential for networking and computing on Grids.
This optimization may be necessary at the level of the computation
of the application, of the organization of the underlying
interconnection network or for the organization of the messages
between the different parts of the application. Managing these
resources relates to a set of <i>policies</i> to optimize their
use and allow an application to be executed under favorable
circumstances.</p></moreinfo><p>Our approach consists of the tuning of techniques and algorithms
for a transparent management of resources, be they data,
computations, networks, ...This approach has to be clearly
distinguished from others which are more focused on applications
and middlewares. We aim at proposing new algorithms (or improve
the exiting ones) <i>for</i> the resource management in
middlewares. Our objective is to provide these algorithms in
libraries so that they may be easily integrated. For instance we
will propose algorithms to efficiently transfer data (data
compression, distribution or redistribution of data) or schedule
sequential or parallel tasks.</p><p>The problems that we are aiming at solving are quite complex.
Therefore they often translate into combinatorial or graph
theoretical problems where the identification of an optimal
solution is known to be hard. But, the classical measures of
complexity (polynomial versus NP-hard) are not very satisfactory
for really large problems: even if a problem has a polynomial
solution it is often infeasible in reality whereas on the other
hand NP-hard problems may allow a quite efficient resolution
with results close to optimality.</p><p>Consequently it is mandatory to study approximation techniques
where the objective is not to impose global optimality constraints
but to relax them in favor of a compromise. Thereby we hope to
find <i>good</i> solutions at a <i>reasonable</i> price. But,
these can only be useful if we know how to analyze and evaluate
them.</p></subsection><subsection id="uid26" topic="t_3"><bodyTitle>Experimental Validation</bodyTitle><participants category="None"><person><firstname>Malek</firstname><lastname>Cherier</lastname><affiliation/><categoryPro/></person><person><firstname>Xavier</firstname><lastname>Delaruelle</lastname><affiliation/><categoryPro/></person><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation/><categoryPro/></person><person><firstname>Martin</firstname><lastname>Quinson</lastname><affiliation/><categoryPro/></person></participants><keyword>reproductibility</keyword><keyword>extendability</keyword><keyword>applicability</keyword><keyword>simulations</keyword><keyword>emulations</keyword><keyword>experiments in situ</keyword><moreinfo><p>An important issue for the research on complex systems such as
grids is to validate the obtained results. This validation
constitutes a scientific challenge by itself since we have to
validate models, their adequation to reality <i>and</i> the
algorithms that we design inside these models. Whereas
mathematical proofs establish soundness <i>within</i> such a
context, the overall validation must be done by experiments. A
successful experiment shows the validity of both the algorithm and
the modeling at the same time. But, if the algorithm does not
provide the expected result or performance, this might be due to
several factors: a faulty modeling, a weak design, or a bad
implementation.</p><p>Experimental validation of grid systems is a particularly
challenging issue. Such systems will be large, rapidly changing,
shared and severely protected. Naive experiments on real
platforms will usually not be reproducible, while the
extensibility and applicability of simulations and emulations will
be very difficult to achieve. These difficulties imply the
study phases through modeling, algorithm design, implementation,
tests and experiments. The test results will reveal precious for a
subsequent modeling phase, complementing the process into a
feedback loop.</p></moreinfo><p>In addition to this idea of validating the whole (modeling, design
and implementation) in our research we are often restricted by a
lack of knowledge: the systems that we want to describe might be too
complex; some components or aspects might be unknown or the
theoretical investigations might not yet be sufficiently advanced to
allow for provable satisfactory solutions of problems.</p><p>We think that an experimental validation is a valuable completion of
theoretical results on protocol and algorithm behavior. The focus
of algorithmic research being upon performance, the main experiments
we are concerned with are performance evaluation. To our opinion,
such experiments should fulfill the following properties:</p><descriptionlist><label>reproducibility:</label><li id="uid27"><p>Experimental settings must be designed and
described such that they are reproducible by others and must give
the same result with the same input.</p></li><label>extensibility:</label><li id="uid28"><p>A report on a scientific experiment concerning
performance of an implementation on a particular system is only of
marginal interest if it is simply descriptive and does not point
beyond the particular setting in which it is performed.
Therefore, the design of an experiment <i>must</i> target possible
comparisons with passed and (in particular) future work,
extensions to more and other processors, larger data sets,
different architectures and alike. Several dimensions have to be
taken into account: scalability,
portability,
prediction and
realism.</p></li><label>applicability:</label><li id="uid29"><p>Performance evaluation should not be a goal
<i>in fine</i> but should result in concrete predictions of the
behavior of programs in the real world. However, as the set of
parameters and conditions is potentially infinite, a good
experiment campaign must define realistic parameters for
platforms, data sets, programs, applications, <i>etc.</i> and
must allow for an easy calibration.</p></li><label>revisability:</label><li id="uid30"><p>When an implementation does not perform as
expected, it should be possible to identify the reasons, be they
caused by the modeling, the algorithmic design, the particular
implementation and/or the experimental environment. Methodologies
that help to explain mispredictions and to indicate improvements
have to be developed.</p></li></descriptionlist></subsection></fondements><domaine id="uid31"><bodyTitle>Application Domains</bodyTitle><subsection id="uid32" topic="t_1"><bodyTitle>High Performance Computing</bodyTitle><participants category="None"><person><firstname>Jens</firstname><lastname>Gustedt</lastname><affiliation/><categoryPro/></person><person><firstname>Frédéric</firstname><lastname>Suter</lastname><affiliation/><categoryPro/></person><person><firstname>Pierre-Nicolas</firstname><lastname>Clauss</lastname><affiliation/><categoryPro/></person></participants><subsection id="uid33"><bodyTitle>Models and Algorithms for Coarse Grained Computation </bodyTitle><p>With this work we aim at extending the coarse grained modeling (and
the resulting algorithms) to hierarchically composed machines such
as clusters of clusters or clusters of multiprocessors.</p><p>To be usable in a Grid context this modeling has first of all to
overcome a principal constraint of the existing models: the idea
of an homogeneity of the processors and the interconnection
network. Even if the long term goal is to target arbitrary
architectures it would not be realistic to think to achieve this
directly, but in different steps:</p><simplelist><li id="uid34"><p>Hierarchical but homogeneous architectures: these are
composed of an homogeneous set of processors (or of the same
computing power) interconnected with a non-uniform network or
bus which is hierarchic (CC-Numa, clusters of SMPs).</p></li><li id="uid35"><p>Hierarchical heterogeneous architectures: there is no
established measurable notion of efficiency or speedup. Also
most certainly not any arbitrary collection of processors will
be useful for computation on the Grid. Our aim is to be able to
give a set of concrete indications of how to construct an
extensible Grid.</p></li></simplelist><p>In parallel, we have to work upon the characterization of
architecture-robust efficient algorithms, <i>i.e., </i>algorithms that are
independent, up to a certain degree, of low-level components or
the underlying middleware.</p><p>The literature about fine grained parallel algorithms is quite
exhaustive. It contains a lot of examples of algorithms that could
be translated to our setting, and we will look for systematic
descriptions of such a translation.</p><p>List ranking, tree contraction and graph
coloring algorithms already have been
designed following the coarse grained setting given by the model
<i>PRO</i>  <ref xlink:href="#bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p><p>To work in the direction of understanding of what problems might
be ``<i>hard</i>'' we tackled a problem that is known to be P-complete
in the PRAM/NC framework, but for which not much had been known
when only imposing the use of relatively few processors: the
<i>lexicographic first maximal independent set</i> (LFMIS)
problem <ref xlink:href="#bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p><p>We already are able to give a work optimal algorithm in case we
have about <span class="math" align="left">log<hi rend="it">n</hi></span> processors and thus to prove that the NC
classification is not necessarily appropriate for today's parallel
environments which consist of few processors (up to some
thousands) and large amount of data (up to some terabytes).</p></subsection><subsection id="uid36"><bodyTitle>External Memory Computation </bodyTitle><p>In the mid-nineties several
authors <ref xlink:href="#bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, <ref xlink:href="#bid7" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>
developed a connection between two different types of computation models:
BSP-like models of parallel computation and IO
efficient external memory algorithms. Their main idea is to
enforce data locality during the execution of a program by
simulating a parallel computation of several processors on one
single processor.</p><p>Whereas such an approach is convincing on a theoretical level, its
efficient and competitive implementation is quite challenging in
practice. In particular, it needs software that induces as little
computational overhead as possible by itself. Up to now, it seems
that this has only been provided by software specialized in IO
efficient implementations.</p><p>In fact, the stability of our library <i>parXXL</i> (formerly <i>SSCRAP</i>),
see Section <ref xlink:href="#uid50" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, also showed
in its extension towards external memory
computing <ref xlink:href="#bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.
<i>parXXL</i> nas a
consequent implementation of an abstraction between the
<i>data</i> of a process execution and the memory of a processor.
The programmer acts upon these on two different levels:</p><simplelist><li id="uid37"><p>with a sort of <i>handle</i> on some data array which is an
abstract object that is common to all <i>parXXL</i> processes.</p></li><li id="uid38"><p>with a map of its (local) part of that data into the address
space of the <i>parXXL</i> processor, accessible as a
conventional pointer.</p></li></simplelist><p>Another add-on was the possibility to fix a maximal number of
processors (<i>i.e., </i>threads) that should be executed concurrently</p><p>In <ref xlink:href="#bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, we develop a pipeline algorithm aware of the use
of external memory to store the handled data. The originality of
our approach is to overlap computation, communication, and IO
through an original strategy using several memory blocks accessed
in a cyclic manner. The resulting pipeline algorithm achieves a
saturation of the disk resource which is the bottleneck in
algorithms relying on external memory.</p></subsection><subsection id="uid39"><bodyTitle>Irregular Problems </bodyTitle><p>Irregular data structures like sparse graphs and matrices are in
wide use in scientific computing and discrete optimization. The
importance and the variety of application domains are the main
motivation for the study of efficient methods on such type of
objects. The main approaches to obtain good results are parallel,
distributed and out-of-core computation.</p><p>We follow several tracks to tackle irregular problems: automatic
parallelization, design of coarse grained algorithms and the
extension of these to external memory settings.</p><p>In particular we study the possible management of very large
graphs, as they occur in reality. Here, the notion of
``<i>networks</i>'' appears twofold: on one side many of these graphs
originate from networks that we use or encounter (Internet, Web,
peer-to-peer, social networks) and on the other the handling of
these graphs has to take place in a distributed Grid environment.
The principal techniques to handle these large graphs will be
provided by the coarse grained models. With the
<i/><span class="smallcap" align="left">PRO</span><i/> model <ref xlink:href="#bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/> and the
<i>parXXL</i> library we already provide tools to better design
algorithms (and implement them afterwards) that are adapted to
these irregular problems.</p><p>In addition we will be able to rely on certain structural
properties of the relevant graphs (short diameter, small
clustering coefficient, power laws). This will help to design data
structures that will have good locality properties and algorithms
that compute invariants of these graphs efficiently.</p></subsection></subsection><subsection id="uid40" topic="t_2"><bodyTitle>Evolution of Scheduling Policies and Network Protocols</bodyTitle><participants category="None"><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation/><categoryPro/></person><person><firstname>Frédéric</firstname><lastname>Suter</lastname><affiliation/><categoryPro/></person><person><firstname>Pierre-François</firstname><lastname>Dutot</lastname><affiliation/><categoryPro/></person><person><firstname>Tchimou</firstname><lastname>N'Takpé</lastname><affiliation/><categoryPro/></person><person><firstname>Luiz Angelo</firstname><lastname>Steffenel</lastname><affiliation/><categoryPro/></person></participants><subsection id="uid41"><bodyTitle>Scheduling on the Grid </bodyTitle><p>Recent developments in grid environment have focused on the need
to efficiently schedule tasks onto distributed computational servers.</p><p>Thus, environments based on the client-agent-server model such as
<ref xlink:href="http://icl.cs.utk.edu/netsolve/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2738238441031">NetSolve</ref>, <ref xlink:href="http://ninf.apgrid.org/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3234954337021">Ninf</ref> or <ref xlink:href="http://graal.ens-lyon.fr/~diet/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3924997430024">DIET</ref> are able to distribute
client requests on a set of distributed servers. Performances of such
environments greatly depend on the scheduling heuristic implemented.
In these systems, a server executes each request as soon as it
has been received: it never delays the start of the execution.</p><p>In order for a such a system to be efficient, the mapping function must choose a
server that fulfills several criteria. First, the total execution time
of the client application, e.g. the makespan, has to be as short as
possible. Second, each request of every clients must be served as
fast as possible. Finally, the resource utilization must be optimized.
However, these objectives are often contradictory. Therefore it is required
to design multi-criteria heuristics that guarantee a balance between these criteria.</p></subsection><subsection id="uid42"><bodyTitle>Parallel Task Scheduling</bodyTitle><p>The use of parallel computing for large and time-consuming
scientific simulations has become mainstream. Two kinds of
parallelism are typically exploited in scientific applications:
<i>task parallelism</i> and <i>data parallelism</i>. In task
parallelism, which is often called "coarse-grain" parallelism, the
application is partitioned into a set of tasks. These tasks are
organized in a Directed Acyclic Graph (DAG) in which nodes
correspond to tasks and edges correspond to precedence and/or data
communication constraints. In data parallelism, or "fine-grain"
parallelism, an application exhibits parallelism typically at the
level of loops. Although data parallelism can be thought of simply as
very fine-grain task parallelism, in practice each kind of
parallelism corresponds to a specific programming model. A way to
expose and exploit increased parallelism, to in turn achieve
higher scalability and performance, is to write parallel
applications that use both task and data parallelism. This
approach is termed <i>mixed parallelism</i> and allows several
data-parallel tasks to be executed concurrently.</p><p>A well-known challenge for the efficient execution of
task-parallel applications is scheduling. The problem consists in
deciding which compute resource should perform which task when, in
a view to optimizing some metric such as overall execution time.
In the case of mixed-parallel applications, data parallelism adds
a level of difficulty to the task-parallel scheduling problem.
Indeed, the common assumption is that data-parallel tasks are
moldable, i.e., they can be executed on arbitrary numbers of
processors, with more processors leading to faster task execution
times. This is typical of most mixed-parallel applications, and
raises the question: how many processors should be allocated to
each data-parallel task? There is thus an intriguing tension
between running more concurrent data-parallel tasks with each
fewer processors, or fewer concurrent data-parallel tasks with
each more processors. Not surprisingly this scheduling problem is
NP-complete. Consequently, several researchers have attempted to
design scheduling heuristics for mixed-parallel applications. The
most successful approaches proceed in two phases: one phase to
determine how many processors should be allocated to each
data-parallel task, one phase to schedule these tasks on the
platform using standard list scheduling algorithms.</p><p>A limitation of these two-phase scheduling algorithms is that they
assume a homogeneous computing environment. While homogeneous
platforms are relevant to many real-world scenarios, heterogeneous
platforms are becoming increasing common and powerful. Indeed, in
the face of increasing computation and memory demands of
scientific application, many current computing platforms consist
of multiple compute clusters aggregated within or across
institutions. Mixed parallel applications appear then ideally
positioned to take advantage of such large-scale platforms.
However, the clusters in these platforms are rarely identical.
Because deployed by different institutions at different times,
they typically consist of different numbers of different compute
nodes (e.g., there can be large slow clusters and small fast
clusters).</p><p>Two approaches can be followed to schedule mixed-parallel
applications on heterogeneous platforms. The first approach
consists in adapting the aforementioned two-phase algorithms for
mixed-parallel applications on homogeneous platforms and making
them amenable to heterogeneous platforms. The second approach
consists in adapting list scheduling algorithms that were
specifically designed for executing task-parallel applications on
heterogeneous platforms and making them amenable to mixed
parallelism <ref xlink:href="#bid10" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>. Both approaches have merit and an
interesting question is: is one approach significantly better than
the other, and if so, which one?</p></subsection><subsection id="uid43"><bodyTitle>Data Redistribution Between Clusters</bodyTitle><p>During computations performed on clusters of machines it occurs
that data has to be shifted from one cluster to an other. For
instance, these two clusters may differ in the resources they
offer (specific hardware, computing power, available software) and
each cluster may be more adequate for a certain phase of the
computation. Then the data have to be redistributed from the
first cluster to the second. Such a redistribution should use the
capacities of the underlying network in an efficient way.</p><p>This problem of redistribution between clusters generalizes the
redistribution problem inside a parallel machine, which already is
highly non trivial.</p><p>Redistributing data between clusters has recently received considerable attention
as it occurs in many application frameworks. Examples
of such frameworks are distributed code-coupling, parallel task execution and persistence
and redistribution for metacomputing.</p><p>The problem is easily modeled by a decomposition of a bipartite graph into
matchings of a given size. However finding a minimal decomposition is
NP-Hard and therefore it is required to look for heuristics or approximation algorithms.</p></subsection><subsection id="uid44"><bodyTitle>Dynamic and Adaptive Compression of Network Streams</bodyTitle><p>A commonly used technique to speed up transfer of large data over
networks with restricted capacity during a distributed computation
is data compression. But such an approach fails to be efficient
if we switch to a high speed network, since here the time to
compress and decompress the data dominates the transfer time.
Then a programmer wanting to be efficient in both cases, would
have to provide two different implementations of the network layer
of his code, and a user of this program would have to determine
which of the variants he/she has to run to be efficient in a
particular case.</p><p>A solution of this problem is a adaptive service which offers the possibility to transfer data
while compressing it. The compression level is dynamically changed according to
the environment and the data. The adaptation process is required by the heterogeneous
and dynamic nature of grids. For instance if the network is very fast, time to compress the data may not be available. But, if the visible bandwidth decreases (due to some congestion on the network), some time to compress the data may become available.</p><p>Then the problems to solve are to never degrade the performance, to offer a portable implementation,
to deal with all kind of network and environments.</p></subsection></subsection><subsection id="uid45" topic="t_3"><bodyTitle>Providing Environments for Experiments</bodyTitle><participants category="None"><person><firstname>Xavier</firstname><lastname>Delaruelle</lastname><affiliation/><categoryPro/></person><person><firstname>Jens</firstname><lastname>Gustedt</lastname><affiliation/><categoryPro/></person><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation/><categoryPro/></person><person><firstname>Martin</firstname><lastname>Quinson</lastname><affiliation/><categoryPro/></person></participants><subsection id="uid46"><bodyTitle>Simulating Grid Platforms</bodyTitle><p>We participate to the development of the <span class="smallcap" align="left">SimGrid</span> tool. It enables the simulation of
distributed applications in distributed computing environments for the specific
purpose of developing and evaluating scheduling algorithms. Simulations not
only allow repeatable results (what is hard to achieve on shared resources)
but also make it possible to explore wide ranges of platform and application
scenarios. <span class="smallcap" align="left">SimGrid</span> implements realistic fluid network models that result in very
fast yet precise simulations. <span class="smallcap" align="left">SimGrid</span> also enables the simulation of distributed
scheduling agents, which has become critical for current scheduling research in
large-scale platforms. This tool is being used by several groups in the Grid
Scheduling literature.</p></subsection><subsection id="uid47"><bodyTitle>Emulating Heterogeneity</bodyTitle><p>We have designed a tool called <i>Wrekavoc</i>. The goal of Wrekavoc is to define and control the heterogeneity of a given platform by degrading
CPU, network or memory capabilities of each node composing this platform. Our current implementation of Wrekavoc
have been tested on an homogeneous cluster. We have shown that configuring a set of nodes is very fast. Micro-benchmarks show that we are able to independently degrade CPU, bandwidth and latency to the desired values. Tests on algorithms of the literature (load balancing and matrix multiplication) confirm
the previous results and show that Wrekavoc is a suitable tool for developing, studying and comparing algorithms in heterogeneous
environments.</p></subsection><subsection id="uid48"><bodyTitle>Grid'5000</bodyTitle><p>We participate to the development of the Grid'5000 platform. Its purpose is to serve as an experimental testbed for research in Grid Computing. In addition to theory, simulators and emulators, there is a strong need for large scale testbeds where real life experimental conditions hold. Grid'5000 aims at building a highly reconfigurable, controlable and monitorable experimental Grid platform gathering nine sites geographically distributed in France featuring a total of five thousands CPUs. We are in charge of one of these nine sites and we currently provide about one hundred processors to the community.</p></subsection></subsection></domaine><logiciels id="uid49"><bodyTitle>Software</bodyTitle><subsection id="uid50" topic="t_1"><bodyTitle>parXXL</bodyTitle><participants category="None"><person><firstname>Jens</firstname><lastname>Gustedt</lastname><affiliation/><categoryPro/></person><person><firstname>Stéphane</firstname><lastname>Vialle</lastname><affiliation/><categoryPro/></person><person><firstname>Pierre-Nicolas</firstname><lastname>Clauss</lastname><affiliation/><categoryPro/></person></participants><moreinfo><p><i>parXXL</i> is a library for large scale computation and communication
that executes fine grained algorithms (computation and
communication are of the same order of magnitude) on coarse
grained architectures (clusters, grids, mainframes).</p></moreinfo><p>Historically <i>parXXL</i> the result of a merge of two different projects, <i>ParCeL</i> (from Supélec) and <i>SSCRAP</i> (from INRIA), that stand for a consequent modeling and
implementation of fine grained networks (<i>ParCeL</i>) and coarse grained
algorithmics (<i>SSCRAP</i>) respectively.</p><p>The integration, testing and benchmarking of <i>parXXL</i> started as a
joint effort with Amelia De Vivo, university of Basilicata, Ponteza,
Italy, until her sudden and unexpexted death in June 2006.</p><p>This library takes the requirements of <i>PRO</i>,
see Section <ref xlink:href="#uid16" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, into
account, <i>i.e., </i>the design of algorithms in alternating computation
and communication steps. It realizes an abstraction layer between
the algorithm as it was designed and its realization on different
architectures and different modes of communication. The current
version of this library
is available at <ref xlink:href="http://parxxl.gforge.inria.fr/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2873396182006">http://parxxl.gforge.inria.fr/</ref>
and integrates:</p><simplelist><li id="uid51"><p>a layer for message passing with
<ref xlink:href="http://www-unix.mcs.anl.gov/mpi/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2048566857010">MPI</ref>,</p></li><li id="uid52"><p>a layer for shared memory with <ref xlink:href="http://www.humanfactor.com/pthreads/pthreadlinks.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1999290172021">POSIX
threads</ref>,
and,</p></li><li id="uid53"><p>a layer for out-of-core management with file mapping (system
call <i>mmap</i>).</p></li></simplelist><p>All three different realizations of the communication layers are
quite efficient. They let us execute programs that are otherwise
unchanged within the three different contexts such that they reach
or maybe outperform programs that are directly written for them.</p></subsection><subsection id="uid54" topic="t_2"><bodyTitle>AdOC</bodyTitle><participants category="None"><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation/><categoryPro/></person></participants><moreinfo><p>The <ref xlink:href="http://www.loria.fr/~ejeannot/adoc/adoc.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3821444565004"><span class="smallcap" align="left">AdOC</span></ref>,
(Adaptive Online Compression) library implements
the <span class="smallcap" align="left">AdOC</span> algorithm for dynamic adaptive compression of
network streams.</p></moreinfo><p><span class="smallcap" align="left">AdOC</span> is written in C and uses the standard library
<i>zlib</i> for the compression part. It is realized as an
additional layer above TCP and offers a service of adaptive
compression for the transmission of program buffers or files.
Compression is only used if it doesn't generate an additional
cost, typically if the network is slow or the sending processor is
not charged too much. It integrates overlap techniques between
compression and communication as well as mechanisms that avoid
superfluous copy operations. The send and receive functions have
exactly the same semantics as the system calls <tt>read</tt> and
<tt>write</tt> so the integration of <span class="smallcap" align="left">AdOC</span> into existing
libraries and application software is straightforward. Moreover,
<span class="smallcap" align="left">AdOC</span> is thread-safe.
</p></subsection><subsection id="uid55" topic="t_3"><bodyTitle>Wrekavoc</bodyTitle><participants category="None"><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation/><categoryPro/></person></participants><moreinfo><p>Wrekavoc addresses the problem of controlling the heterogeneity of
a cluster. Our objective is to have a configurable environment
that allows for reproducible experiments on large set of
configurations using real applications with no emulation of the
code. Given an homogeneous cluster Wrekavoc degrades the
performance of nodes and network links independently in order to
build a new heterogeneous cluster. Then, any application can be
run on this new cluster without modifications.</p></moreinfo><p>Wrekavoc is implemented using the client-server model. A server,
with administrator privilege, is deployed on each node one wants to
configure. The client reads a configuration file and sends orders
to each node in the configuration. The client can also order the
nodes to recover the original state.</p><descriptionlist><label>CPU Degradation.</label><li id="uid56"><p>We have implemented several methods for degrading CPU performance.
The first approach consists in managing the frequency of the CPU
through the kernel CPU-Freq interface. We propose two other
solutions in case CPU-Freq is not available. One is based on CPU
burning. A program that runs under real-time scheduling policy
burns a constant portion of the CPU, whatever the number of
processes currently running. The other is based on user-level
process scheduling called CPU-lim. A CPU limiter is a program that
supervises processes of a given user. Using the <tt>/proc</tt>
pseudo-filesystem, it suspends the processes when they have used
more than the required fraction of the CPU.</p></li><label>Network Limitation.</label><li id="uid57"><p>Limiting latency and bandwidth is done using <i>tc</i> (traffic
controller) based on <i>Iproute2</i> a program that allows advanced
IP routing. With this tools it is possible to control both incoming
and outgoing traffic. Furthermore, the latest versions (above
2.6.8.1) allows to control the latency of the network interface.</p></li><label>Memory Limitation.</label><li id="uid58"><p>Wrekavoc is able to limit the largest malloc a user can make. This
is possible through the security module PAM. However, we have not
been able to limit the whole memory usable by all the processes yet.</p></li><label>Configuring and Controlling Nodes and Links.</label><li id="uid59"><p>The configuration of a homogeneous cluster is made through the
notion of islet. An islet is a set of nodes that share similar
limitation. Two islets are linked together by a virtual network
which can also be limited. An islet is defined as a union of IP
addresses (or machine names) intervals.</p><p>Each islet configuration is stored into a configuration file. At
the end of this file is described the network connection (bandwidth
and latency) between each islet.</p></li></descriptionlist><p>We have also Wrekavoc on the Grid-explorer cluster with 216
nodes. Each node has two 2 GHz AMD Opteron 246 with 2 GB of RAM. It
runs under Linux Debian 3.1 with kernel 2.6.8.
Results show that we are able to independently degrades each
resources and that the obtained degradation is very close to the
desired one.</p></subsection><subsection id="uid60" topic="t_3"><bodyTitle>GRAS</bodyTitle><participants category="None"><person><firstname>Martin</firstname><lastname>Quinson</lastname><affiliation/><categoryPro/></person></participants><moreinfo><p>The <span class="smallcap" align="left">GRAS</span> (Grid Reality And Simulation) framework eases the
development of Grid services and infrastructures.</p></moreinfo><p>GRAS provides a C ANSI interface to build distributed services and
infrastructure for the Grid. Two implementations of this API are provided:
the first one (called Grid R&amp;D Kit) lets the developers experiment, test and
debug their work within the SimGrid simulator. The other implementation
(called Grid Runtime Environment) allows the resulting programs to run
efficiently on real systems.</p><p>The simulator thus greatly eases the research and development of Grid services
(such as for example monitoring infrastructure or distributed storage
systems). In addition, the Grid Runtime Environment is ported to Linux,
Windows, Solaris, Mac OS X, AIX and IRIX operating systems, and to 9 hardware
architectures. Services built on top of this achieve better communication
performance than heterogeneous implementations of the MPI protocol.</p><p>This tool is now integrated into the <span class="smallcap" align="left">SimGrid</span> framework, and available from</p><p noindent="true"><ref xlink:href="http://gforge.inria.fr/projects/simgrid/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="963329705031">http://gforge.inria.fr/projects/simgrid/</ref>.</p></subsection><subsection id="uid61" topic="t_3"><bodyTitle>LaPIe</bodyTitle><participants category="None"><person><firstname>Luiz Angelo</firstname><lastname>Steffenel</lastname><affiliation/><categoryPro/></person></participants><moreinfo><p><span class="smallcap" align="left">LaPIe</span> is an automatically tuned collective communication library designed for large-scale heterogeneous
systems.</p></moreinfo><p>The popularity of heterogeneous parallel processing environments like clusters and computer grids has emphasised the impact of network heterogeneity on the performance of parallel applications. Collective communication operations are especially concerned by this problem, as heterogeneity interfers directly on the communication performance.</p><p><span class="smallcap" align="left">LaPIe</span> provides a set of MPI collective communication operations especially designed to perform automatic
adaptation according to the network characteristics. Indeed, <span class="smallcap" align="left">LaPIe</span> combines both topology discovery and
performance prediction to chose the best communication scheduling that minimizes the overall communication time for a given operation.</p><p><span class="smallcap" align="left">LaPIe</span> is distributed as a programming library that overloads (through profiling) existing MPI calls. This allows <span class="smallcap" align="left">LaPIe</span> to be easily integrated into existing applications without modifying their code - we just need to recompile them.
In addition, <span class="smallcap" align="left">LaPIe</span> was designed to facilitate the addition of new scheduling techniques and collective communication operations. Therefore, <span class="smallcap" align="left">LaPIe</span> provides an excelent testbed to develop and evaluate new communication scheduling techniques and/or architecture-specific optimizations.</p><p><span class="smallcap" align="left">LaPIe</span> currently supports <i>MPI_Bcast</i>, <i>MPI_Scatter</i> and <i>MPI_Alltoall</i> operations, whose efficiency was evaluated in several papers we published. New operations such as <i>MPI_Reduce</i>, <i>MPI_Gather</i> and <i>MPI_Allgather</i> should be added very soon.</p><p><span class="smallcap" align="left">LaPIe</span> is available at <ref xlink:href="http://libresource.inria.fr/projects/LaPIe" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2321719073001">http://libresource.inria.fr/projects/LaPIe</ref>.</p></subsection></logiciels><resultats id="uid62"><bodyTitle>New Results</bodyTitle><subsection id="uid63" topic="t_1"><bodyTitle>Structuring of Applications for Scalability</bodyTitle><participants category="None"><person><firstname>Frédéric</firstname><lastname>Suter</lastname><affiliation/><categoryPro/></person><person><firstname>Jens</firstname><lastname>Gustedt</lastname><affiliation/><categoryPro/></person><person><firstname>Pierre-Nicolas</firstname><lastname>Clauss</lastname><affiliation/><categoryPro/></person></participants><subsection id="uid64"><bodyTitle>Large Scale Experiments</bodyTitle><p>The merge of the two libraries <i>ParCeL</i> and <i>SSCRAP</i> into the new software suite
<ref xlink:href="http://parxxl.gforge.inria.fr/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2873396182006"><i>parXXL</i></ref>
has been accomplished this year. It consists of different
toolboxes, <tt>par::cpp</tt> (interfaces for the C++ language),
<tt>par::sys</tt> (interfacing POSIX systems), <tt>par::mem</tt>
(tools for managing memory), <tt>par::step</tt> (manage
supersteps), <tt>par::cell</tt> (management of cellular networks)
and <tt>par::cellnet</tt> (defining default network types).</p><p>The integration of the formerly seperated libraries allows to
validate the whole on a wide range of fine grained applications
and problems. A report on the design and the first benchmarking
of the integrated code can be found in <ref xlink:href="#bid11" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p><p>Now that the communication layer of <i>parXXL</i> can handle
large numbers of <span class="smallcap" align="left">POSIX</span> threads (shared memory) or
distributed processes (MPI), we were able to run large scale
experiments on mainframes and clusters. These have proved the
scalability of our approach as a whole, including engineering,
modeling and algorithmic aspects: the algorithms that are
implemented and tested show a speedup that is very close to the
best possible theoretical values, and these speedups are reproducible
on a large variety of platforms, see <ref xlink:href="#bid12" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p></subsection><subsection id="uid65"><bodyTitle>Models and Algorithms for Coarse
Grained Computation</bodyTitle><p>We continued the design of algorithms in the coarse grained
setting as given by the model <i>PRO</i>  <ref xlink:href="#bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>. In
particular we aimed for the design
of an algorithm that takes advantage of the structure commonly
encountered with
massive graphs, namely the fact that they usually have a bounded
arboricity. There we gave algorithms for computing probability
vectors that can be used for the clustering of communities,
see <ref xlink:href="#bid13" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p><p>For testing and benchmarking the generation of large random input
data with known probability distributions is crucial.
In <ref xlink:href="#bid14" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, we show how to uniformly
distribute data at random in two related settings: <i>coarse
grained parallelism</i> and <i>external memory</i>. In contrast to
previously known work for parallel setups, our method is able to
fulfill the three criteria of uniformity, work-optimality and
balance among the processors simultaneously. To guarantee the
uniformity we investigate the matrix of communication requests
between the processors. We show that its distribution is a
generalization of the multivariate hypergeometric distribution
and we give algorithms to sample it efficiently in the two
settings.</p></subsection><subsection id="uid66"><bodyTitle>Overlapping Computations and Communications with I/O</bodyTitle><p>In <ref xlink:href="#bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, we noticed that the performance of our
pipeline algorithm were impacted by asynchronous communications that
introduced gaps between I/O operations. To address this issue we
studied how to adapt this kind of algorithms, that is wavefront
algorithm, to shared memory platforms.</p><p>Using the <i>parXXL</i> library we were able to propose a
architecture-independant out-of-core implementation of a well known
hydrodynamics kernel, see <ref xlink:href="#bid15" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>. In addition to
this implementation we proposed a optimized data layout that allow
to reduce the I/O impact on each iteration of the algorithm by an
order of magnitude at the cost of an initial rewriting of the data.
This work is currently under submission, see <ref xlink:href="#bid16" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p></subsection></subsection><subsection id="uid67" topic="t_2"><bodyTitle>Transparent Ressource Management</bodyTitle><participants category="None"><person><firstname>Pierre-François</firstname><lastname>Dutot</lastname><affiliation/><categoryPro/></person><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation/><categoryPro/></person><person><firstname>Tchimou</firstname><lastname>N'Takpé</lastname><affiliation/><categoryPro/></person><person><firstname>Luiz Angelo</firstname><lastname>Steffenel</lastname><affiliation/><categoryPro/></person><person><firstname>Frédéric</firstname><lastname>Suter</lastname><affiliation/><categoryPro/></person></participants><subsection id="uid68"><bodyTitle>Scheduling under Uncertainty</bodyTitle><p>When scheduling a set of task modeled by a DAG, due to runtime variation,
the actual makespan can be different than the
makespan computed by the scheduling algorithm. A schedule is said <i>robust</i>
when this variation is not too large, <i>i.e.</i> when the schedule is not too sensible to
runtime variation.</p><p>We have addressed the problem of matching and scheduling of DAG-structured application to
both minimize the makespan and maximize the robustness in a heterogeneous computing system.
Due to the conflict of the two objectives, it is usually impossible to achieve both goals
at the same time. We have given two definitions of robustness of a schedule based on
tardiness and miss rate. Slack was proved to be an effective metric to be used
to adjust the robustness. We have employed <span class="math" align="left"><img width="9" height="12" align="bottom" border="0" src="../../images/img_epsilon.png" alt="$ \epsilon$"/></span>-constraint method to solve
the bi-objective optimization problem where minimizing the makespan and maximizing the slack
are the two objectives. We have defined the overall performance of a schedule considering both
makespan and robustness such that user have the flexibility to put emphasis on either objective.
Experiment results have validated the performance of the proposed algorithm.</p></subsection><subsection id="uid69"><bodyTitle>Parallel Task Scheduling</bodyTitle><p>When conducting our initial experimental comparison of
M-HEFT <ref xlink:href="#bid10" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/> and the HCPA heuristic developed during the
master thesis of Tchimou N'Takpé we identified several
limitations in both algorithms. This year we proposed improvements
to address these limitations. The allocation phase of HCPA has been
improved by proposing a new stopping criterion that allows smaller
but still efficient allocations. We also introduced a packing
strategy in order to fill gaps that may appear in its placement
phase as a task may be delayed unnecessarily just because its
computed processor allocation is (perhaps only slightly) larger than
the number of processors available at the time when the task is
ready for execution.</p><p>We also address a glaring drawbacks of M-HEFT, which is that it
tends to use very large processor allocations for application tasks.
This is simply due to the fact that a task's processor allocation is
chosen "blindly" so that the task's completion time is minimized. To
remedy this problem with M-HEFT we propose three simple ways to
bound a task's processor allocation.</p><p>Part of these research have been published in <ref xlink:href="#bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, <ref xlink:href="#bid18" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>,
and a comparison between improved versions of our heuristics is
under submission.</p><p>Finally we are currently on the implementation of a guaranteed heuristic in
collaboration with Henri Casanova, at University of Hawai`i, Manoa
and Pierre-Fran cois Dutot. An optimal allocation is computed by
a linear program and a list scheduling algorithm is then used to
place these task's allocation.</p></subsection><subsection id="uid70"><bodyTitle>Data Redistribution</bodyTitle><p>Various redistribution algorithm of the literature have been
implemented and tested this year. Indeed, many algorithms have been
proposed to redistribute data on a same cluster. However, no fair
comparison exists between these algorithms. Moreover, some of them
can easily be extended to solve the KPBS problem that consists in
redistributing data between clusters over a backbone.</p><p>We have carried out experiments on the grid explorer cluster and on
grid 5000 between the Orsay site and the Rennes site as well as on a singe cluster.</p><p>Surprisingly, on the machines we tested, we have found that avoiding contention is not always useful. Indeed, in most of the cases, the brute-force method is the fastest way to redistribute data from a block-cyclic distribution to another block-cyclic distribution. This result is mainly due to the fact that contention does not degrade the performance of the networks we have used. However, in the case where the pattern is irregular OGGP is the
best scheduling algorithm. We also showed that preemption is useful only if its cost is taken into
account by the algorithm.</p><p>In conclusion, if performance is the only issue, the brute-force method is often the best one.
However, if other issues have to be considered (QOS, memory constraints, predictability
and stability), scheduling algorithms such as OGGP are a very good options.</p></subsection><subsection id="uid71"><bodyTitle>Performance Prediction</bodyTitle><p>Being able of accurately estimating the runtime of a program and communication time of data transfer is
critical for efficiently scheduling application on distributed environments such as grids.</p><p>We have introduced a template based modeling mechanism that is able to accurately predict the runtime
of the service based on previous execution. It improves the standard runtime estimation of
GridSolve as it is more accurate and takes into account the specificity of the service and the machine it runs on.
Second, we have developed an estimator of the communication cost between the client and the server.
Since communication cost is often very large such an estimator enables to discard fast remote server if the gain
in terms of computation time is overshadowed by the communication time.</p><p>We have also worked on modeling the dense LU factorization in order to predict the runtime on a
parallel machine. With this model we are able to predict a block-size close to the optimal for a given
size of the matrix and a given number of processors</p></subsection><subsection id="uid72"><bodyTitle>Total Exchange Performance Prediction</bodyTitle><p>One of the most important collective communication patterns for scientific applications is the total exchange (also called All-to-All, in which each process holds <i>n</i> different data items of size <i>m</i> that should be distributed among the <i>n</i> processes, including itself. However, this communication pattern tend to saturate network resources, causing unexpected transmission delays - the network contention.</p><p>Having accurate predictions is extremely important on the development of application performance prediction frameworks such as PEMPIs <ref xlink:href="#bid19" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/> and GridSolve. Because it is not always possible to use contention-aware All-to-All implementations (as in the case of popular MPI libraries), it is important to design performance models that take into account the effects of network contention.</p><p>Studying the effects of the network contention in the context of MPI programming environments, we introduced a new approach to model the performance of the All-to-All collective operation. Contrarily to existing models which rely on complex interference analysis, our strategy consists in identifying, based on a sample execution, a contention signature that characterizes a given network environment. Using such method we were able to accurately predicted the performance of the All-to-All operation on different network architectures (Fast Ethernet, Gigabit Ethernet and Myrinet, for example), as illustrated in our paper <ref xlink:href="#bid20" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p></subsection><subsection id="uid73"><bodyTitle>Grid-aware Total Exchange</bodyTitle><p>As presented above, Total Exchange algorithms (also called All-to-All) are widely studied in the context of
(partially) homogeneous clusters subjected to network contention. Only a few works try to optimize
the execution of such communication patterns on grid environments, and up to now the results are far
from being widely spread. Indeed, heterogeneity of the communication environment turns the optimization
of the All-to-All operation into a NP-hard problem.</p><p>Based on preliminary experiments conducted by <ref xlink:href="#bid21" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>, we were able to implement on <span class="smallcap" align="left">LaPIe</span>
some scheduling heuristics that are efficient for small messages (or better saying, for strongly heterogeneous
environments. Nevertheless, these heuristics fail with large messages as they are unable to improve the utilisation
of the wide-area bandwidth. For instance, we are currently observing
the impact of different implementation algorithms from popular MPI distribution such as MPICH and OpenMPI on
the communication schedule, and trying to figure out the causes of low-bandwidth utilisation sometimes observed
with these algorithms. The next step will consist on developing specific heuristics to circumvent these restriction. They
should be tested in both simulated and real environments, using respectively GRAS/MSG (or SMPI, if available) and <span class="smallcap" align="left">LaPIe</span>.</p></subsection></subsection><subsection id="uid74" topic="t_3"><bodyTitle>Experimental Validation</bodyTitle><participants category="None"><person><firstname>Malek</firstname><lastname>Cherier</lastname><affiliation/><categoryPro/></person><person><firstname>Xavier</firstname><lastname>Delaruelle</lastname><affiliation/><categoryPro/></person><person><firstname>Ahmed</firstname><lastname>Harbaoui</lastname><affiliation/><categoryPro/></person><person><firstname>Emmanuel</firstname><lastname>Jeannot</lastname><affiliation/><categoryPro/></person><person><firstname>Martin</firstname><lastname>Quinson</lastname><affiliation/><categoryPro/></person><person><firstname>Christophe</firstname><lastname>Thiery</lastname><affiliation/><categoryPro/></person></participants><subsection id="uid75"><bodyTitle>Improvement of the <span class="smallcap" align="left">SimGrid</span> tool</bodyTitle><p>The goal of the <span class="smallcap" align="left">SimGrid</span> tool suite is to allow the study and development of
distributed application on modern platforms. It is the result of a
collaboration with Henri Casanova (Univ. of Hawaii, Manoa) and Arnaud Legrand
(MESCAL team, INRIA Rhône-Alpes, France). Simulation is a common answer to
the grid specific challenges such as scale and heterogeneity. <span class="smallcap" align="left">SimGrid</span> is one of
the major simulator in the Grid community.</p><p>This year, Malek Cherrier was hired as an engineer on an ODL contract
(Opération de Développement Logiciel – software development operation)
granted by INRIA, allowing us to assess the technical issues posed by the
development of the tool. We completed the port <span class="smallcap" align="left">SimGrid</span> to the Windows platforms,
increasing the possible user base. We also worked on an automated testing
infrastructure to ensure the software quality of the product. This step was
necessary to stabilize the existing code base prior to the add of new
functionalities, planed for the future.</p><p>In the same time, Christophe Thiery enhanced the simulator to add a new
interface called SimDag. It allows to easily express applications modeled by
DAG of tasks. Such an interface was present in <span class="smallcap" align="left">SimGrid</span> version 2, but it were not
ported yet into the <span class="smallcap" align="left">SimGrid</span> 3 framework. This functionality helps the work on
parallel task scheduling achieved within the team (<i>cf.</i><ref xlink:href="#uid69" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>) and above.</p><p><span class="smallcap" align="left">SimGrid</span> is freely downloadable <ref xlink:href="#bid22" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/> and its user base is
rapidly growing, resulting in the publication of about ten publications (half
of them from users not being part of the core team).</p></subsection><subsection id="uid76"><bodyTitle>Grid Platform Discovery</bodyTitle><p>Due to the changing characteristics of the Grids, distributed applications
targeting these platforms must be network-aware and react to the condition
changes. To make this possible, applications must have a synthetic view of
the network condition they experiment. Several platform monitoring tools
exist, but they provide irrelevant or incomplete information to network-aware
applications. Most of these tools intend to help the network administrator to
detect abnormalities in their system. They thus concentrate on very low level
metrics such as the amount of data emited by a given host where network-aware
application need to access the available bandwidth between host pairs. Some
tools were designed specifically to provide such higher-level information
(the most predominant being NWS – <ref xlink:href="#bid23" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>), but they are limited to
quantitative information about the bandwidth, latency and processor
availability.</p><p>We designed a tool to discover the network topology from an application point
of view. We are mainly interested in predicating the effect of resource
sharing between concurrent data stream. This information is for example
crucial to schedule individual messages of group communications or to compute
the optimal localization of backup servers and storage areas.</p><p>Testing and comparing the different possible heuristics to address this
problem is difficult since it comes done to assessing how similar the
discovered graph is from the real platform topology. We designed a testing
framework on simulator, allowing to do so by comparing the performance of
classical applications both on the discovered platform and on the real
one. This comparison metric thus captures how the discovered platform matches
the real one <i>from the application point of view</i>.</p><p>We compared several heuristics presented theoretically in the literature, and
plan to improve them in a near future <ref xlink:href="#bid24" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p></subsection><subsection id="uid77"><bodyTitle>Grid'5000</bodyTitle><p>Grid'5000 aims at building an experimental Grid platform featuring a total of five thousands CPUs over nine sites in France. We have built one of these site by installing a 47-nodes HP cluster. Each compute node of the HP cluster has two 2 GHz AMD Opteron 246 with 2 GB of RAM and runs under Linux Debian. The cluster is connected to the grid through a 10 Gigabit Ethernet network, provided by Renater. We were the first site to provide this 10 Gigabit uplink. We manage the day to day usage of the cluster and regularly update it to fit as close as possible the Grid'5000 recommendations.</p><p>We support the local and national Grid'5000 users by helping them using the platform. We provide them trainings and we try to find with them the best way for their experiments to use the grid. We take a significant part in the organization of the "Grid'5000 spring school 2006" and we mount our own education-day called "Journée Grid'5000 au Loria".</p><p>Each Grid'5000 site aims at providing at least five hundreds CPUs. We have designed our needs for a second cluster and conduct its purchase. This new machine is a 120-nodes HP cluster. Each compute node has two 1.6 GHz Dual-core Intel Xeon 5110 with 2 GB of RAM and two gigabit Ethernet interfaces. We plan to receive and install this cluster at the end of the year.</p><p>We take a significant part in the national development of the Grid'5000 platform. We help consolidating the production infrastructure, by developing tools like the account management software called cpu-g5k (https://gforge.inria.fr/projects/grid5000/) or creating Linux-based grid environment for users. We also participate at most of the existing workgroups of the project, like the one for the next Kadeploy version (<ref xlink:href="https://gforge.inria.fr/projects/kadeploy" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink">https://gforge.inria.fr/projects/kadeploy/</ref>https://gforge.inria.fr/projects/kadeploy/). Moreover we take in charge some of the collaborative services like the wiki website and the bug reporting tool.</p></subsection></subsection></resultats><international id="uid78"><bodyTitle>Other Grants and Activities</bodyTitle><subsection id="uid79"><bodyTitle>National Initiatives</bodyTitle><subsection id="uid80"><bodyTitle>CNRS initiatives, GDR-ARP and specific initiatives</bodyTitle><p>We participate at numerous national initiatives. In the
<ref xlink:href="http://asr.cnrs.fr/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1165288063018">GDR-ASR</ref>
(architecture, systems, and networks) we take part in
<ref xlink:href="http://ares.insa-lyon.fr/tarot/jsp/site/Portal.jsp" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1897704749012">TAROT</ref><span class="math" align="left"><sup>, </sup></span><footnote id="uid81" place="foot" anchored="yes"><i>Techniques
algorithmiques, réseaux et d'optimisation pour les
télécommunications</i></footnote>,
Grappes<footnote id="uid82" place="foot" anchored="yes"><i>Architecture, systèmes, outils et
applications pour réseaux de stations de travail hautes
performances</i></footnote>, and
<ref xlink:href="http://www-r2.u-strasbg.fr/rge/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2700400537023">RGE</ref><span class="math" align="left"><sup>, </sup></span><footnote id="uid83" place="foot" anchored="yes"><i>Réseau Grand Est</i></footnote>. We also participate to the animation of the GDR-ASR as a whole.</p><p>The fincances of RGE, lead by Stéphane Vialle at Supélec, are
maintained by AlGorille.</p></subsection><subsection id="uid84"><bodyTitle>ACI initiatives of the French Research Ministry</bodyTitle><p>We are partners in several projects of different ACI initiatives:</p><simplelist><li id="uid85"><p><ref xlink:href="http://www.lri.fr/~fci/GdX/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="576321299008">Grid
Explorer</ref>. We participate
with a joint proposition together with Stéphane Vialle from
Supélec, Metz Campus, which concerns the integration tests
of <i>SSCRAP</i> and Parcel-6 as described in
Section <ref xlink:href="#uid74" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.
We also work on designing a set of emulation tools for
transforming an homogeneous platform into an heterogeneous one,
see Section <ref xlink:href="#uid55" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="948446382005"/>.</p></li><li id="uid86"><p>In the 2004 initiative ACI
<ref xlink:href="http://www.aci-agir.org" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1459128358018"><span class="smallcap" align="left">Agir</span></ref>
we participate in the definition and design of a set of services
for medical image processing on the grid. More precisely we are in
charge of transfer with compression task and the evaluation of
grid middleware.</p></li></simplelist></subsection><subsection id="uid87"><bodyTitle>ARA Initiatives of the French Research Ministry</bodyTitle><p>We are partners in one project of the ARA Masse de données (thematic call
to project from the French Research Ministry):</p><simplelist><li id="uid88"><p><ref xlink:href="http://www.labri.fr/perso/obeaumon/alpage.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2966819739000">ALPAGE</ref>.</p><p>The new algorithmic challenges associated with large-scale platforms have
been approached from two different directions. On the one hand, the
parallel algorithms community has largely concentrated on the problems
associated with heterogeneity and large amounts of data. Algorithms have
been based on a centralized single-node, responsible for calculating the
optimal solution; this approach induces significant computing times on the
organizing node, and requires centralizing all the information about the
platform. Therefore, these solutions clearly suffer from scalability and
fault tolerance problems.</p><p>On the other hand, the distributed systems community has focused on
scalability and fault-tolerance issues. The success of file sharing
applications demonstrates the capacity of the resulting algorithms to
manage huge volumes of data and users on large unstable platforms.
Algorithms developed within this context are completely distributed and
based on peer-to-peer communications. They are well adapted to very
irregular applications, for which the communication pattern is
unpredictable. But in the case of more regular applications, they lead to a
significant waste of resources.</p><p>The goal of the ALPAGE project is to establish a link between these
directions, by gathering researchers (ID, LIP, LORIA, LaBRI, LIX, LRI) from
the distributed systems and parallel algorithms communities. More
precisely, the objective is to develop efficient and robust algorithms for
some elementary applications, such as broadcast and multicast, distribution
of tasks that may or may not share files, resource discovery. These
fundamental applications correspond well to the spectrum of the
applications that can be considered on large scale, distributed platforms.</p></li></simplelist></subsection><subsection id="uid89"><bodyTitle><span class="smallcap" align="left">INRIA</span> New Investigation Grant</bodyTitle><p>The goal of the ARC OTaPHe is to federate conceptual and
experimental researches around parallel task scheduling conducted by
the AlGorille, <span class="smallcap" align="left">Graal</span>, <span class="smallcap" align="left">Mescal</span> and <span class="smallcap" align="left">Moais</span><span class="smallcap" align="left">INRIA</span> teams. Our approach consists in defining models taking
computational grid heterogeneity into account. These models however
have to remain simple. From those models guaranteed heuristics will
be designed and implemented into the DIET and OAR middlewares in
order to validate them.</p></subsection></subsection><subsection id="uid90"><bodyTitle>European Initiatives</bodyTitle><subsection id="uid91"><bodyTitle>NoE CoreGrid</bodyTitle><p>We take part in the NoE ``<i>CoreGrid</i>'' lead by Thierry Priol from
<span class="smallcap" align="left">INRIA</span> Rennes. More precisely we are part of the work
package 6 on scheduling. Emmanuel Jeannot is the leader for CNRS of
task 6.5: evaluation and benchmarking.</p></subsection><subsection id="uid92"><bodyTitle>Bilateral Collaborations</bodyTitle><p>We maintain several european collaborations with other research
teams. The two most fruitful are with the team of Jan Arne Telle
from Bergen University, Norway, and with Vandy Berten and Joël Goossens of
the Université Libre de Bruxelles on scheduling problems under
stochastic models.</p></subsection></subsection><subsection id="uid93"><bodyTitle>International Initiatives</bodyTitle><subsection id="uid94"><bodyTitle>NSF-INRIA Grant</bodyTitle><p>Our collaboration with Jack Dongarra of the University of
Tennessee, Knoxville and the <span class="smallcap" align="left">Graal</span> project of
<span class="smallcap" align="left">INRIA</span>, has been formalized in an
<span class="smallcap" align="left">INRIA</span>-NSF project which handles the aspects of the
integration of our scheduling algorithms into NetSolve.</p></subsection><subsection id="uid95"><bodyTitle>Bilateral Collaborations</bodyTitle><p>We collaborate with Henri Casanova of University of Hawaii at Manoa
on parallel task scheduling heuristics for heterogeneous
environments as well as on the simulation of grid platforms within
the SimGrid project.</p><p>We collaborate with Prof. Rich Wolski of University of California at Santa
Barbara on grid platforms monitoring and characteristics discovering within the
NWS project.
</p></subsection></subsection><subsection id="uid96"><bodyTitle>Visits</bodyTitle><p>From january to july 2006, Emmanuel Jeannot spent 6 month at the University of Tennessee
under the NSF-INRIA Grant described above.</p></subsection></international><diffusion id="uid97"><bodyTitle>Dissemination</bodyTitle><subsection id="uid98"><bodyTitle>Dissemination</bodyTitle><subsection id="uid99"><bodyTitle>Leadership within the Scientific Community</bodyTitle><p>Jens Gustedt is elected member of
<span class="smallcap" align="left">INRIA</span><ref xlink:href="http://www.inria.fr/inria/organigramme/cs.en.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2629645972006">scientific
board</ref>.</p><p>Emmanuel Jeannot is member of the steering committee of the
GRID'5000 project and head of the Nancy site. Martin Quinson is serving
as vice-head for the Grid'5000 project.</p></subsection><subsection id="uid100"><bodyTitle>Scientific Expertise</bodyTitle><p>In 2006, Jens Gustedt was a member of the thesis committee of
Timothée Bossart, University Paris 6 and has served as an external
expert for the evaluation of scientific projects in regional
initiatives for information science and technology in a neighboring
European country.</p></subsection><subsection id="uid101"><bodyTitle>Teaching Activities</bodyTitle><p>Frédéric Suter is teaching <i>Algorithmique et
programmation</i> (L1), <i>Réseaux et Internet</i> (M2Pro-IMOI)
and <i>Grilles informatiques et algorithmique distribuée
avancée</i> at Henri Poincaré University.</p><p>Martin Quinson is teaching the following modules at ÉSIAL (University
Henri Poincaré): <i>C et Shell</i> (1A), <i>Réseaux et
système</i> (2A) and <i>Programmation d'applications réparties</i>
(3A) (third year). He also participates to the following modules:
<i>Informatique de base</i> (1A), <i>Algorithmique Parallèle et
Distribuée</i> (3A) and <i>Grilles informatiques et algorithmique
distribuée avancée</i> at Henri Poincaré University. He is also
responsible of the specialization <i>Système et Applications
Distribués</i> of ÉSIAL.</p><p>Luiz Angelo Steffenel is teaching the following modules at IUT Nancy Charlemagne (Nancy 2 University):
<i>Introduction à l'Algorithmique</i> (DUT 1A), <i>Bases de la Programmation - Java</i> (DUT 1A),
<i>Systèmes de Gestion de Bases de Données</i> (DUT 2A), <i>Architecture 1</i> (DUT 1A Bis),
<i>Administration de Systèmes de Gestion de Bases de Données</i> (DUT AS). He also participated
to the following modules at the UFR Mathématique et Informatique (Nancy 2 University):
<i>Programmation C Avancée</i> (MIAGE 3A), <i>Certificat C2I</i> (1A).</p></subsection><subsection id="uid102"><bodyTitle>Editorial Activities</bodyTitle><p>Since October 2001, Jens Gustedt is Editor-in-Chief of the journal
<i>Discrete Mathematics and Theoretical Computer Science</i>
(<ref xlink:href="http://www.dmtcs.org/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1299762262019">DMTCS</ref>). DMTCS is an
journal that is published electronically by an independent association
under French law. Based on a contract with <span class="smallcap" align="left">INRIA</span>, its main web-server
is located at the <span class="smallcap" align="left">LORIA</span>. DMTCS has acquired a good visibility within
the concerned domains of Computer Science and Mathematics. In 2006,
in addition to its journal activities DMTCS has published two
conference proceedings.</p><p>In 2006, Jens Gustedt has served as program committee member of
the 2006 International Conference on Parallel Processing
<ref xlink:href="http://www.cse.ohio-state.edu/~icpp2006/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="246767126031">ICPP '06</ref>
and for the special volume of <i>Parallel Computing</i> on large scale
grids.</p><p>Emmanuel Jeannot, Jens Gustedt and Stéphane Vialle have been members
of the program committee of <ref xlink:href="http://www.renpar.org/renpar.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="594720555009">RenPar 2006 (17ème
rencontre du paraléllisme)</ref>.</p></subsection><subsection id="uid103"><bodyTitle>Refereeing</bodyTitle><p>In 2006, members of the team served as referees for the following
journals and conferences:</p><descriptionlist><label>Journals:</label><li id="uid104"><p>Advances in Engineering Software and Computer and Structures Journal
Discrete Applied Mathematics,
IEICE transactions,
IEEE Transactions on Parallel and Distributed Systems,
International Journal of High Performance Computing,
Journal of Parallel Distributed Computing,
Parallel Computing,
Journal of Scientific Programming</p></li><label>Conferences:</label><li id="uid105"><p>CARI 2006,
e-Science 2006 EuroPar 2006,
HCW 2007,
ICON 2006,
ICPP 2006,
IPDPS 2006,
RenPar 2006,
SIMS 2006</p></li></descriptionlist></subsection></subsection></diffusion><biblio id="bibliography" html="bibliography" titre="Bibliography" numero="10"><biblStruct id="bid45" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">New Dynamic Heuristics in the Client-Agent-Server Model</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Yves</foreName><surname full="yes" TEIform="surname">Caniou</surname><initial>Y.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Emmanuel</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">IEEE Heterogeneous Computing Workshop - HCW'03, Nice, France</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">April</month><year full="yes" TEIform="year">2003</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:caniou03a</note></biblStruct><biblStruct id="bid9" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Out-of-Core and Pipeline Techniques for Wavefront Algorithms</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Eddy</foreName><surname full="yes" TEIform="surname">Caron</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Desprez</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Suter</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the 19th International Parallel and Distributed Processing Symposium (IPDPS'05), Denver, CO</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">April</month><year full="yes" TEIform="year">2005</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:CDS05</note></biblStruct><biblStruct id="bid47" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Parallel Extension of a Dynamic Performance Forecasting Tool</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Eddy</foreName><surname full="yes" TEIform="surname">Caron</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Suter</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Accepted for publication in Parallel and Distributed Computing Practice (PDCP)</title><note type="bnote" place="unspecified" anchored="yes">Special issue on selected papers of ISPDC'02</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2004</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:CS04</note></biblStruct><biblStruct id="bid10" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">From Heterogeneous Task Scheduling to Heterogeneous Mixed Parallel Scheduling</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Henri</foreName><surname full="yes" TEIform="surname">Casanova</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Desprez</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Suter</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><editor role="editor" TEIform="editor"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Marco</foreName><surname full="yes" TEIform="surname">Danelutto</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Domenico</foreName><surname full="yes" TEIform="surname">Laforenza</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Marco</foreName><surname full="yes" TEIform="surname">Vanneschi</surname><initial>M.</initial></persName></editor><title level="m" TEIform="title">Proceedings of the 10th International Euro-Par Conference (Euro-Par'04), Pisa, Italy</title><title level="s" TEIform="title">Lecture Notes in Computer Science</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">3149</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">August/September</month><year full="yes" TEIform="year">2004</year></dateStruct><biblScope type="pages" TEIform="biblScope">230–237</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:CDS04</note></biblStruct><biblStruct id="bid46" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Messages Scheduling for Data Redistribution between Clusters</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Johanne</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Emmanuel</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Nicolas</foreName><surname full="yes" TEIform="surname">Padoy</surname><initial>N.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Algorithms, models and tools for parallel computing on heterogeneous network - HeteroPar'03, workshop of SIAM PPAM 2003, Czestochowa, Poland</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">September</month><year full="yes" TEIform="year">2003</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:cohen03b</note></biblStruct><biblStruct id="bid3" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">PRO: A Model for the Design and Analysis of Efficient and Scalable Parallel Algorithms</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Assefaw</foreName><surname full="yes" TEIform="surname">Gebremedhin</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Isabelle</foreName><surname full="yes" TEIform="surname">Guérin Lassous</surname><initial>I.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jan Arne</foreName><surname full="yes" TEIform="surname">Telle</surname><initial>J. A.</initial></persName></author><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2005</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00000899/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2334643323020">http://hal.inria.fr/inria-00000899/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">misc</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:GEBREMEDHIN:2005:50425</note></biblStruct><biblStruct id="bid8" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Towards Realistic Implementations of External Memory Algorithms using a Coarse Grained Paradigm</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">International Conference on Computer Science and its Applications - ICCSA'2003, Montréal, Canada</title><title level="s" TEIform="title">Lecture Notes in Computer Science</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">2668</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">February</month><year full="yes" TEIform="year">2003</year></dateStruct><biblScope type="pages" TEIform="biblScope">269-278</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:gustedt03a</note></biblStruct><biblStruct id="bid4" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Data Handover: Reconciling Message Passing and Shared Memory</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Technical report</note><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">RR-5383</biblScope><publisher TEIform="publisher"><orgName type="institution" TEIform="orgName">INRIA</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Nov</month><year full="yes" TEIform="year">2004</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00070620" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2410383177031">http://hal.inria.fr/inria-00070620</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">techreport</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:gustedt04a</note></biblStruct><biblStruct id="bid5" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A work-optimal coarse-grained PRAM algorithm for Lexicographically First Maximal Independent Set</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jan Arne</foreName><surname full="yes" TEIform="surname">Telle</surname><initial>J. A.</initial></persName></author></analytic><monogr TEIform="monogr"><editor role="editor" TEIform="editor"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Carlo</foreName><surname full="yes" TEIform="surname">Blundo</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Cosimo</foreName><surname full="yes" TEIform="surname">Laneve</surname><initial>C.</initial></persName></editor><title level="m" TEIform="title">Italian Conference on Theoretical Computer Science - ICTCS'03, Bertinoro, Italy</title><title level="s" TEIform="title">Lecture notes in Computer Science</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">2841</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer</orgName></publisher><publisher TEIform="publisher"><orgName type="organisation" TEIform="orgName">EATCS</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">October</month><year full="yes" TEIform="year">2003</year></dateStruct><biblScope type="pages" TEIform="biblScope">125-136</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:gustedt03c</note></biblStruct><biblStruct id="bid44" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Improving Middleware Performance with AdOC: an Adaptive Online Compression Library for Data Transfer</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">International Parallel and Distributed Processing Symposium 2005 (IPDPS'05), Denver, Colorado, USA</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">April</month><year full="yes" TEIform="year">2005</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:j05</note></biblStruct><biblStruct id="bid43" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Adaptive Online Data Compression</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Emmanuel</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Bjorn</foreName><surname full="yes" TEIform="surname">Knuttson</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Mats</foreName><surname full="yes" TEIform="surname">Bjorkman</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Eleventh IEEE International Symposium on High Performance Distributed Computing - HPDC 11, Edinburgh, Scotland</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">July</month><year full="yes" TEIform="year">2002</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:jeannot02a</note></biblStruct><biblStruct id="bid48" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Two fast and efficient message scheduling algorithms for data redistribution through a backbone</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Emmanuel</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Wagner</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">18th International Parallel and Distributed Processing Symposium - IPDPS'04, Santa Fe, New Mexico</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Apr</month><year full="yes" TEIform="year">2004</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:jeannot04a</note></biblStruct><biblStruct id="bid49" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Scheduling Heuristics for Efficient Broadcast Operations on Grid Environments</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Luiz Angelo</foreName><surname full="yes" TEIform="surname">Steffenel</surname><initial>L. A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Grégory</foreName><surname full="yes" TEIform="surname">Mounié</surname><initial>G.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the Performance Modeling, Evaluation and Optimization of Parallel and Distributed Systems Workshop - PMEO'06 (associated to IPDPS'06), Rhodes Island, Greece</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE Computer Society</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Apr</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.archives-ouvertes.fr/hal-00022008" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="611538626007">http://hal.archives-ouvertes.fr/hal-00022008</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:Barchet06a</note></biblStruct><biblStruct id="bid21" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">LaPIe: communications collectives adaptées aux grilles de calcul</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Luiz Angelo</foreName><surname full="yes" TEIform="surname">Steffenel</surname><initial>L. A.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Ph. D. Thesis</note><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName type="school" TEIform="orgName">INPG, France</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2005</year></dateStruct><ref xlink:href="http://tel.ccsd.cnrs.fr/tel-00011603" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3159878748028">http://tel.ccsd.cnrs.fr/tel-00011603</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">phdthesis</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:Barchet05c</note></biblStruct><biblStruct id="bid50" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Modeling Network Contention Effects on AlltoAll Operations</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Luiz Angelo</foreName><surname full="yes" TEIform="surname">Steffenel</surname><initial>L. A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the IEEE Conference on Cluster Computing (CLUSTER 2006), Barcelona, Spain</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE Computer Society</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Sep</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.archives-ouvertes.fr/hal-00089242" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1566131350019">http://hal.archives-ouvertes.fr/hal-00089242</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:Steffenel06b</note></biblStruct><biblStruct id="bid32" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">On the Distribution of Sequential Jobs in Random Brokering For Heterogeneous Computational Grids</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">V.</foreName><surname full="yes" TEIform="surname">Berten</surname><initial>V.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Goossens</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">IEEE Transactions on Parallel and Distributed Systems</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">17</biblScope><biblScope type="number" TEIform="biblScope">2</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">113–124</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:bgj06a</note></biblStruct><biblStruct id="bid25" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Grid'5000: A Large Scale And Highly Reconfigurable Experimental Grid Testbed</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Raphaël</foreName><surname full="yes" TEIform="surname">Bolze</surname><initial>R.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Franck</foreName><surname full="yes" TEIform="surname">Cappello</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Eddy</foreName><surname full="yes" TEIform="surname">Caron</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Michel</foreName><surname full="yes" TEIform="surname">Daydé</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Desprez</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Emmanuel</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Yvon</foreName><surname full="yes" TEIform="surname">Jégou</surname><initial>Y.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Stephane</foreName><surname full="yes" TEIform="surname">Lanteri</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Julien</foreName><surname full="yes" TEIform="surname">Leduc</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Noredine</foreName><surname full="yes" TEIform="surname">Melab</surname><initial>N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Guillaume</foreName><surname full="yes" TEIform="surname">Mornet</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Raymond</foreName><surname full="yes" TEIform="surname">Namyst</surname><initial>R.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Pascale</foreName><surname full="yes" TEIform="surname">Primet</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Benjamin</foreName><surname full="yes" TEIform="surname">Quetier</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Richard</surname><initial>O.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">El-Ghazali</foreName><surname full="yes" TEIform="surname">Talbi</surname><initial>E.-G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Iréa</foreName><surname full="yes" TEIform="surname">Touche</surname><initial>I.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">International Journal of High Performance Computing Applications</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">20</biblScope><biblScope type="number" TEIform="biblScope">4</biblScope><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">November</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">481–494</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:bcc+06</note></biblStruct><biblStruct id="bid36" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Multi-Criteria Scheduling Heuristics for GridRPC Systems</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Y.</foreName><surname full="yes" TEIform="surname">Caniou</surname><initial>Y.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">International Journal of High Performance Computing Applications</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">20</biblScope><biblScope type="number" TEIform="biblScope">1</biblScope><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">spring</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">61–76</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:cj06b</note></biblStruct><biblStruct id="bid27" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Message Scheduling for Parallel Data Redistribution between Clusters</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">N.</foreName><surname full="yes" TEIform="surname">Padoy</surname><initial>N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Wagner</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">IEEE Transactions on Parallel and Distributed Systems</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">17</biblScope><biblScope type="number" TEIform="biblScope">10</biblScope><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">October</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">1163–1175</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:cjpw06</note></biblStruct><biblStruct id="bid14" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Efficient Sampling of Random Permutations</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">J. on Discrete Algorithms</title><note type="bnote" place="unspecified" anchored="yes">accepted</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00000900/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="318870215025">http://hal.inria.fr/inria-00000900/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:GUSTEDT:2005:INRIA-00000900:2</note></biblStruct><biblStruct id="bid35" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Scheduling Messages for Data Redistribution: an Experimental Study</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Wagner</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">International Journal of High Performance Computing Applications</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">20</biblScope><biblScope type="number" TEIform="biblScope">4</biblScope><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">November</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">443–454</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:jw06b</note></biblStruct><biblStruct id="bid33" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A Probabilistic Approach for Fault Tolerant Multiprocessor Real-time Scheduling</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">V.</foreName><surname full="yes" TEIform="surname">Berten</surname><initial>V.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Goossens</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">14th Workshop on Parallel and Distributed Real-Time Systems, Island of Rhodes, Greece</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">April</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:bgj06b</note></biblStruct><biblStruct id="bid26" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Wrekavoc a Tool for Hemulating Heterogeneity</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">L.-C.</foreName><surname full="yes" TEIform="surname">Canon</surname><initial>L.-C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">15th IEEE Heterogeneous Computing Workshop (HCW'06), Island of Rhodes, Greece</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">April</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:cj06a</note></biblStruct><biblStruct id="bid37" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">The SIMGRID Project: Simulation and Deployment of Distributed Applications</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Henri</foreName><surname full="yes" TEIform="surname">Casanova</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Kayo</foreName><surname full="yes" TEIform="surname">Fujiwara</surname><initial>K.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Arnaud</foreName><surname full="yes" TEIform="surname">Legrand</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Martin</foreName><surname full="yes" TEIform="surname">Quinson</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">The 15th IEEE International Symposium on High Performance Distributed Computing (HPDC'06)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00108428" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3241760392025">http://hal.inria.fr/inria-00108428</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:cflq_hpdc06</note></biblStruct><biblStruct id="bid12" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">An experimental validation of the PRO model for parallel and distributed computation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Mohamed</foreName><surname full="yes" TEIform="surname">Essaïdi</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName></author></analytic><monogr TEIform="monogr"><editor role="editor" TEIform="editor"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Beniamino Di</foreName><surname full="yes" TEIform="surname">Martino</surname><initial>B. D.</initial></persName></editor><title level="m" TEIform="title">14th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP 2006), 15/02/2006, Montbeliard-Sochaux, France</title><title level="s" TEIform="title">in: IEEE CS, 14th Euromicro International Conference on Parallel, Distributed and Network based Processing</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">449-456</biblScope><ref xlink:href="http://hal.inria.fr/inria-00000612/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="490259530021">http://hal.inria.fr/inria-00000612/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:ESSAIDI:2006:INRIA-00000612:1</note></biblStruct><biblStruct id="bid13" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Bounded Arboricity to Determine the Local Structure of Sparse Graphs</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Gaurav</foreName><surname full="yes" TEIform="surname">Goel</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">32 International Workshop on Graph-Theoretic Concepts in Computer Science - WG 2006, 21/06/2006, Bergen, Norway</title><title level="s" TEIform="title">in: Lecture Notes in Computer Science, Graph-Theoretic Concepts in Computer Science 32nd International Workshop, WG 2006, Bergen, Norway, June 22-24, 2006 Revised Papers</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">4271</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">159-167</biblScope><ref xlink:href="http://hal.inria.fr/inria-00103755/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="399246102026">http://hal.inria.fr/inria-00103755/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:GOEL:2006:INRIA-00103755:1</note></biblStruct><biblStruct id="bid11" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">parXXL: A Fine Grained Development Environment on Coarse Grained Architectures</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Stéphane</foreName><surname full="yes" TEIform="surname">Vialle</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Amelia</foreName><surname full="yes" TEIform="surname">De Vivo</surname><initial>A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Workshop on State-of-the-Art in Scientific and Parallel Computing - PARA'06, Umeå, Sweden</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00103772/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2933359618001">http://hal.inria.fr/inria-00103772/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:GUSTEDT:2006:INRIA-00103772:1</note></biblStruct><biblStruct id="bid29" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A Practical Approach of Diffusion Load Balancing Algorithm</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Vernier</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">12th International Euro-Par Conference, Dresden, Germany</title><title level="s" TEIform="title">LNCS</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">4128</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer Verlag</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">August</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">211–221</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:jv06b</note></biblStruct><biblStruct id="bid34" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Modeling, Predicting and Optimizing Redistribution between Clusters on Low Latency Networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Wagner</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">The First International Symposium on Frontiers in Networking with Applications (FINA 2006), Vienna, Austria</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">April</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:jw06a</note></biblStruct><biblStruct id="bid18" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Algorithmes d'ordonnancement de graphes de tâches parallèles sur plates-formes hétérogènes</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Tchimou</foreName><surname full="yes" TEIform="surname">N'Takpé</surname><initial>T.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Dix-septièmes Rencontres Francophones du Parallélisme (RenPar'17), Perpignan</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Oct</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:TNT06</note></biblStruct><biblStruct id="bid17" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Critical Path and Area Based Scheduling of Parallel Task Graphs on Heterogeneous Platforms</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Tchimou</foreName><surname full="yes" TEIform="surname">N'Takpé</surname><initial>T.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Suter</surname><initial>F.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the Twelfth International Conference on Parallel and Distributed Systems (ICPADS), Minneapolis, MN</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">July</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:NS06</note></biblStruct><biblStruct id="bid38" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">GRAS: a Research and Development Framework for Grid and P2P Infrastructures</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Martin</foreName><surname full="yes" TEIform="surname">Quinson</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><editor role="editor" TEIform="editor"><persName TEIform="persName"><foreName full="yes" TEIform="foreName"/><surname full="yes" TEIform="surname">IASTED</surname><initial/></persName></editor><title level="m" TEIform="title">The 18th IASTED International Conference on Parallel and Distributed Computing and Systems</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00108389" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="309314961000">http://hal.inria.fr/inria-00108389</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:q_pdcs06</note></biblStruct><biblStruct id="bid31" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Robust Task Scheduling in Non-Deterministic Heterogeneous Systems</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Z.</foreName><surname full="yes" TEIform="surname">Shi</surname><initial>Z.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J. J.</foreName><surname full="yes" TEIform="surname">Dongarra</surname><initial>J. J.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of IEEE International Conference on Cluster Computing, Barcelona, Spain</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">October</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:sjd06</note></biblStruct><biblStruct id="bid39" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Scheduling Heuristics for Efficient Broadcast Operations on Grid Environments</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Luiz Angelo</foreName><surname full="yes" TEIform="surname">Steffenel</surname><initial>L. A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Gréory</foreName><surname full="yes" TEIform="surname">Mounié</surname><initial>G.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the Performance Modeling, Evaluation and Optimization of Parallel and Distributed Systems Workshop - PMEO'06 (associated to IPDPS'06), Rhodes Island, Greece</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE Computer Society</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">4</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.archives-ouvertes.fr/hal-00022008" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="611538626007">http://hal.archives-ouvertes.fr/hal-00022008</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Steffenel06a</note></biblStruct><biblStruct id="bid20" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Modeling Network Contention Effects on AlltoAll Operations</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Luiz Angelo</foreName><surname full="yes" TEIform="surname">Steffenel</surname><initial>L. A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the IEEE Conference on Cluster Computing (CLUSTER 2006), Barcelona, Spain</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE Computer Society</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">9</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.archives-ouvertes.fr/hal-00089242" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1566131350019">http://hal.archives-ouvertes.fr/hal-00089242</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Steffenel06b</note></biblStruct><biblStruct id="bid30" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">A Practical Approach of Diffusion Load Balancing Algorithms</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Emmanuel</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Flavien</foreName><surname full="yes" TEIform="surname">Vernier</surname><initial>F.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Research Report</note><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">5875</biblScope><publisher TEIform="publisher"><orgName type="institution" TEIform="orgName">INRIA</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">March</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00071394" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2160241014003">http://hal.inria.fr/inria-00071394</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">techreport</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:jv06a</note></biblStruct><biblStruct id="bid40" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">A Framework for Adaptive Collective Communications on Heterogeneous Hierarchical Networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Luiz Angelo</foreName><surname full="yes" TEIform="surname">Steffenel</surname><initial>L. A.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Research Report</note><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">6036</biblScope><publisher TEIform="publisher"><orgName type="institution" TEIform="orgName">INRIA</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">11</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="https://hal.inria.fr/inria-00116897" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink">https://hal.inria.fr/inria-00116897</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">techreport</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Steffenel06c</note></biblStruct><biblStruct id="bid41" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Fast and Scalable Total Order Broadcast for Wide-area Networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Luiz Angelo</foreName><surname full="yes" TEIform="surname">Steffenel</surname><initial>L. A.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Research Report</note><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">6037</biblScope><publisher TEIform="publisher"><orgName type="institution" TEIform="orgName">INRIA</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">11</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="https://hal.inria.fr/inria-00116895" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink">https://hal.inria.fr/inria-00116895</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">techreport</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Steffenel06d</note></biblStruct><biblStruct id="bid42" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Modelling Network Contention Effects on All-to-All Operations</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Luiz Angelo</foreName><surname full="yes" TEIform="surname">Steffenel</surname><initial>L. A.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Research Report</note><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">6038</biblScope><publisher TEIform="publisher"><orgName type="institution" TEIform="orgName">INRIA</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">11</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="https://hal.inria.fr/inria-00116891" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink">https://hal.inria.fr/inria-00116891</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">techreport</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Steffenel06e</note></biblStruct><biblStruct id="bid15" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Algorithme à front d'onde et pipeline out-of-core sur architecture à mémoire partagée</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Pierre-Nicolas</foreName><surname full="yes" TEIform="surname">Clauss</surname><initial>P.-N.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Technical report</note><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName type="school" TEIform="orgName">Université Henri Poincaré - Nancy I</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">masterthesis</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Claus:2006:master</note></biblStruct><biblStruct id="bid16" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Optimized Data Layout for Architecture Independant Implementation of an Out-of-core Wavefront Algorithm</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Pierre-Nicolas</foreName><surname full="yes" TEIform="surname">Clauss</surname><initial>P.-N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jens</foreName><surname full="yes" TEIform="surname">Gustedt</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frédéric</foreName><surname full="yes" TEIform="surname">Suter</surname><initial>F.</initial></persName></author><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">unpublished</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Claus:2006:preprint</note></biblStruct><biblStruct id="bid28" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Modeling the LU Factorization for SMP Clusters</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jack J.</foreName><surname full="yes" TEIform="surname">Dongarra</surname><initial>J. J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Emmanuel</foreName><surname full="yes" TEIform="surname">Jeannot</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Julien</foreName><surname full="yes" TEIform="surname">Langou</surname><initial>J.</initial></persName></author><note type="bnote" place="unspecified" anchored="yes">Presented at 4th International Workshop on Parallel Matrix Algorithms and Applications (PMAA 06)</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">September</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">misc</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:djl06</note></biblStruct><biblStruct id="bid24" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Etude comparative des algorithmes de découverte de la topologie de la grille</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Ahmed</foreName><surname full="yes" TEIform="surname">Harbaoui</surname><initial>A.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Technical report</note><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName type="school" TEIform="orgName">LORIA</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">masterthesis</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:harbaoui_master06</note></biblStruct><biblStruct id="bid22" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Scheduling Distributed Applications: the SimGrid Simulation Framework</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Casanova</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">A.</foreName><surname full="yes" TEIform="surname">Legand</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">L.</foreName><surname full="yes" TEIform="surname">Marchal</surname><initial>L.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the third IEEE International Symposium on Cluster Computing and the Grid (CCGrid'03)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">may</month><year full="yes" TEIform="year">2003</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:simgrid03</note></biblStruct><biblStruct id="bid6" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A Bridging Model for Parallel Computation, Communication, and I/O</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Thomas H.</foreName><surname full="yes" TEIform="surname">Cormen</surname><initial>T. H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Michael T.</foreName><surname full="yes" TEIform="surname">Goodrich</surname><initial>M. T.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">ACM Computing Surveys</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">28A</biblScope><biblScope type="number" TEIform="biblScope">4</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1996</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:cormen96:bridgmodelparalcomputcommunio</note></biblStruct><biblStruct id="bid1" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">LogP: Towards a Realistic Model of Parallel Computation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Culler</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">R.</foreName><surname full="yes" TEIform="surname">Karp</surname><initial>R.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Patterson</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">A.</foreName><surname full="yes" TEIform="surname">Sahay</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">K.E.</foreName><surname full="yes" TEIform="surname">Schauser</surname><initial>K.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Santos</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">R.</foreName><surname full="yes" TEIform="surname">Subramonian</surname><initial>R.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">T.</foreName><surname full="yes" TEIform="surname">von Eicken</surname><initial>T.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceeding of 4-th ACM SIGPLAN Symp. on Principles and Practises of Parallel Programming</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1993</year></dateStruct><biblScope type="pages" TEIform="biblScope">1-12</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:LogP</note></biblStruct><biblStruct id="bid7" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Efficient external memory algorithms by simulating coarsegrained parallel algorithms</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Dehne</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">W.</foreName><surname full="yes" TEIform="surname">Dittrich</surname><initial>W.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Hutchinson</surname><initial>D.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">ACM Symposium on Parallel Algorithms and Architectures</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1997</year></dateStruct><biblScope type="pages" TEIform="biblScope">106-115</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:dehne97efficient</note></biblStruct><biblStruct id="bid2" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Scalable parallel computational geometry for coarse grained multicomputers</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Dehne</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">A.</foreName><surname full="yes" TEIform="surname">Fabri</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">A.</foreName><surname full="yes" TEIform="surname">Rau-Chaplin</surname><initial>A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">International Journal on Computational Geometry</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">6</biblScope><biblScope type="number" TEIform="biblScope">3</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1996</year></dateStruct><biblScope type="pages" TEIform="biblScope">379-400</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:DehneFRC96</note></biblStruct><biblStruct id="bid19" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">PEMPIs: A New Metodology for Modeling and Prediction of MPI Programs Performance</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Edson T.</foreName><surname full="yes" TEIform="surname">Midorikawa</surname><initial>E. T.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Helio M.</foreName><surname full="yes" TEIform="surname">Oliveira</surname><initial>H. M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jean M.</foreName><surname full="yes" TEIform="surname">Laine</surname><initial>J. M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the SBAC-PAD 2004</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE Computer Society/Brasilian Computer Society</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2004</year></dateStruct><biblScope type="pages" TEIform="biblScope">254–261</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Midorikawa04</note></biblStruct><biblStruct id="bid0" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A bridging model for parallel computation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Leslie G.</foreName><surname full="yes" TEIform="surname">Valiant</surname><initial>L. G.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Communications of the ACM</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">33</biblScope><biblScope type="number" TEIform="biblScope">8</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1990</year></dateStruct><biblScope type="pages" TEIform="biblScope">103-111</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Valiant90</note></biblStruct><biblStruct id="bid23" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">The NWS: A Distributed Resource Performance Forecasting Service for Metacomputing</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">R.</foreName><surname full="yes" TEIform="surname">Wolski</surname><initial>R.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">N.</foreName><surname full="yes" TEIform="surname">Spring</surname><initial>N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Hayes</surname><initial>J.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Future Generation Computing Systems, Metacomputing Issue</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">15</biblScope><biblScope type="number" TEIform="biblScope">5–6</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1999</year></dateStruct><biblScope type="pages" TEIform="biblScope">757–768</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:nws</note></biblStruct></biblio></raweb>