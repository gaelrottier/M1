<?xml version="1.0" encoding="UTF-8"?>
<raweb xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="en" year="2006"><identification id="alchemy" isproject="false"><shortname>Alchemy</shortname><projectName>Architectures, Languages and Compilers to Harness the End of Moore Years</projectName><theme>COM</theme><team id="uid1"><participants category="Head_of_project_team"><person><firstname>Olivier</firstname><lastname>Temam</lastname><affiliation>INRIA</affiliation><categoryPro>Chercheur</categoryPro><moreinfo>Research
Director (DR) Inria</moreinfo><hdr>oui</hdr></person></participants><participants category="Administrative_assistants"><person><firstname>Stéphanie</firstname><lastname>Meunier</lastname><affiliation>INRIA</affiliation><categoryPro>Assistant</categoryPro><moreinfo>TR Inria, with Gemo</moreinfo></person></participants><participants category="Staff_members,_Inria"><person><firstname>Hugues</firstname><lastname>Berry</lastname><affiliation>INRIA</affiliation><categoryPro>Chercheur</categoryPro><moreinfo>Research Associate (CR) Inria, on secondment from
the Cergy-Pontoise University until september, 2006, then CR1 since
october 2006</moreinfo></person><person><firstname>Albert</firstname><lastname>Cohen</lastname><affiliation>INRIA</affiliation><categoryPro>Chercheur</categoryPro><moreinfo>Research Associate (CR) Inria</moreinfo></person><person><firstname>Christine</firstname><lastname>Eisenbeis</lastname><affiliation>INRIA</affiliation><categoryPro>Chercheur</categoryPro><moreinfo>Research Director (DR) Inria</moreinfo></person><person><firstname>Grigori</firstname><lastname>Fursin</lastname><affiliation>INRIA</affiliation><categoryPro>PostDoc</categoryPro><moreinfo>Postdoctoral Fellow</moreinfo></person></participants><participants category="Staff_members,_Paris-11_University"><person><firstname>Cédric</firstname><lastname>Bastoul</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>Assistant Professor</moreinfo></person><person><firstname>Frédéric</firstname><lastname>Gruau</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>Assistant Professor</moreinfo></person></participants><participants category="Technical_staff"><person><firstname>Hamid</firstname><lastname>Daoud</lastname><affiliation>INRIA</affiliation><categoryPro>Technique</categoryPro><moreinfo>Expert engineer, FP6 IST grant</moreinfo></person><person><firstname>Sylvain</firstname><lastname>Girbal</lastname><affiliation>INRIA</affiliation><categoryPro>Technique</categoryPro><moreinfo>Expert engineer, FP6 IST Grant</moreinfo></person><person><firstname>Sebastian</firstname><lastname>Pop</lastname><affiliation>INRIA</affiliation><categoryPro>Technique</categoryPro><moreinfo>Expert engineer, since
October, 2006, Thalès (Carroll) grant</moreinfo></person></participants><participants category="Ph._D._students"><person><firstname>Mounira</firstname><lastname>Bachir</lastname><affiliation>INRIA</affiliation><categoryPro>PhD</categoryPro><moreinfo>Inria scholarship, since October,
2006,  University of Versailles-Saint-Quentin</moreinfo></person><person><firstname>Patrick</firstname><lastname>Carribault</lastname><affiliation>UnivFr</affiliation><categoryPro>PhD</categoryPro><moreinfo>Bull fellowship (Cifre),
 University of Versailles-Saint-Quentin</moreinfo></person><person><firstname>Mohamed</firstname><lastname>Fellahi</lastname><affiliation>INRIA</affiliation><categoryPro>PhD</categoryPro><moreinfo>Inria scholarship, since October,
2006, University of Paris-Sud</moreinfo></person><person><firstname>Fei</firstname><lastname>Jiang</lastname><affiliation>INRIA</affiliation><categoryPro>PhD</categoryPro><moreinfo>Inria scholarship, with the <span class="smallcap" align="left">Tao</span> Inria
team, University of Paris-Sud</moreinfo></person><person><firstname>Piotr</firstname><lastname>Lesnicki</lastname><affiliation>UnivFr</affiliation><categoryPro>PhD</categoryPro><moreinfo>MENRT scholarship, since October, 2006 University of Paris-Sud</moreinfo></person><person><firstname>Zheng</firstname><lastname>Li</lastname><affiliation>INRIA</affiliation><categoryPro>PhD</categoryPro><moreinfo>Inria scholarship, University of Paris-Sud</moreinfo></person><person><firstname>Pierre</firstname><lastname>Palatin</lastname><affiliation>CNRS</affiliation><categoryPro>PhD</categoryPro><moreinfo>CNRS BDI scholarship, University of Paris-Sud</moreinfo></person><person><firstname>Sebastian</firstname><lastname>Pop</lastname><affiliation>AutreEtablissementPublic</affiliation><categoryPro>PhD</categoryPro><moreinfo>École Nationale
Supérieure des Mines de Paris, until September, 2006</moreinfo></person><person><firstname>Louis-Noël</firstname><lastname>Pouchet</lastname><affiliation>UnivFr</affiliation><categoryPro>PhD</categoryPro><moreinfo>MENRT scholarship, since
October, 2006, University of Paris-Sud</moreinfo></person><person><firstname>Benoît</firstname><lastname>Siri</lastname><affiliation>INRIA</affiliation><categoryPro>PhD</categoryPro><moreinfo>Inria scholarship, University of Paris-Sud</moreinfo></person><person><firstname>Nicolas</firstname><lastname>Vasilache</lastname><affiliation>UnivFr</affiliation><categoryPro>PhD</categoryPro><moreinfo>MENRT scholarship, University of Paris-Sud</moreinfo></person></participants><participants category="Student_interns"><person><firstname>Hamid</firstname><lastname>Daoud</lastname><affiliation>INRIA</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>Master of computer science,
Paris-13 University,
March to September, 2006</moreinfo></person><person><firstname>Frédéric</firstname><lastname>De Mesmay</lastname><affiliation>AutreEtablissementPublic</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>École Polytechnique, March to July, 2006</moreinfo></person><person><firstname>Mohamed</firstname><lastname>Fellahi</lastname><affiliation>INRIA</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>Master of computer science, University of Paris-Sud,
March to September, 2006</moreinfo></person><person><firstname>Helena</firstname><lastname>Fulger</lastname><affiliation>AutreEtablissementPublic</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>École Polytechnique, March to July, 2006</moreinfo></person><person><firstname>Fei</firstname><lastname>Jiang</lastname><affiliation>INRIA</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>Master of computer science, University of Paris-Sud,
March to September, 2006 (with the Tao Inria team)</moreinfo></person><person><firstname>Charles-Eric</firstname><lastname>Laporte</lastname><affiliation>INRIA</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>Master Paris Centre,
March to July, 2006</moreinfo></person><person><firstname>Piotr</firstname><lastname>Lesnicki</lastname><affiliation>INRIA</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>Master of computer science, University of Paris-Sud,
March to September, 2006</moreinfo></person><person><firstname>Louis-Noël</firstname><lastname>Pouchet</lastname><affiliation>INRIA</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>Master of computer science, University of Paris-Sud,
March to September, 2006</moreinfo></person><person><firstname>Alina</firstname><lastname>Stoica</lastname><affiliation>AutreEtablissementPublic</affiliation><categoryPro>Stagiaire</categoryPro><moreinfo>École Polytechnique, March to July, 2006</moreinfo></person></participants><participants category="External_collaborators"><person><firstname>Pierre</firstname><lastname>Amiranoff</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>PRAG, IUT d'Orsay</moreinfo></person><person><firstname>Denis</firstname><lastname>Barthou</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>Assistant professor,  University of Versailles-Saint-Quentin</moreinfo></person><person><firstname>Benjamin</firstname><lastname>Dauvergne</lastname><affiliation>INRIA</affiliation><categoryPro>PhD</categoryPro><moreinfo>PhD student, Tropics project-team, Inria Sophia-Antipolis</moreinfo></person><person><firstname>Sébastien</firstname><lastname>Donadio</lastname><affiliation>UnivFr</affiliation><categoryPro>PhD</categoryPro><moreinfo>PhD student,  University of Versailles-Saint-Quentin</moreinfo></person><person><firstname>Nathalie</firstname><lastname>Drach</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>Professor, Paris-6 University</moreinfo></person><person><firstname>Sid-Ahmed-Ali</firstname><lastname>Touati</lastname><affiliation>UnivFr</affiliation><categoryPro>Enseignant</categoryPro><moreinfo>Assistant professor,  University of Versailles-Saint-Quentin</moreinfo></person></participants></team><UR name="Futurs"/></identification><presentation id="uid3"><bodyTitle>Overall Objectives</bodyTitle><subsection id="uid4"><bodyTitle>Overall Objectives</bodyTitle><p><span class="smallcap" align="left">Alchemy</span> is a joint Inria/University of Paris Sud research group.</p><p>The general research topics of the <span class="smallcap" align="left">Alchemy</span> group are architectures,
languages and compilers for high-performance embedded and
general-purpose processors. <span class="smallcap" align="left">Alchemy</span> investigates <i>scalable</i>
architecture and compiler/programming solutions for high-performance
general-purpose and embedded processors. <span class="smallcap" align="left">Alchemy</span> stands for
Architectures, Languages and Compilers to Harness the End of Moore
Years, referring to both the traditional processor architectures
implemented using the current photolithographic processes, and novel
architecture/language paradigms compatible with future and alternative
technologies. The current emphasis of <span class="smallcap" align="left">Alchemy</span> is on the former part,
and we are progressively increasing our efforts on the latter part.</p><p>The research goals of <span class="smallcap" align="left">Alchemy</span> span from short term to long term. The
short-term goals target existing complex processor architectures, and
thus focus on improving program performance on these architectures
(software-only techniques). The medium-term goals target the upcoming
CMPs (Chip Multi-Processors) with a large number of cores, which will
result from the now slower progression of core clock frequency due to
technological limitations. The main challenge is to take advantage of
the large number of cores for a wide range of applications,
considering that automatic parallelization techniques have not yet
proved an adequate solution. In <span class="smallcap" align="left">Alchemy</span>, we explore joint
architecture/programming paradigms as a pragmatic alternative
solution. Finally, even longer term research is conducted with the
goal of harnessing the properties of future and alternative
technologies for processing purposes.</p><p>Most of the research in <span class="smallcap" align="left">Alchemy</span> attempts to jointly consider the
hardware and software aspects, based on the premise that many of the
limitations of existing architecture and compiler techniques stem from
the lack of cooperation between architects and compiler
designers. However, <span class="smallcap" align="left">Alchemy</span> addresses the aforementioned research
goals through two different, though sometimes complementary,
approaches. One approach considers that, in spite of their complexity,
architectures and programs can still be accurately and efficiently
modeled (and optimized) using <i>analytical</i> methods. The second
approach considers the architecture/program pair already has or will
reach a complexity level that will evade analytical methods, and
explores a <i>complex systems</i> approach; the principle is to accept
that the architecture/program pair is more easily understood (and thus
optimized) based on its observed behavior rather than infered from its
known design.
</p></subsection></presentation><fondements id="uid5"><bodyTitle>Scientific Foundations</bodyTitle><subsection id="uid6"><bodyTitle>Scientific Foundations</bodyTitle><p>In the sections below, the different research activities of Alchemy
are described, from short-term to long-term goals. For most of the goals,
both analytical and complex systems approaches are
conducted.</p><subsection id="uid7"><bodyTitle>A practical approach to program optimizations for complex
architectures</bodyTitle><p>This part of our research work is more targeted at single-core
architectures but also applies to multi-cores. The rationale for this
research activity is that compilers rely on architecture models
embedded in heuristics to drive compiler optimizations and
strategy. As architecture complexity increases, such models tend to be
too simplistic, often resulting in inefficient steering of
compiler optimizations.</p><subsection id="uid8"><bodyTitle>Iterative optimization</bodyTitle><p>Our general approach consists in acknowledging that architectures are
too complex to embed reliable architecture models in compilers, and to
explore the behavior of the architecture/program pair through repeated
executions. Then, using machine-learning techniques, a model of this
behavior is infered from the observations. This approach is usually called
<i>iterative optimization</i>.</p><p>In the recent years, iterative optimization has emerged as a major
research trend, both in traditional compilation contexts and in
application-specific library generators (like ATLAS or SPIRAL). The
topic has matured significantly since the pionneering works of Mike
O'Boyle <ref xlink:href="#bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> at University of Edinburgh, UK or Keith
Cooper <ref xlink:href="#bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> at Rice University. While these research works
successfully demonstrated the performance <i>potential</i> of the
approach, they also highlighted that iterative optimization cannot
become a <i>practical</i> technique unless a number of issues are
resolved. Some of the key issues are: the size and structure of the
search space, the sensitivity to data sets, and the necessity to build
long transformation sequences.</p><p><b>Scanning a large search space.</b> Transformation parameters, the
order in which transformations are applied, and even which
transformations must be applied and how many times, all form a huge
transformation space. One of the main challenges of iterative
optimization is to rapidly converge towards an efficient, if not
optimal, point of the transformation space. Machine-Learning
techniques can help build an empirical model of the transformation
space in a simple and systematic way, only based on the observation of
transformations behavior, and then rapidly deduce the most profitable
points of the space. We are investigating how to correlate static and
dynamic program features with transformation efficiency. This approach
can speed up the convergence of the search process by one or two
orders of magnitude compared to random search <ref xlink:href="#bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p>We have also shown that by representing the impact of loop transformations
using structured encoding derived from polyhedral program representation,
it is possible to reduce the complexity of the search by several orders
of magnitude <ref xlink:href="#bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. This encoding is further described
in Section <ref xlink:href="#uid9" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p>We have also shown that it is possible to further speed up
transformation space exploration by exploring several transformations
during a single run <ref xlink:href="#bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Currently, one program
transformation is explored for each loop nest, while performance often
reaches a stable state soon after the start of the execution. We have
shown that, assuming we properly identify the phase behavior of
programs, it is possible to explore multiple transformations in each
run.</p><p><b>Data set sensitivity.</b> Iterative optimization is based on the
notion that the compiler will discover the best way to optimize a
program through repeatedly running the same program on the same data
set, trying one or a few different optimizations upon each
run. However, in reality, a user rarely needs to execute the same data set
twice. Therefore, iterative optimization is based on the implicit
assumption that the best optimization configuration found will work
<i>well</i> for <i>all data sets</i> of a program. To the best of our
knowledge, this assumption has never been thoroughly
investigated. Most studies on iterative optimization repeatedly
execute the same program/data set
pair <ref xlink:href="#bid7" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid10" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid11" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, only
recently, some studies have focused on the impact of data sets on
iterative optimizations <ref xlink:href="#bid12" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid13" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p>In order to explore the issue of data set sensitivity, we have
assembled a data set suite, of 20 data sets per benchmark, for most of
the MiBench <ref xlink:href="#bid14" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> embedded benchmarks. We have found that,
though a majority of programs exhibit stable performance across data
sets, the variability can significantly increase with many
optimizations. However, for the best optimization configurations, we
find that this variability is in fact small. Furthermore, we show that
it is possible to find a compromise configuration across data sets
which is often within 5% of the best possible optimization
configuration for most data sets, and that the iterative process can
converge in less than 20 iterations (for a population of 200
optimization configurations). Overall, the preliminary conclusion, at
least for the MiBench benchmarks, is that iterative optimization is a
fairly robust technique across data sets, which brings it one step
closer to practical usage.</p><p><b>Compositions of program transformations.</b> Compilers impose a
certain set of program transformations, an order of application and
how many times each transformation is applied. In order to explore
what are the possible gains beyond these strict constraints, we have
manually optimized kernels and benchmarks, trying to achieve the best
possible performance assuming no constraint on transformation order,
count or selection <ref xlink:href="#bid15" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid16" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. The study helped us
clarify which transformations bring the best performance improvements
in general. But the main conclusion of that study is that
surprisingly long compositions of transformations are sometimes needed
(in one case, up to 26 composed loop transformations) in order to
achieve good performance. Either because multiple issues must be
tackled simultaneously or because some transformations act as enabling
operations for other transformations.</p><p>As a result, we have started developing a framework facilitating the
composition of long transformations. This framework is based on the
polyhedral representation of program
transformations <ref xlink:href="#bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. This framework also enables a
more analytical approach to program optimization and parallelization,
beyond the simple composition of transformations. This latter part is
further developed in Section <ref xlink:href="#uid9" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p><b>Putting it all together: continuous optimization.</b> Increasingly,
we are now moving toward automatizing the whole iterative optimization
process. Our goal is to bring together, within a single software
environment, the different aforementioned observations and techniques
(search space techniques, data set sensitivity properties, long
compositions of transformations,...). We are currently in the
process of plugging these different techniques within GCC in order to
create a tool capable of doing continuous, whole-program optimization,
and even collaborative optimization across different users.</p><p><b>Hardware-Oriented applications of iterative optimization.</b>
Because iterative optimization can successfully capture complex
dynamic/run-time phenomena, we have shown that the approach can act as
a replacement for costly hardware structures designed to improve the
run-time behavior of programs, such as out-of-order execution in
superscalar processors. An iterative optimization-like strategy
applied to an embedded VLIW processor <ref xlink:href="#bid18" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> was shown
to achieve almost the same performance as if the processor was fitted
with dynamic instruction reordering support. We are also
investigating applications of this approach to the
specialization/idiomization of general-purpose and embedded
processors <ref xlink:href="#bid19" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Currently, we are exploring
similar approaches for providing thread scheduling and placement
information for CMPs without requiring costly run-time environement
overhead or hardware support. This latter study is related to the work presented
in Section <ref xlink:href="#uid10" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p><span class="smallcap" align="left">Current activities:</span> IST STREP MilePost, FET IP SARC, MEDEA+ ITEA
GGCC, IST NoE HiPEAC, RNTL COP.</p><p><span class="smallcap" align="left">Current people:</span> Albert Cohen, Patrick Carribault, Grigori
Fursin, Sylvain Girbal, Piotr Lesnicki, Louis-Noël Pouchet, Olivier
Temam, Nicolas Vasilache.</p></subsection><subsection id="uid9"><bodyTitle>Polyhedral program representation: facilitating the
analysis and transformation of programs</bodyTitle><p>As loop transformations are utterly important — performancewise —
and among the hardest to predictably drive through static cost models,
their current support in compilers is disappointing. After decades of
experience and theoretical advances, the best compilers can miss some
of the most important loop transformations in simple numerical codes
from linear algebra or signal processing codes. Performance hits of
more than an order of magnitude are not uncommon on single-threaded
code, and the situation worsens when automatically parallelizing or
optimizing parallel code.</p><p>Our previous work on sequences of loop transformations
<ref xlink:href="#bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> has led to the design of a theoretical
framework, based on the polyhedral model
<ref xlink:href="#bid20" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid21" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid22" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid23" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid24" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid25" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, and a set of tools based on
the advanced Open64 compiler. We have shown that this framework does
simplify the problem of building complex transformation sequences, but
also that it scales to real-world benchmarks <ref xlink:href="#bid26" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid27" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid28" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid29" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, and allows to
significantly reduce the size of the search space and better
understand its structure <ref xlink:href="#bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. The latter work, for
example, is the first attempt at directly characterizing all
<i>legal and distinct</i> ways to reschedule a loop nest.</p><p>After two decades of academic research, the polyhedral model is
finally evolving into a mature, production-ready approach to solve the
challenges of maximizing the scalability and efficiency of
statically-controlled, loop-based computations on a variety of high
performance and embedded targets. After Open64, we are now porting these
techniques to the GCC compiler <ref xlink:href="#bid30" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, applying
them to several multi-level parallelization and optimization problems,
including vectorization, extraction and exploitation of thread-level
parallelism on distributed memory CMPs like the Cell broadband engine
from IBM, NXP's CAT-DI scalable signal-processing accelerator and
novel STMicroelectronics emerging xStream architecture.</p><p><span class="smallcap" align="left">Current activities:</span> IST STREP ACOTES, ANR CIGC PARA, RNTL COP.</p><p><span class="smallcap" align="left">Current people:</span> Cedric Bastoul, Albert Cohen, Sebastian Pop,
Louis-Noël Pouchet, Nicolas Vasilache.</p></subsection></subsection><subsection id="uid10"><bodyTitle>Joint architecture/programming approaches</bodyTitle><p>While Section <ref xlink:href="#uid7" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> is only concerned with
transforming programs for a more efficient exploitation of existing
architectures, in the longer term, researchers can assume
modifications of architectures and/or programs are possible. These
relaxed constraints allow to target the root causes of poor
architecture/program performance.</p><p>The current architecture/program model partly fails because the burden
is either excessively on the architecture (superscalar processors), or
the compiler (VLIW and now CMPs). And both compiler and architecture
optimizations often aim at program <i>reverse-engineering</i>:
compilers attempt to dig up program properties (locality, parallelism)
from the static program, while architectures attempt to retrieve them
from program run-time behavior. Now, in many cases, the user is not
only aware of these properties but may pass them effortlessly to the
architecture and the compiler provided she had the appropriate
programming support, provided the compiler would pass this information
to the architecture, and the architecture would be fitted with the
appropriate support to take advantage of them. For instance, simply
knowing that a C structure denotes a tree rather than a graph can
provide significant information for parallel execution. Such
approaches, while not fully automatic, are practical and would relieve
the complexity burden of the architecture and the compiler, while
extracting significant amounts of task-level parallelism.</p><p>In the paragraphs below we apply this approach of passing more program
semantic to the compiler and the architecture, first for
domain-specific stream-oriented programs, and then for the
parallelization of more general programs.</p><subsection id="uid11"><bodyTitle>Passing program semantics using a synchronous language for
high-performance video processing</bodyTitle><p>While we are currently investigating the aforementioned approach for
general-purpose applications, we have started with the investigation
of the specific domain of high-end video
processing. In this domain, assessing that real-time properties will
be satisfied is as important as reaching uncommon levels of compute
density on a chip. 150 giga-operations per second per Watt (on pixel
components) is the norm for current high-definition TVs, and cannot be
achieved with programmable cores at present. The future standards will
need an 8-fold increase (e.g., for 3D displays or
super-high-definition). Predictability and efficiency are the keywords
in this domain, in terms of both architecture and compiler behavior.</p><p>Our approach combines the aforementioned iterative optimization and
polyhedral modeling research with a predictability- and
efficiency-oriented parallel programming language. We focus on
warrantable (as opposed to best-effort) usage of hardware resources
with respect to real-time constraints. Therefore, this parallel
programming language must allow overhead-free generation of
tightly coupled parallel threads, interacting through dedicated
registers rather than caches, streaming data through high-bandwidth,
statically managed interconnect structures, with frequent
synchronizations (once every few cycles), and very limited memory
resources immediately available. This language also needs to support
advanced loop transformations, and its representation of concurrency
compatible with the expression of multi-level partitioning and mapping
decisions. All these conditions tend to consider a language closer to
hardware synthesis languages than general-purpose, von Neumann
oriented imperative ones <ref xlink:href="#bid31" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid32" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p>The synchronous data-flow paradigm is a natural candidate, because of
its ability to combine high-productivity in programming complex
concurrent applications (due to the determinism and compositionality
of the underlying model, a rare feature of a concurrent semantics),
direct modeling of computation/communication time, and static checking
of non-functional properties (time and resource constraints). Yet
generating low-level, tightly fused loops with maximal exposition of
fine-grain parallelism from such languages is a difficult problem, as
soon as the target processor is not the one being described by the
synchronous data-flow program, but a pre-existing target on which we
are folding an application program. The two tasks are totally
different: although the most difficult decisions are pushed back to
the programmer in the hardware synthesis case, application programmers
usually rely on the compiler to abstract away the folding of their
code in a reasonably portable fashion across a variety of targets.
This aspect of synchronous language compilation has largely been
overlooked and constitutes the main direction of our work. Another
direction lies in the description of hardware resources, at the same
level as the application being mapped and scheduled onto them; this
unified representation would allow the expression of the search space
of program transformations, and would be a necessary step to apply
incremental refinement methods (expert-driven, very popular in this
domain).</p><p>Technically, we extend the classical clock calculus (a type system) of
the <i>Lucid Synchrone</i> language, expliciting significantly more
information about the program behavior, especially when tasks must be
started and will be completed, how information flow among tasks, etc.
Our main contribution is the integration of relaxed synchronous
operators like jittering and bursty streams within synchronous bounds
<ref xlink:href="#bid33" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. This research consists in revisiting the
semantics of synchronous Kahn networks in the domain of media
streaming applications and reconfigurable parallel architectures, in
collaboration with Marc Duranton from Philips Research Eindhoven (now
NXP Semiconductors) and with Marc Pouzet from LRI and the Proval Inria
project team.</p><p><span class="smallcap" align="left">Current activities:</span> IST STREP ACOTES, Marie Curie ToK-IAP
PSYCHES.</p><p><span class="smallcap" align="left">Current people:</span> Albert Cohen, Christine Eisenbeis, Mohammed Fellahi.</p></subsection><subsection id="uid12"><bodyTitle>Passing program semantic using software components</bodyTitle><p>Beyond domain-specific and regular applications (loops and arrays),
automatic compiler-based parallelization has achieved only mixed
results on programs with complex control and data
structures <ref xlink:href="#bid34" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Writing, and especially debugging,
large parallel programs is a notoriously difficult
task <ref xlink:href="#bid35" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, and one may wonder whether the vast
majority of programmers will be able to cope with it. Currently,
transactional memory is a popular
approach <ref xlink:href="#bid36" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> for reducing the programmer
burden using intuitive transaction declarations instead of more
complex concurrency control constructs. However, it does not depart
from the classic approach of parallelizing standard C/C++/Fortran
programs, where parallelism can be difficult to extract or
manipulate. Parallel languages, such as HPF <ref xlink:href="#bid37" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, require
more ambitious evolutions of programming habits, but they also let
programmers pass more semantic about the control and data
characteristics of programs to the compiler for easier and more
efficient parallelization. However, one can only observe that, for the
moment, few such languages have become popular in practice.</p><p>A solution would have a better chance to be adopted by the community
of programmers at large if it integrates well with popular practices
in <i>software engineering</i>, and this aspect of the parallelization
problem may have been overlooked. Interestingly, software engineering
has recently evolved towards a programming model that can blend well
with multi-core architectures and parallelization. Programming has
consistently evolved towards more encapsulation: procedures, then
objects, then <i>components</i> <ref xlink:href="#bid38" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Essentially for two
reasons, because programmers have difficulties grasping large programs
and need to think locally, and because encapsulation enables
<i>reuse</i> of programming efforts. Component-based programming, as
proposed in Java Beans, .Net or more ad-hoc component
frameworks, is the step beyond C++ or Java objects:
programs are decomposed into modules which fully encapsulate code and
data (no global variable) and which communicate among themselves
through explicit interfaces/links.</p><p>Components have many assets for the task of developing parallel
programs. (1) Components provide a pragmatic approach for bringing
parallelization to the community at large thanks to component reuse.
(2) Components provide
an implicit and intuitive programming model: the programmer views
the program as a "virtual space" (rather than a sequence of tasks)
where components reside; two components residing together in the
space and not linked or not communicating through an existing link
implicitly operate in parallel; this virtual space can be mapped to
the physical space of a multi-threaded/multi-core architecture. (3)
Provided the architecture is somehow aware of the program
decomposition into components, and can manipulate individual
components, the compiler (and the user) would be also relieved of
the issue of mapping programs to architectures.</p><p>In order to use software components for large-scale and fine-grain
parallelization, the key notion is to augment them with the ability to
split or replicate. For instance, a component walking a binary tree
could spawn two components to scan two child nodes and the
corresponding subtrees in parallel.</p><p>We are investigating a low-overhead component-based approach for
fine-grain parallelism where components have the ability to
replicate <ref xlink:href="#bid39" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid40" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. We investigate both a
hardware-supported and software-only approach to component division.
We show that a low-overhead component framework, possibly paired with
component hardware support, can provide both an intuitive programming
model for writing fine-grain parallel programs with complex control
flow and data structures, and an efficient platform for parallel
components execution.</p><p><span class="smallcap" align="left">Current activities:</span> FET IP SARC, IST NoE HiPEAC, ANR APE.</p><p><span class="smallcap" align="left">Current people:</span> Olivier Certner, Zheng Li, Pierre Palatin, Olivier Temam.</p></subsection></subsection><subsection id="uid13"><bodyTitle>Spatial computing</bodyTitle><p>The last research direction stems from possible evolutions of
technology. While this research direction may seem very long term,
processor manufacturers cannot always afford to investigate many risky
alternatives way ahead in time. At the same time, for them to accept
and adopt radical changes, they have to be anticipated long in
advance. Thus, we believe prospective research is a core role for
academic researchers, which may be less immediately useful to
companies, but which can bring a real addition to their internal
research activities, and which also carries the potential of bringing
disruptive technology.</p><p>Prospective information on the future of CMOS technology suggests
that, though the density of transistors will keep increasing, the
commuting speed of transistors will not increase as fast, and
transistors may be more faulty (either fabrication defects or
execution faults). Possible replacement/alternative technologies, such
as nanotubes <ref xlink:href="#bid41" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> which have received a lot of attention lately, share many
of these properties: high density, but slow components (possibly even
slower than current components), a large rate of defects/faults, and
more difficulty to place them except than in fairly regular
structures.</p><p>In short, several potential upcoming technologies seem to bring a very
large number of possibly faulty and not so fast components with layout
issues. For architectures to take advantage of such technology, they
would have to rely on <i>space</i> much more than <i>time/speed</i> to
achieve high performance. Large spatial architectures bring a set of
new architecture issues, such as controling the execution of a program
in a totally decentralized way, efficiently managing the placement of
program tasks on the space, and managing the relative movement of
these different tasks so as to minimize communications. Furthermore,
beyond a certain number of processing elements, it is not even clear
whether many applications will embed enough traditional task-level
parallelism to take advantage of such large spaces, so applications
may have to be expressed (programmed) differently in order to leverage
that space. These two research issues are addressed in the two
research activities described below.</p><p><b>Blob computing.</b> Blob computing <ref xlink:href="#bid42" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> is both a
spatial programming and architecture model which aims at investigating
the utilization of a vast amount of processing elements. The key
originality of the model is to acknowledge that the chip space becomes
too large for anything else than purely <i>local</i> actions. As a
result, all architecture control becomes local. Similarly, the program
itself is decomposed into a set of purely local actions/tasks, called
Blobs, connected together through links; the program can
create/destroy these links during its lifetime.</p><p>With respect to architecture control, for instance, the local method
for expressing that two tasks frequently communicating through a link
must get close together in space so that their communication latency
is low is expressed through a simply physical law, emulating spring
tension; the more communications, the higer the tension. Similarly,
expressing that tasks should move away because too many tasks are
grouped in the same physical spot is achieved through a law similar to
pressure: as the number of tasks increases, the local pressure on
neighbor tasks increases, inducing them to move away. Overall many of
these local control rules derive from physical or biological laws
which achieve the same goals: controling a large space through simple
local interactions.</p><p>With respect to programming, the user essentially has to decompose the
program into a set of nodes and links. The program can create a static
node/link topology that is later used for computations, or it can
dynamically change that topology during execution. But the key concept
is that the user is not in charge of placing tasks on the physical
space, only to express the <i>potential</i> parallelism through task
division. As can be observed, several of the intuitions of the CAPSULE
environment of Section <ref xlink:href="#uid12" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> stems from this Blob model.</p><p><b>Bio-Inspired computing.</b> As mentioned above, beyond a certain
number of individual components, it is not even clear whether it will
be possible to decompose tasks in such a way they can take advantage
of a large space. Searching for pieces of solution to this problem
has progressively lead us to biological neural networks. Indeed,
biological neural networks (as opposed to artificial neural networks,
ANNs) are well-known examples of systems capable of complex
information processing tasks using a large number of self-organized,
but slow and unreliable components. And the
complexity of the tasks typically processed by biological neurons is
well beyond what is classically implemented with ANNs, because ANNs
lack key features of biological neural networks.</p><p noindent="true">Emulating the workings of biological neural networks may at first seem
far-fetched. However, the SIA (Semiconductor Industry Association) in its 2005
roadmap addresses for the first time ``biologically inspired
architecture implementations'' <ref xlink:href="#bid43" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> as emerging research
architectures and focuses on biological neural networks as interesting
scalable designs for information processing.
More importantly, the computer science community is beginning to
realize that biologists have made tremendous progress in the
understanding of how certain complex information processing tasks are
implemented (programmed) using biological neural networks.</p><p noindent="true">One of the key emerging features of biological neural networks is that
they process information by <i>abstracting</i> it, and then only
manipulate such higher abstractions. As a result, each new input (for
image processing for instance) can be analyzed using these learned
abstractions directly, thus avoiding to rerun a lengthy set of
elementary computations. More precisely,
Poggio et al. <ref xlink:href="#bid44" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> at MIT have shown how
combinations of neurons implementing simple operations such as MAX or
SUM, can automatically create such abstractions for image processing,
and some computer science researchers in the image processing domain
have started to take advantage of these findings.</p><p noindent="true">We are starting to
investigate the information processing capabilities of this
abstraction programming
method <ref xlink:href="#bid45" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid46" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid47" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid48" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. While image
processing is also our first application, we plan to later look at a
more diverse set of example applications.</p><p><b>A complex systems view of computing systems.</b> More generally, the
increased complexity of computing systems at stake, whether due to a
large number of individual components, a large number of cores or
simply complex architecture program/pairs, suggest that novel design
and evaluation methodologies should be investigated that rely less on
known design information than on observed behavior of the global
resulting system. The main problem here is to be able to extract
general characteristics of the architecture on the basis of
measurements of its global behavior. For that purpose, we are using
tools provided by the physics of complex systems (nonlinear time
series analysis, phase transitions, multifractal analysis...).</p><p noindent="true">We have already applied such tools to better understand the
performance behavior of complex but traditional computing systems such
as superscalar processors <ref xlink:href="#bid49" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid50" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. And we are
starting to apply them to sampling techniques for performance
evaluation <ref xlink:href="#bid51" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid52" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. We
will be progressively expanding the reach of these techniques in our
research studies in the future.</p><p><span class="smallcap" align="left">Current activities:</span> ASTICO ACI grant.</p><p><span class="smallcap" align="left">Current people:</span> Hugues Berry, Christine Eisenbeis,
Frédéric Gruau, F. Jiang, Benoît Siri, Olivier Temam</p></subsection><subsection id="uid14"><bodyTitle>Transversal research activities: simulation and compilation</bodyTitle><p>Since our research group has been involved in both compiler and
architecture research for several years, we have progressively given
increased attention to tools, partly because we found a lot of
productivity was lost in inefficient or hard to reuse tools. Since
then, both simulation and compilation platforms have morphed into
research activities of their own. Our group is now coordinating the
development of the simulation platform of the European HiPEAC network,
and it is co-coordinating the development of the compiler research
platform of HiPEAC together with University of Edinburgh.</p><subsection id="uid15"><bodyTitle>Simulation platform</bodyTitle><p>As processor architecture and program complexity increase, so does the
development and execution time of simulators. Therefore, we have
investigated simulation methodologies capable of increasing our
research productivity. The key point is to improve the reuse, sharing,
comparison and speed capabilities of simulators. For the first three
properties, we are investigating the development of a <i>modular</i>
simulation platform, and for the latter fourth property, we are
investigating sampling techniques and more abstract modeling
techniques. Our simulation platform is called UNISIM <ref xlink:href="#bid53" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p><i>What is UNISIM?</i> UNISIM is a structural simulation environment
which provides an intuitive mapping from the hardware block diagram to
the simulator; each hardware block corresponds to a simulation module.
UNISIM is also a library of modules where researchers will be able to
download and upload (contribute) modules.</p><p><i>What are the assets of UNISIM over other simulation platforms?</i>
UNISIM allows to reuse, exchange and compare simulator parts (and
architecture ideas), something that is badly needed in academic
research, and between academia and industry. Recently, we did a
comparison of 10 different cache mechanisms proposed over the course
of 15 years <ref xlink:href="#bid54" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, and suggested the progress of research
has been all but regular because of the lack of a common ground for
comparison, and because simulation results are easily skewed by small
differences in the simulator setup.</p><p>Also, other simulation environments or simulators advocate modular
simulation for sharing and comparison, such as the SystemC
environment <ref xlink:href="#bid55" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, or the M5 simulator <ref xlink:href="#bid56" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. While they
do improve the modularity of simulators, in practice, reuse is still
quite difficult because most simulation environments overlook the
difficulty and importance of reusing <i>control</i>. For instance,
SystemC focuses on reusing hardware blocks such as ALUs, caches, and
so on. However, while hardware blocks correspond to the greatest share
of transistors in the actual design, they often correspond to the
least share of simulator lines. For instance, the cache data and
instruction banks often correspond to a sizeable amount of
transistors, but they merely correspond to array declarations in the
simulator; conversely, cache control corresponds to few transistors
but most of the source lines of any cache simulator
function/module. As a result, it is difficult to achieve reuse in
practice, because control code is often not implemented in such a way
that it can lend well to reuse.</p><p>On the contrary, UNISIM is focused on reuse of control code, provides
a standardized module communication protocol and a control abstraction
for that purpose. Moreover, UNISIM will later on come with an open
library in order to better structure the set of available simulators
and simulator components.</p><p><i>Taking a realistic approach at simulator usage.</i> Obviously, many
research groups will not accept easily to drop years of investment in
their simulation platforms and to switch to a new environment. We take
a pragmatic approach and UNISIM is designed from the ground up to be
interoperable with existing simulators, from industry and academia. We
achieve interoperability by wrapping full simulators or simulator
parts within UNISIM modules. We have an example full SimpleScalar
simulator stripped of its memory, wrapped into a UNISIM module, and
plugged into a UNISIM SDRAM module.</p><p>Moreover, we are in the process of developing a number of APIs (for
power, GUI, functional simulators, sampling,...) which will allow
third-party tools to be plugged into the UNISIM engine. We call these
APIs simulator capabilities or services.</p><p><i>With CMPs, communications become more important than cores
cycle-level behavior.</i> While the current version of UNISIM is focused
on cycle-level simulators, we are developing a more abstract view of
simulators called Transaction-Level Models (TLM). Later on, we will
also allow hybrid simulators, using TLM for prototyping, and then
zooming on some components of a complex system.</p><p>Because CMPs also require operating system support for a large part,
and because existing alternatives such as SIMICS <ref xlink:href="#bid57" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> are not
open enough, we are also developing full-system support in our new
simulators jointly with CEA. Currently, UNISIM has a functional
simulator of a PowerPC750 capable of booting Linux.</p><p><i>Cooperation.</i> While Inria was initially developing its own
environment called MicroLib <ref xlink:href="#bid58" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>,<ref xlink:href="#bid54" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>,<footnote id="uid16" place="foot" anchored="yes">Some
of the MicroLib developments were rather heavily disseminated: 3500+
downloads of our PowerPC750 simulator, 7400+ downloads of our parallel
simulation environment DIST <ref xlink:href="#bid59" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> as of November 2006.</footnote> we found
many similarities with the Liberty environment developed at Princeton
University (David August). After a few interactions, we decided to
merge the two environments into a single one called UNISIM. Since
then, UNISIM has been adopted as the official simulation platform of
the European HiPEAC network, and has attracted other
cooperations. First, from CEA, a French research institution, which is
heavily involved in the development of the TLM part of UNISIM, and
also with UPC, which is involved in both the TLM part and the
development of CMP simulators (they have a UNISIM model of an IBM
Cell). Ghent University has recently started to investigate the
application of its statistical simulation techniques to UNISIM
simulators.</p><p><span class="smallcap" align="left">Current activities:</span> European NoE HiPEAC, European IP SARC, Inria MODSIM joint team.</p><p><span class="smallcap" align="left">Current people:</span> Sylvain Girbal, Olivier Temam, Zheng Li.</p></subsection><subsection id="uid17"><bodyTitle>Compilation platform</bodyTitle><p>The free <i>GNU Compiler Collection</i> (GCC) is the leading tool
suite for portable developments on open platforms. It supports more
than 6 input languages and 30 target processor architectures and
instruction sets, with state-of-the-art support for debugging,
profiling and cross-compilation. It has long been supported by the
general-purpose and high-performance hardware vendors. The last couple
of years have seen GCC taking momentum in the embedded system
industry, and also as a platform for advanced research in program
analysis, transformation and optimization.</p><p>GCC 4.2 features more than 170 compilation passes, two thirds of them
playing a direct role in program optimization. These passes are
selected, scheduled, and parameterized through a versatile pass
manager. The main families of passes can be classified as:</p><simplelist><li id="uid18"><p>interprocedural analyses and optimizations;</p></li><li id="uid19"><p>profile-directed optimization (interprocedural and intraprocedural);</p></li><li id="uid20"><p>induction variable analysis, canonicalization and strength-reduction;</p></li><li id="uid21"><p>loop optimizations;</p></li><li id="uid22"><p>automatic vectorization;</p></li><li id="uid23"><p>data layout optimization.</p></li></simplelist><p>More advanced developments are in progress. We identified three major
ones with a direct impact on high-performance embedded systems
research:</p><simplelist><li id="uid24"><p>link-time optimization (towards just-in-time and dynamic
compilation), with emphasis on scalability to whole-program
optimization and compatibility with production usage;</p></li><li id="uid25"><p>automatic parallelization, featuring full OpenMP 2.5 support and
evolving towards automatic extraction of loop and functional
parallelism, with ongoing research on speculative forms of
parallelism.</p></li></simplelist><p>The HiPEAC network supports GCC as a platform for research and
development in compilation for high-performance and embedded systems.
The network activities on the GCC research platform are coordinated by
Mike O'Boyle and Albert Cohen. We briefly survey the activities
conducted in this context in the Alchemy project team.</p><p><i>Collaborative research and mutual-interest development.</i>
Multiple research collaborations have emerged.
Those including Alchemy are listed below.</p><simplelist><li id="uid26"><p>IBM Haifa and Philips Research (now NXP Semiconductors) are
jointly working on automatic vectorization for complex and wide
embedded vector architectures. This work makes heavy use of Sebastian
Pop's results on induction variables and dependence analysis. A paper
has been submitted to a journal;</p></li><li id="uid27"><p>STMicroelectronics, Inria Futurs and the University of Edinburgh
regularly exchange personnel and ideas on just-in-time and machine
learning compilation; one PhD student (Piotr Lesnicki) started in
October on these topics, with the option to hire another one early in
2007.</p></li></simplelist><p>These efforts have an impact on the visibility and influence of
European researchers in the GCC developer community (heavily industry
backed, with major contributions from IBM, HP, Intel, AMD, RedHat and
Apple). 7 participants to the 2006 GCC developer's summit were
affiliated to HiPEAC institutions (IBM Haifa, STMicroelectronics,
Philips and Inria Futurs).</p><p><span class="smallcap" align="left">Current activities:</span> IST NoE HiPEAC, FET IP SARC, IST STREP
ACOTES, IST STREP MilePost, MEDEA+ ITEA GGCC.</p><p><span class="smallcap" align="left">Current people:</span> Albert Cohen, Grigori Fursin, Sebastian Pop, Olivier
Temam, Piotr Lesnicki, Hamid Daoud.</p></subsection></subsection></subsection></fondements><logiciels id="uid28"><bodyTitle>Software</bodyTitle><subsection id="uid29"><bodyTitle>Main software developments</bodyTitle><subsection id="uid30"><bodyTitle>Main software developments</bodyTitle><p rend="flushed-left"><span class="smallcap" align="left">Compilers &amp; program optimization:</span></p><descriptionlist><label>Polyhedral transformations in Open64</label><li id="uid31"><p>The WRaP-IT tool (WHIRL
Represented as Polyhedra – Interface Tool) is a program analysis
and transformation tool implemented on top of the Open64 compiler
<ref xlink:href="#bid60" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> and of the CLooG code generator
<ref xlink:href="#bid61" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. The formal basis of this tool is the polyhedral model
for reasoning about loop nests. We introduced a specific polyhedral
representation that guarantees strong transformation
compositionality properties <ref xlink:href="#bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. This new
representation is used to generalize classical loop transformations,
to lift the constraints of classical compiler frameworks and enable
more advanced iterative optimization and machine learning schemes.
WRaP-IT — and its loop nest transformation kernel called URUK
(Unified Representation Universal Kernel) — is designed to support
a wide range of transformations on industrial codes, starting from
the SPEC CPU2000 benchmarks, and recently considering a variety of
media and signal processing codes (vision, radar, software radio,
video encoding, and DNA-mining in particular, as part of the IST
STREP ACOTES, ANR CIGC PARA, and a collaboration with Thales).</p><p>Based on this framework, we are also planning an
extension of the polyhedral model to handle speculative code
generation and transformation of programs with data-dependent
control, and a direct search and transformation algorithm based on
the Farkas lemma. These developments will take place in the GRAPHITE
project: a migration/rewrite of our Open64-based software to the GCC
suite. This project is motivated by the maturity — performancewise
and infrastructurewise — of GCC 4.x, and on the massive industrial
investment taking off on GCC in the recent years, especially in the
embedded world. We are heavily involved in fostering research
projects around GCC as a common compilation platform, and GRAPHITE
is one of those projects.</p><p>Grigori Fursin developed the first prototype of an iterative
optimization API for GCC, and started using this infrastructure for
continuous and adaptive optimization research, in collaboration with
the University of Edinburgh.</p></li></descriptionlist><p rend="flushed-left"><span class="smallcap" align="left">Processor simulation:</span></p><descriptionlist><label>UNISIM</label><li id="uid32"><p>The UNISIM platform has been described in
Section <ref xlink:href="#uid15" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. As of now, besides the simulation engine, the
developments include a shared-memory CMP based on the PowerPC 405,
functional simulators for the PowerPC 405 (and cycle-level),
PowerPC 750, a functional system simulator of the PowerPC 750 capable
of booting Linux, 10 different cache modules corresponding to various
research works. The following simulators or tools are currently under
development: a functional and cycle-level version of the ARM 9 with
full-system capability, a distributed-memory CMP based on the
Power 405 core, an ST231 VLIW functional and later on cycle-level
simulator.</p></li><label>BeeRS &amp; IDDCA</label><li id="uid33"><p>BeeRS <ref xlink:href="#bid62" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> is a
sampling technique that focuses on practicality by jointly
considering warm-up and sampling. Most sampling techniques treat the
problem separately which complicates their practical usage. BeeRS
also includes the IDDCA clustering technique which has been shown to
outperform traditional k-means techniques by an order of
magnitude <ref xlink:href="#bid51" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p></li><label>MicroLib</label><li id="uid34"><p>MicroLib <ref xlink:href="#bid63" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> is our former version of a modular simulation platform.
It includes a library of modular simulator components freely
distributed on a web site (www.microlib.org). As of now,
it contains generic modules for each of the main components of a
superscalar processor, a full superscalar processor model, an embedded
processor model (PowerPC 750).</p></li><label>FastSysC</label><li id="uid35"><p>FastSysC <ref xlink:href="#bid64" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> is an enhanced SystemC engine. SystemC is itself a modular
simulation environment which is becoming a de facto standard supported
by more than 50 companies in the embedded domain. However, the SystemC
engine development is geared toward adding functionalities rather than improving performance.
Because performance is critical in processor simulation, due to excessively long traces,
we have developed from scratch a new SystemC engine geared toward performance.</p></li><label>DiST</label><li id="uid36"><p>As part of our efforts on speeding up simulation
execution, we have developed a tool for parallelizing simulators,
called DiST <ref xlink:href="#bid59" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, requiring little simulator
modifications and incurring only a small loss of accuracy. The main
asset of the tool is that it can take advantage of multiple computing
resources.</p></li></descriptionlist></subsection></subsection></logiciels><resultats id="uid37"><bodyTitle>New Results</bodyTitle><subsection id="uid38"><bodyTitle>Practical approach to program optimizations</bodyTitle><subsection id="uid39"><bodyTitle>Iterative optimization</bodyTitle><p>Our general approach consists in acknowledging that architectures are
too complex to embed reliable architecture models in compilers, and to
explore the behavior of the architecture/program pair through repeated
executions. Then, using machine-learning techniques, a model of this
behavior is infered from the observations. This approach is usually called
<i>iterative optimization</i>.</p><p>In the recent years, iterative optimization has emerged as a major
research trend, both in traditional compilation contexts and in
application-specific library generators (like ATLAS or SPIRAL). The
topic has matured significantly since the pionneering works of Mike
O'Boyle <ref xlink:href="#bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> at University of Edinburgh, UK or Keith
Cooper <ref xlink:href="#bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> at Rice University. While these research works
successfully demonstrated the performance <i>potential</i> of the
approach, they also highlighted that iterative optimization cannot
become a <i>practical</i> technique unless a number of issues are
resolved. Some of the key issues are: the size and structure of the
search space, the sensitivity to data sets, and the necessity to build
long transformation sequences.</p><p><b>Scanning a large search space.</b> Transformation parameters, the
order in which transformations are applied, and even which
transformations must be applied and how many times, all form a huge
transformation space. One of the main challenges of iterative
optimization is to rapidly converge towards an efficient, if not
optimal, point of the transformation space. Machine-Learning
techniques can help build an empirical model of the transformation
space in a simple and systematic way, only based on the observation of
transformations behavior, and then rapidly deduce the most profitable
points of the space. We are investigating how to correlate static and
dynamic program features with transformation efficiency. This approach
can speed up the convergence of the search process by one or two
orders of magnitude compared to random search <ref xlink:href="#bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p>We have also shown that by representing the impact of loop transformations
using structured encoding derived from polyhedral program representation,
it is possible to reduce the complexity of the search by several orders
of magnitude <ref xlink:href="#bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. This encoding is further described
in Section <ref xlink:href="#uid9" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p>We have also shown that it is possible to further speed up
transformation space exploration by exploring several transformations
during a single run <ref xlink:href="#bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Currently, one program
transformation is explored for each loop nest, while performance often
reaches a stable state soon after the start of the execution. We have
shown that, assuming we properly identify the phase behavior of
programs, it is possible to explore multiple transformations in each
run.</p><p><b>Data set sensitivity.</b> Iterative optimization is based on the
notion that the compiler will discover the best way to optimize a
program through repeatedly running the same program on the same data
set, trying one or a few different optimizations upon each
run. However, in reality, a user rarely needs to execute the same data set
twice. Therefore, iterative optimization is based on the implicit
assumption that the best optimization configuration found will work
<i>well</i> for <i>all data sets</i> of a program. To the best of our
knowledge, this assumption has never been thoroughly
investigated. Most studies on iterative optimization repeatedly
execute the same program/data set
pair <ref xlink:href="#bid7" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid10" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid11" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, only
recently, some studies have focused on the impact of data sets on
iterative optimizations <ref xlink:href="#bid12" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid13" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p>In order to explore the issue of data set sensitivity, we have
assembled a data set suite, of 20 data sets per benchmark, for most of
the MiBench <ref xlink:href="#bid14" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> embedded benchmarks. We have found that,
though a majority of programs exhibit stable performance across data
sets, the variability can significantly increase with many
optimizations. However, for the best optimization configurations, we
find that this variability is in fact small. Furthermore, we show that
it is possible to find a compromise configuration across data sets
which is often within 5% of the best possible optimization
configuration for most data sets, and that the iterative process can
converge in less than 20 iterations (for a population of 200
optimization configurations). Overall, the preliminary conclusion, at
least for the MiBench benchmarks, is that iterative optimization is a
fairly robust technique across data sets, which brings it one step
closer to practical usage.</p><p><b>Compositions of program transformations.</b> Compilers impose a
certain set of program transformations, an order of application and
how many times each transformation is applied. In order to explore
what are the possible gains beyond these strict constraints, we have
manually optimized kernels and benchmarks, trying to achieve the best
possible performance assuming no constraint on transformation order,
count or selection <ref xlink:href="#bid15" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid16" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. The study helped us
clarify which transformations bring the best performance improvements
in general. But the main conclusion of that study is that
surprisingly long compositions of transformations are sometimes needed
(in one case, up to 26 composed loop transformations) in order to
achieve good performance. Either because multiple issues must be
tackled simultaneously or because some transformations act as enabling
operations for other transformations.</p><p>As a result, we have started developing a framework facilitating the
composition of long transformations. This framework is based on the
polyhedral representation of program
transformations <ref xlink:href="#bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. This framework also enables a
more analytical approach to program optimization and parallelization,
beyond the simple composition of transformations. This latter part is
further developed in Section <ref xlink:href="#uid9" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p><b>Putting it all together: continuous optimization.</b> Increasingly,
we are now moving toward automatizing the whole iterative optimization
process. Our goal is to bring together, within a single software
environment, the different aforementioned observations and techniques
(search space techniques, data set sensitivity properties, long
compositions of transformations,...). We are currently in the
process of plugging these different techniques within GCC in order to
create a tool capable of doing continuous, whole-program optimization,
and even collaborative optimization across different users.</p><p><b>Hardware-Oriented applications of iterative optimization.</b>
Because iterative optimization can successfully capture complex
dynamic/run-time phenomena, we have shown that the approach can act as
a replacement for costly hardware structures designed to improve the
run-time behavior of programs, such as out-of-order execution in
superscalar processors. An iterative optimization-like strategy
applied to an embedded VLIW processor <ref xlink:href="#bid18" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> was shown
to achieve almost the same performance as if the processor was fitted
with dynamic instruction reordering support. We are also
investigating applications of this approach to the
specialization/idiomization of general-purpose and embedded
processors <ref xlink:href="#bid19" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Currently, we are exploring
similar approaches for providing thread scheduling and placement
information for CMPs without requiring costly run-time environement
overhead or hardware support. This latter study is related to the work presented
in Section <ref xlink:href="#uid10" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p><span class="smallcap" align="left">Current activities:</span> IST STREP MilePost, FET IP SARC, MEDEA+ ITEA
GGCC, IST NoE HiPEAC, RNTL COP.</p><p><span class="smallcap" align="left">Current people:</span> Albert Cohen, Patrick Carribault, Grigori
Fursin, Sylvain Girbal, Piotr Lesnicki, Louis-Noël Pouchet, Olivier
Temam, Nicolas Vasilache.</p></subsection><subsection id="uid40"><bodyTitle>Polyhedral program representation: facilitating the
analysis and transformation of programs</bodyTitle><p>As loop transformations are utterly important — performancewise —
and among the hardest to predictably drive through static cost models,
their current support in compilers is disappointing. After decades of
experience and theoretical advances, the best compilers can miss some
of the most important loop transformations in simple numerical codes
from linear algebra or signal processing codes. Performance hits of
more than an order of magnitude are not uncommon on single-threaded
code, and the situation worsens when automatically parallelizing or
optimizing parallel code.</p><p>Our previous work on sequences of loop transformations
<ref xlink:href="#bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> has led to the design of a theoretical
framework, based on the polyhedral model
<ref xlink:href="#bid20" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid21" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid22" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid23" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid24" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid25" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, and a set of tools based on
the advanced Open64 compiler. We have shown that this framework does
simplify the problem of building complex transformation sequences, but
also that it scales to real-world benchmarks <ref xlink:href="#bid26" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid27" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid28" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid29" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, and allows to
significantly reduce the size of the search space and better
understand its structure <ref xlink:href="#bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. The latter work, for
example, is the first attempt at directly characterizing all
<i>legal and distinct</i> ways to reschedule a loop nest.</p><p>After two decades of academic research, the polyhedral model is
finally evolving into a mature, production-ready approach to solve the
challenges of maximizing the scalability and efficiency of
statically-controlled, loop-based computations on a variety of high
performance and embedded targets. After Open64, we are now porting these
techniques to the GCC compiler <ref xlink:href="#bid30" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, applying
them to several multi-level parallelization and optimization problems,
including vectorization, extraction and exploitation of thread-level
parallelism on distributed memory CMPs like the Cell broadband engine
from IBM, NXP's CAT-DI scalable signal-processing accelerator and
novel STMicroelectronics emerging xStream architecture.</p><p><span class="smallcap" align="left">Current activities:</span> IST STREP ACOTES, ANR CIGC PARA, RNTL COP.</p><p><span class="smallcap" align="left">Current people:</span> Cedric Bastoul, Albert Cohen, Sebastian Pop,
Louis-Noël Pouchet, Nicolas Vasilache.</p></subsection><subsection id="uid41"><bodyTitle>Iterative optimization meets the polytope model</bodyTitle><participants category="None"><person><firstname>Albert</firstname><lastname>Cohen</lastname><affiliation/><categoryPro/></person><person><firstname>Sylvain</firstname><lastname>Girbal</lastname><affiliation/><categoryPro/></person><person><firstname>David</firstname><lastname>Parello</lastname><affiliation/><categoryPro/></person><person><firstname>Olivier</firstname><lastname>Temam</lastname><affiliation/><categoryPro/></person><person><firstname>Nicolas</firstname><lastname>Vasilache</lastname><affiliation/><categoryPro/></person></participants><p>Static cost models have a hard time coping with hardware components
exhibiting complex run-time behaviors, calling for alternative
solutions. Iterative optimization is emerging as a promising research
direction, but currently, it is mostly limited to finding the
parameters of program transformations or selecting whole optimization
phases. One of the cornerstones of our <i>Center for Program
Tuning</i> (RNTL project, <i>Centre d'Optimisation de Programmes</i>,
2003–2005) is to facilitate the expression and search of compositions
of program transformations. Our framework relies on a unified
polyhedral representation of loops and statements. The key is to
clearly separate the impact of each program transformation on the
following three components: the iteration domain, the statements
schedule and the memory access functions <ref xlink:href="#bid28" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Within this
framework, composing a long sequence of program transformations
induces no code explosion. As a result, searching for compositions of
transformations is not hampered by the multiplicity of compositions,
and ultimately, it is equivalent to testing different values of the
matrices parameters in many cases. Our techniques have been
implemented on top of the Open64/ORC compiler. In addition, we have
designed a prototype iterative optimization infrastructure for
iterative optimization, based on genetic algorithms. This
infrastructure distributes simulations, dynamic profiles,
compilations, transformations, while interacting with a
machine-learning component or with an expert user. Validation of these
concepts and application of the tools is beginning on the SPEC CPU2000
benchmarks; showing the ability of our tools and framework to scale to
larger codes is a critical phase in the center for program tuning.
Recent research addresses the automatic search of program
transformations in a multidimensional space, combining Lagrangian
relaxation (e.g., Farkas Lemma), operation research algorithms and
iterative optimization.</p></subsection><subsection id="uid42"><bodyTitle>Iterative compilation and continuous optimizations</bodyTitle><participants category="None"><person><firstname>Albert</firstname><lastname>Cohen</lastname><affiliation/><categoryPro/></person><person><firstname>Grigori</firstname><lastname>Fursin</lastname><affiliation/><categoryPro/></person><person><firstname>Olivier</firstname><lastname>Temam</lastname><affiliation/><categoryPro/></person></participants><p>Currently we are working on iterative compilation and continuous optimizations.
For iterative compilation we attempt to further improve existing
compiler infrastructure such as gcc or PathScale to be able to
apply a greater variety of program transformations systematically
and automatically to considerably improve program performance
and/or reduce power consumption for embedded systems.
We investigate both static and run-time optimizations
and adaptation towards various data inputs.
For continuous optimizations we attempt to collect
all information available during program optimization
and its multiple executions with various datasets.
We further intend to use machine-learning techniques to quickly
and automatically optimize new programs or adapt towards
new datasets by exploiting all previously gathered knowledge.</p><p>This year we published 3 papers on the above topics.</p><p>The paper <ref xlink:href="#bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>,
ranked first at the International Conference on High Performance
Embedded Architectures and Compilers (<span class="smallcap" align="left">HiPEAC</span> 2005) shows a method
to make iterative optimization practical and usable by speeding
up the evaluation of a large range of optimizations. Instead of
using a full run to evaluate a single program optimization, we take
advantage of periods of stable performance, called phases. For
that purpose, we propose a low-overhead phase detection scheme geared
toward fast optimization space pruning, using code instrumentation and
versioning implemented in a production compiler .We demonstrate
that it is possible to search for complex optimizations at run-time
without resorting to sophisticated dynamic compilation
frameworks. In addition to that, our approach also enables
to quickly design self-tuned applications.</p><p>The two other papers <ref xlink:href="#bid65" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> and <ref xlink:href="#bid66" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> (in collaboration
with Edinburgh University) explore the ways to search
for best transformations in large optimizations spaces.
The first paper uses Pugh's Unified Transformation
Framework to exploit the performance improvement potential
of complex transformation compositions and presents a heuristic
search algorithm capable of efficiently locating good program
optimizations within such a space.
The second paper empirically evaluates source-level transformations
and the probabilistic feedback-driven search for "good" transformation
sequences within a large optimization space.</p></subsection><subsection id="uid43"><bodyTitle>Low-level optimization</bodyTitle><participants category="None"><person><firstname>Patrick</firstname><lastname>Carribault</lastname><affiliation/><categoryPro/></person><person><firstname>Albert</firstname><lastname>Cohen</lastname><affiliation/><categoryPro/></person></participants><p>This work is done in collaboration with William Jalby from  University of Versailles-Saint-Quentin.
To achieve the best performance on single processors, optimizations
need to target most components of the architecture simultaneously,
focusing on the memory hierarchy (including registers), branch
prediction, instruction-level parallelism and vector (SIMD)
parallelism. Typical examples of good candidates for aggressive
optimization technologies include regular and numerical computations
from scientific, signal processing or multimedia applications.</p><p>More irregular programs can also be data and compute intensive, but
less architecture-aware optimizations have been proposed for such
programs. Still, speculative and very complex transformations are
available for such codes in the context of massively parallel
computers. We investigated the applicability and extension/adaptation
of some of these techniques for the optimization on uniprocessors, and
our results were extremely promising in the case of two approximate
string-matching codes (for computational biology).
Hybrid static-dynamic optimizations for such programs are also being
considered, driving the selection of optimization parameters at
run-time through the fine-grain tracking of the behaviour of the
application (performance counters).</p><p>Finally, we studied even more irregular codes: decision trees in
control-intensive emulators, text processors or memory management
functions. We showed that, surprisingly, high quality performance
predictions could be achieved at compile time, helping the compiler to
take the right code generation decisions. This study
also led to the design of a new program transformation, called Deep
Jam, generalizing the unroll-and-jam optimization to nested irregular
loops with conditionals and early exits <ref xlink:href="#bid67" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p></subsection><subsection id="uid44"><bodyTitle>Advanced analysis and optimization for the end-user</bodyTitle><participants category="None"><person><firstname>Albert</firstname><lastname>Cohen</lastname><affiliation/><categoryPro/></person><person><firstname>Sebastian</firstname><lastname>Pop</lastname><affiliation/><categoryPro/></person></participants><p>This work is done in collaboration with Georges Silber, Pierre Jouvelot and François
Irigoin from École Nationale Supérieure des Mines de Paris.</p><p>We designed an induction variable analyzer suitable for the analysis
of typed, low-level, three address representations in SSA form. At the
heart of our analyzer is a new algorithm recognizing scalar
evolutions. We define a representation called trees of recurrences
that is able to capture different levels of abstractions: from the
finer level that is a subset of the SSA representation restricted to
arithmetic operations on scalar variables, to the coarser levels such
as the evolution envelopes that abstract sets of possible evolutions
in loops. Unlike previous work, our algorithm tracks induction
variables without prior classification of a few evolution patterns:
different levels of abstraction can be obtained on demand
<ref xlink:href="#bid68" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. The low complexity of the algorithm fits the constraints
of a production compiler, and roots the mainline dependence analysis
framework in the Gnu Compiler Collection (GCC), as illustrated by the
evaluation of our implementation on standard benchmark programs
<ref xlink:href="#bid69" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p></subsection></subsection><subsection id="uid45"><bodyTitle>Joint architecture/programming approaches</bodyTitle><subsection id="uid46"><bodyTitle>Passing program semantics using a synchronous language for
high-performance video processing</bodyTitle><p>While we are currently investigating the aforementioned approach for
general-purpose applications, we have started with the investigation
of the specific domain of high-end video
processing. In this domain, assessing that real-time properties will
be satisfied is as important as reaching uncommon levels of compute
density on a chip. 150 giga-operations per second per Watt (on pixel
components) is the norm for current high-definition TVs, and cannot be
achieved with programmable cores at present. The future standards will
need an 8-fold increase (e.g., for 3D displays or
super-high-definition). Predictability and efficiency are the keywords
in this domain, in terms of both architecture and compiler behavior.</p><p>Our approach combines the aforementioned iterative optimization and
polyhedral modeling research with a predictability- and
efficiency-oriented parallel programming language. We focus on
warrantable (as opposed to best-effort) usage of hardware resources
with respect to real-time constraints. Therefore, this parallel
programming language must allow overhead-free generation of
tightly coupled parallel threads, interacting through dedicated
registers rather than caches, streaming data through high-bandwidth,
statically managed interconnect structures, with frequent
synchronizations (once every few cycles), and very limited memory
resources immediately available. This language also needs to support
advanced loop transformations, and its representation of concurrency
compatible with the expression of multi-level partitioning and mapping
decisions. All these conditions tend to consider a language closer to
hardware synthesis languages than general-purpose, von Neumann
oriented imperative ones <ref xlink:href="#bid31" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid32" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p><p>The synchronous data-flow paradigm is a natural candidate, because of
its ability to combine high-productivity in programming complex
concurrent applications (due to the determinism and compositionality
of the underlying model, a rare feature of a concurrent semantics),
direct modeling of computation/communication time, and static checking
of non-functional properties (time and resource constraints). Yet
generating low-level, tightly fused loops with maximal exposition of
fine-grain parallelism from such languages is a difficult problem, as
soon as the target processor is not the one being described by the
synchronous data-flow program, but a pre-existing target on which we
are folding an application program. The two tasks are totally
different: although the most difficult decisions are pushed back to
the programmer in the hardware synthesis case, application programmers
usually rely on the compiler to abstract away the folding of their
code in a reasonably portable fashion across a variety of targets.
This aspect of synchronous language compilation has largely been
overlooked and constitutes the main direction of our work. Another
direction lies in the description of hardware resources, at the same
level as the application being mapped and scheduled onto them; this
unified representation would allow the expression of the search space
of program transformations, and would be a necessary step to apply
incremental refinement methods (expert-driven, very popular in this
domain).</p><p>Technically, we extend the classical clock calculus (a type system) of
the <i>Lucid Synchrone</i> language, expliciting significantly more
information about the program behavior, especially when tasks must be
started and will be completed, how information flow among tasks, etc.
Our main contribution is the integration of relaxed synchronous
operators like jittering and bursty streams within synchronous bounds
<ref xlink:href="#bid33" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. This research consists in revisiting the
semantics of synchronous Kahn networks in the domain of media
streaming applications and reconfigurable parallel architectures, in
collaboration with Marc Duranton from Philips Research Eindhoven (now
NXP Semiconductors) and with Marc Pouzet from LRI and the Proval Inria
project team.</p><p><span class="smallcap" align="left">Current activities:</span> IST STREP ACOTES, Marie Curie ToK-IAP
PSYCHES.</p><p><span class="smallcap" align="left">Current people:</span> Albert Cohen, Christine Eisenbeis, Mohammed Fellahi.</p></subsection><subsection id="uid47"><bodyTitle>Passing program semantic using software components</bodyTitle><p>Beyond domain-specific and regular applications (loops and arrays),
automatic compiler-based parallelization has achieved only mixed
results on programs with complex control and data
structures <ref xlink:href="#bid34" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Writing, and especially debugging,
large parallel programs is a notoriously difficult
task <ref xlink:href="#bid35" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, and one may wonder whether the vast
majority of programmers will be able to cope with it. Currently,
transactional memory is a popular
approach <ref xlink:href="#bid36" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> for reducing the programmer
burden using intuitive transaction declarations instead of more
complex concurrency control constructs. However, it does not depart
from the classic approach of parallelizing standard C/C++/Fortran
programs, where parallelism can be difficult to extract or
manipulate. Parallel languages, such as HPF <ref xlink:href="#bid37" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, require
more ambitious evolutions of programming habits, but they also let
programmers pass more semantic about the control and data
characteristics of programs to the compiler for easier and more
efficient parallelization. However, one can only observe that, for the
moment, few such languages have become popular in practice.</p><p>A solution would have a better chance to be adopted by the community
of programmers at large if it integrates well with popular practices
in <i>software engineering</i>, and this aspect of the parallelization
problem may have been overlooked. Interestingly, software engineering
has recently evolved towards a programming model that can blend well
with multi-core architectures and parallelization. Programming has
consistently evolved towards more encapsulation: procedures, then
objects, then <i>components</i> <ref xlink:href="#bid38" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Essentially for two
reasons, because programmers have difficulties grasping large programs
and need to think locally, and because encapsulation enables
<i>reuse</i> of programming efforts. Component-based programming, as
proposed in Java Beans, .Net or more ad-hoc component
frameworks, is the step beyond C++ or Java objects:
programs are decomposed into modules which fully encapsulate code and
data (no global variable) and which communicate among themselves
through explicit interfaces/links.</p><p>Components have many assets for the task of developing parallel
programs. (1) Components provide a pragmatic approach for bringing
parallelization to the community at large thanks to component reuse.
(2) Components provide
an implicit and intuitive programming model: the programmer views
the program as a "virtual space" (rather than a sequence of tasks)
where components reside; two components residing together in the
space and not linked or not communicating through an existing link
implicitly operate in parallel; this virtual space can be mapped to
the physical space of a multi-threaded/multi-core architecture. (3)
Provided the architecture is somehow aware of the program
decomposition into components, and can manipulate individual
components, the compiler (and the user) would be also relieved of
the issue of mapping programs to architectures.</p><p>In order to use software components for large-scale and fine-grain
parallelization, the key notion is to augment them with the ability to
split or replicate. For instance, a component walking a binary tree
could spawn two components to scan two child nodes and the
corresponding subtrees in parallel.</p><p>We are investigating a low-overhead component-based approach for
fine-grain parallelism where components have the ability to
replicate <ref xlink:href="#bid39" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid40" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. We investigate both a
hardware-supported and software-only approach to component division.
We show that a low-overhead component framework, possibly paired with
component hardware support, can provide both an intuitive programming
model for writing fine-grain parallel programs with complex control
flow and data structures, and an efficient platform for parallel
components execution.</p><p><span class="smallcap" align="left">Current activities:</span> FET IP SARC, IST NoE HiPEAC, ANR APE.</p><p><span class="smallcap" align="left">Current people:</span> Olivier Certner, Zheng Li, Pierre Palatin, Olivier Temam.</p></subsection></subsection><subsection id="uid48"><bodyTitle>A biological approach to computing</bodyTitle><subsection id="uid49"><bodyTitle>Architecture simulation and sampling</bodyTitle><participants category="None"><person><firstname>Hugues</firstname><lastname>Berry</lastname><affiliation/><categoryPro/></person><person><firstname>Daniel</firstname><lastname>Gracia Pérez</lastname><affiliation/><categoryPro/></person><person><firstname>Olivier</firstname><lastname>Temam</lastname><affiliation/><categoryPro/></person></participants><p><i><b>Sampling and Simulation</b></i><i/></p><p noindent="true">Architecture simulation is usually based on cycle-accurate simulators that are very slow compared to execution times on the real architecture. This problem might even become a real blockage with the forthcoming complex multi-core architectures. One possible solution is to simulate only chosen pieces (i.e. samples) of the whole program and use the simulation of these samples to extrapolate to the whole program. In the past few years, several research works have demonstrated that sampling can drastically speed up architecture simulation, and several of these sampling techniques are already largely used. However, for a sampling technique to be both easily and properly used, it must fulfill a number of conditions: it should require no hardware-dependent modification of the simulator, it should simultaneously consider warm-up of the cache structures and sampling, while still delivering high speed and accuracy.</p><p noindent="true">We recently proposed <ref xlink:href="#bid62" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> a sampling technique focused more on transparency than on speed and accuracy, though the technique delivers almost state-of-the-art performance. Our sampling technique is based on algorithms that were originally developed for neurological image analysis. We make the following contributions: (1) a technique for splitting the execution trace into a potentially very large number of variable-size regions to capture program dynamic control flow, (2) a clustering method capable of efficiently coping with such a large number of regions, (3) a budget- based method for jointly considering warm-up and sampling costs, presenting them as a single parameter to the user, and for distributing the number of simulated instructions between warmup and sampling based on the region partitioning and clustering information. Overall, the method achieves an accuracy/time tradeoff that is close to the best reported results using clustering-based sampling (though usually with perfect or hardware-dependent warm-up), with an average CPI error of 1.68% and an average number of simulated instructions of 288 million instructions over the Spec benchmarks. The technique/tool can be readily applied to a wide range of benchmarks, architectures and simulators, and will be used as a sampling option of the UniSim modular simulation framework.</p><p noindent="true"><i/><i><b>Complex systems analysis of performance</b></i><i/></p><p noindent="true">The difficulties encountered in the field of architecture simulators can in part be ascribed to the complexity of the microprocessors themselves. Indeed, performance traces obtained during simulations can be highly variable and difficult to predict. A better understanding and characterization of these complex signals could lead to development of better sampling/simulation techniques. In this context, we studied the time-evolution of performance traces during execution of several prototypical programs on prototypical modern microprocessors <ref xlink:href="#bid70" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid71" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. We recorded several metrics characterizing execution performance and memory operations, and analyzed them using current techniques from complex systems sciences (nonlinear time series analysis in particular). These techniques have been used, for example, to analyze and quantify signals from complex physiological systems, such as heartbeat time series (electrocardiograms) or brain waves (electroencephalograms). Besides regular periodic behaviors, we evidenced highly variable performance evolutions for several programs. More interestingly, we showed that the evolution of performance during the execution of several programs displays clear evidences of deterministic chaos, with sensitivities to initial conditions that are comparable to textbook chaotic systems. This is a clear demonstration that current monoprocessor architectures are, if not complex systems, at least complicated enough to yield such complex behaviors. Future work will focus on applying these analytical tools to concrete simulation issues, and extend our analysis to still more complex architectures, such as chip multiprocessors.</p></subsection><subsection id="uid50"><bodyTitle>Biological neural networks as bio-inspiration sources for future architectures</bodyTitle><participants category="None"><person><firstname>Hugues</firstname><lastname>Berry</lastname><affiliation/><categoryPro/></person><person><firstname>Bruno</firstname><lastname>Cessac</lastname><affiliation/><categoryPro/></person><person><firstname>Bruno</firstname><lastname>Delord</lastname><affiliation/><categoryPro/></person><person><firstname>Mathias</firstname><lastname>Quoy</lastname><affiliation/><categoryPro/></person><person><firstname>Benoit</firstname><lastname>Siri</lastname><affiliation/><categoryPro/></person><person><firstname>Olivier</firstname><lastname>Temam</lastname><affiliation/><categoryPro/></person></participants><p noindent="true">Current trends in the evolution of microprocessor architecture outline systems consisting of a huge number of slow components (possibly even slower than current ones) with a large rate of defects/faults as well as interconnect and placement with variable degrees of irregularity. For architectures to take advantage of such technology, they would have to rely on space much more than time/speed to achieve high performance. The major issues that architects will face at long term are thus how to design, organize and programm these systems, in such a way to warranty scalability. Searching for pieces of solution to this problem has progressively led us to biological neural networks. Indeed, biological neural networks (as opposed to artificial neural networks, ANNs) are well-known examples of systems capable of complex information processing tasks using a large number of self-organized, but slow and unreliable components. And the complexity of the tasks typically processed by biological neurons is well beyond what is classically implemented with ANNs, because ANNs lack key features of biological neural networks. Emulating the workings of biological neural networks may at first sight seem far-fetched. However, the SIA (Semiconductor Industry Association) in its 2005 roadmap addresses for the first time ``biologically inspired architecture implementations'' as emerging research architectures and focuses on biological neural networks as interesting scalable designs for information processing.</p><p noindent="true"><i/><i><b>An abstract model for biological neural network growth</b></i><i/></p><p noindent="true">Computing machines, such as current processor architectures, are designed using a very abstract model of the physical properties of transistors and circuits. Typically, microprocessor architects do not deal with the complex physics occurring at the transistor level but rely upon a very abstract and simplified model of the undergoing physical phenomena. Similarly, if we want to start thinking about computing systems built upon biological neurons, we must come up with sufficiently abstract models of biological neural networks, that will enable the design of large systems without dealing with the detailed individual behavior of the neurons. For instance, to understand what kind of computing systems can be built upon biological neurons, we must first understand the kind of <i>structures</i> into which biological neurons can self-assemble. To this aim, we started with the biological neural network of <i>Caenorhabditis elegans</i>, which has been described in great details in the biology literature. Using this map as an oracle, we defined <ref xlink:href="#bid46" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> a model of network growth in real space and provided empirical evidence that the characteristics of networks built upon this model and the above mentioned biological network closely match. Since this model describes the network <i>growth</i> using simple local rules, it can be used to represent much larger networks, as would be needed for computing systems. In other words, it allows the generation of surrogate networks with structures comparable to that of <i>Caenorhabditis elegans</i>. Further works will be devoted to testing the implementation of these bioinspired structures inside real computing systems such as the interconnect network of chip multiprocessors.</p><p noindent="true"><i/><i><b>Structure and dynamics of recurrent neural networks</b></i><i/></p><p noindent="true">A second major research direction consists in the study of the relationship between function, learning and structure in recurrent neural networks (RNNs). RNNs include backward connections, which endow them with a rich variety of dynamical behaviors. Many real biological neuron networks show such high proportions of backward connections. Recurrent neural networks appear thus more interesting to the understanding of computation in large neural networks than the classical feed-forward structures used in most artificial neural networks. Unlike Hopfield-like networks, RNNs exhibit complex dynamics (limit cycles, chaos) and transitions between them. We started to study these systems using complex networks approaches. In this framework, the dynamics of the neurons (the network nodes) depends on synaptic weights (the network links) that themselves vary over time (``learning'') as a function of the neuron dynamics. The system can thus be thought of as composed by two coupled layers (one for neuron dynamics and one for network structure) whose mutual coupling remains largely obscure. We proposed to use both a dynamical system and a graph theory approach in order to understand this mutual coupling <ref xlink:href="#bid48" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. We investigated several local (unsupervised) learning rules to update synaptic strengths. These rules are simple implementations of Hebb's rule for learning in biological neurons (i.e. neurons which fire together become more tightly coupled).</p><p noindent="true">Due to the aforementioned coupling, learning shapes the network dynamics, topology and function. We evidenced that the modifications of the dynamics can be related to changes in the local loop content. We further showed that, because of these local structural alterations, the global network topology changes as well. Indeed, under the influence of learning, the distribution of the strong synapses on the network is no more homogeneous, i.e. two neurons have an increasing probability to be strongly coupled if they are both connected to a third neuron by strong synapses. Besides, the mean-shortest path remains low, so that these learning rules organize the network as a small-world one. Our studies <ref xlink:href="#bid45" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid47" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/> thus progressively uncover a global sketch allowing the understanding of the relationships between dynamics, structure and function in these networks. Future works in this project will follow two main directions. Firstly, we will extend our fundamental studies of RNNs using tools from spectral graph theory, that should allow us to better delineate how input patterns are actually encoded into the network structure. Secondly, we will apply these fundamental studies to the case of visual object recognition. Our aim here is to develop a bio-inspired model for object recognition in which the network structure would emerge through activity-based local learning rules.</p></subsection><subsection id="uid51"><bodyTitle>Optimizing the structure of large-size neural networks</bodyTitle><participants category="None"><person><firstname>Hugues</firstname><lastname>Berry</lastname><affiliation/><categoryPro/></person><person><firstname>Fei</firstname><lastname>Jiang</lastname><affiliation/><categoryPro/></person><person><firstname>Marc</firstname><lastname>Schoenauer</lastname><affiliation/><categoryPro/></person></participants><p noindent="true">The connectivity structure of complex networks (i.e. their topology) is a crucial determinant of information transfer in large networks (internet, social networks, metabolic networks...). For instance, information, virus or epidemic spreading in complex networks (``small-world'' or ``scale-free'' networks) is much more efficient/fast than in comparable random or regular networks. Other crucial properties of these systems are topology-controlled, such as tolerance to faults/defects (robustness), vaccination or the existence of critical thresholds for epidemic spreading. Several studies have applied such complex networks tools to neural networks. Here again, several functional properties of neural networks seem to depend on the network (complex) topology. For instance, a recent study (Simard <i>et al., Physics Letters A</i> 336:8-15,2005) has shown that introducing a ``small-world'' topology in a monolayer perceptron increases the learning rate of the network. Symmetrically, evolutionary algorithms are commonly used to modify the topology of neural networks so as to optimize their performance. But, in most cases, the studied topologies are quite simple and the number of connections/neurons is low. Furthermore, the evolutionary mechanisms used in most of these studies do not modify the topology in an intensive manner.</p><p noindent="true">Hence, optimization of large neural networks through artificial evolution has hardly been studied. However optimization of complex topologies in related systems has recently begun to be inspected. For instance, Tomassini and collaborators (<i>Complex Systems</i> 15:261-284, 2005) have used evolutionary algorithms to optimize the topology of 1D-cellular automata networks and reported that their optimal topologies were systematically close to ``small-world'' ones. More recently, Oikonomou &amp; Cluzel (<i>Nature Physics</i> 2:532-536, 2006) have optimized the topology of boolean networks and found that the evolution of networks with random topology is very different, even quantitatively, from networks with ``scale-free'' topology.
Here, we wish to study the interaction between the topology of large neural networks and their learning capacities. Our approach tackles both the direct and inverse problem:</p><simplelist><li id="uid52"><p><i>Direct problem</i>: Given a network with fixed topology, we study how the network learns to perform its target task through local (Hebb's) rules. An important part of this study consists in trying to understand the emergence of modular structures in the networks. Modularity is indeed a common feature in biological neural networks, but is usually not observed in artificial neural networks obtained with artificial evolution. Another important aspect of this part of the study is that quantification of the network efficiency can be defined on the basis of its pure performance, but it may also be based on its robustness to failures, noise, or attacks.</p></li><li id="uid53"><p><i>Inverse problem</i>: Given a set of local learning rules and a given evolutionary optimization algorithm acting on the network topology, we study what kind of topology the networks evolve to. In other words, we want to know if there exists such a thing as an optimal topology, for given local learning rules and a given task to perform. Here again, network optimization can concern the pure performance of the network, but, alternatively, it may as well concern its robustness to noise or defects.</p></li></simplelist><p>This project is a collaboration with project-team TAO (INRIA futurs, Orsay), headed by Marc Schoenauer, and grounds the Ph.D. thesis work of F. Jiang, which is co-supervised and co-funded by both groups.</p></subsection><subsection id="uid54"><bodyTitle>Individual properties of biological neurons</bodyTitle><participants category="None"><person><firstname>Hugues</firstname><lastname>Berry</lastname><affiliation/><categoryPro/></person><person><firstname>Bruno</firstname><lastname>Delord</lastname><affiliation/><categoryPro/></person><person><firstname>Stephane</firstname><lastname>Genet</lastname><affiliation/><categoryPro/></person><person><firstname>Emmanuel</firstname><lastname>Guigon</lastname><affiliation/><categoryPro/></person><person><firstname>Loic</firstname><lastname>Sabarly</lastname><affiliation/><categoryPro/></person></participants><p>The properties of biological neural networks that are of direct interest to architecture research are in part due to the intrinsic properties of the individual neurons. We are collaborating with the neuroscience research lab ANIM (INSERM U742) to develop simulation and modeling studies of specific properties of individual biological neurons such as time handling or plasticity and memory properties.</p><p noindent="true">A major effort in this project is devoted to modeling of the cerebellum. The cerebellum is a non-cortical structure that contains more neurons than the rest of the brain (in mammals) and has been implied in motor control, among others. The repetition of a conserved connectivity motif (i.e. a module) throughout this structure suggests that this motif produces a unique computational process at the basis of most of the cerebellum functions. One hypothesis suggests that the cerebellum basically provides representations of the time interval separating two successive events (in the tenths second range). Purkinje cells (PCs) are the only output of the cerebellar cortex and probably provide essential mechanisms for this temporal computation. But the implied mechanisms are still poorly understood. The most probable mechanism seems to be the generation of a slow response in PCs, such as the dendrite plateau potentials observed experimentally. In this work, we studied the triggering and propagation of the plateaus in spatial representations (cables) of the complex PC dendrite <ref xlink:href="#bid72" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>. Our model showed that plateau potentials form an original type of electrical signaling, that cannot be classified as action potentials nor passive electrotonus. Furthermore, our model suggests that plateau potentials could be adaptive signals, whose duration could be learned in order to code time intervals between successive events. The main perspectives of this works consist thus in including synaptic plasticity mechanisms in the model to test its adaptability and time learning properties. In particular, we will use the plasticity model that is currently under study by our group and is able to yield, in a unique dynamical process, plasticity and memory properties which agree with experimental observations at PC synapses. We shall then obtain a module able to model learning of time interval representations in the cerebellum.</p></subsection></subsection></resultats><contrats id="uid55"><bodyTitle>Contracts and Grants with Industry</bodyTitle><subsection id="uid56"><bodyTitle>Collaborations involving industry</bodyTitle><descriptionlist><label>STMicroelectronics</label><li id="uid57"><p>Besides the aforementioned RNTL contract COP, and the HiPEAC
network of excellence, and IP SARC, we have a regular and informal
collaboration on iterative compilation and novel processor
architecture with the AST (Advanced Systems and Technologies)
research group of STMicroelectronics based in Lugano, Switzerland
and Grenoble, France.</p></li><label>Philips Semiconductors, now NXP</label><li id="uid58"><p>We have had regular collaborations with Philips for almost 10 years now,
including direct contracts. Currently, we are involved in several
grants with Philips (IP SARC, Marie-Curie fellowships, ACOTES). Philips
Semiconductors has recently become NXP.</p></li><label>ARM R&amp;D, Cambridge</label><li id="uid59"><p>In the context of the SARC FP6 FET Proactive IP project, Pierre Palatin spent a 3 months summer
internship at ARM R&amp;D, Cambridge. The goal was the application of Capsule on
specific ARM architectures.</p></li></descriptionlist></subsection><subsection id="uid60"><bodyTitle>National and international collaborative grants</bodyTitle><descriptionlist><label>GGCC: EU, MEDEA+ program</label><li id="uid61"><p>ITEA Call 8 project on global analysis
and optimization in GCC. Our involvment lie in the compiler
infrastructure, static analysis in the polyhedral model, and feature
extraction for global and contiunous optimization. With CEA (dpt. of
energy), UPM (Spain), SICS (Sweden), major industrial partners
(Airbus, Telefonica, Bertin) and SMEs (Mandriva, MySQL, and others).
04/2006–04/2009.</p></li><label>ACOTES: EU, IST program</label><li id="uid62"><p>FP6 STREP on language and compiler
support for high-performance streaming applications. We are one of the
largest contractors in the project, with major involvment in
interprocedural optimization and loop transformations for concurrent
distributed streaming applications; it is both a programming model and
compiler project. With Philips Research (Eindhoven), IBM Research
(Haifa), STMicroelectronics (AST Lugano), Nokia (Helsinki), and UPC
(Barcelona). 05/2006–05/2009.</p></li><label>MilePost: EU, IST program</label><li id="uid63"><p>FP6 STREP on machine-learning
compilation. This project matches one of
the core directions of the project: iterative optimization research,
with an emphasis on making iterative compilation methods practical in
real development environments. With IBM Research (Haifa), ARC
(London), CAPS Entreprise (Rennes), IRISA (Rennes), and University of
Edinburgh. 05/2006–05/2009.</p></li><label>PARA: French Ministry of Research</label><li id="uid64"><p>ANR CIGC project on
multi-level parallel programming and automatic parallelization. We are
involved in automatic code generation approaches for domain-specific
and target-specific optimizations; iterative and polyhedral
compilation methods are explored in an application-specific context.
With Bull, University of Versailles, LaBRI (University of Bordeaux),
INT (Evry), CAPS Entreprise (Rennes). 01/2006–01/2009.</p></li><label>APE: French Ministry of Research</label><li id="uid65"><p>ANR RNTL project on
parallel real-time applications for embedded systems. We are developing
a component-based environment called CAPSULE for distributed-memory
processors. It will be applied to a novel processor of STMicroelectronics
and tested on applications from Thales. With STMicroelectronics, Thales,
University of Paris 6, CEA. 01/2006–01/2009.</p></li><label>PSYCHES: EU, IST program</label><li id="uid66"><p>Marie Curie ToK IAP (Transfer of
Knowledge, Industry-Academia Partnership); long-term exchange of
personnel and 2 years of post-doc; with Philips Research (Eindhoven)
and UPC (Barcelona). 03/2006–03/2009.</p></li><label>SARC: EU, IST program</label><li id="uid67"><p>FP6 FET Proactive IP on advanced
computer architecture. The goal is to address all the aspects
of a scalable processor architecture based on multi-cores.
It includes programming paradigms, compiler optimization,
hardware support and simulation issues. CAPSULE is being
used as component-based programming approach, and UNISIM
for the simulation platform. 01/2006–01/2010.</p></li><label>Embedded TeraOps</label><li id="uid68"><p>A SYSTEMATIC ``Pôle de Competitivité'' regional
funding for the development of a large-scale embedded multi-core
architectures, coordinated by Thales. It will initially focus on
streaming applications but it will later target programs with more
complex control flow. Thales, Dassault, Thomson, CEA,
INRIA. 01/2006–01/2010.</p></li><label>MODSIM</label><li id="uid69"><p>MODSIM is an INRIA grant for a joint international team between INRIA
and Princeton University. The goal is the development of the UNISIM
simulation platform. With Princeton University. 01/2006–12/2009.</p></li><label>ACI ASTICO Grant</label><li id="uid70"><p>French Minister of Research grant to explore
biological neuron networks as possible sources of inspiration for
future computing systems, with a focus on the complex structure of
these networks. Our aim is at the same time to investigate
bio-inspired computing systems, and original approaches for the
modeling and understanding of biological neural networks. With
University of Cergy-Pontoise, University of Nice-Sophia-Antipolis and
University of Paris 6. 01/2005–01/2008.</p></li><label>NoE HiPEAC</label><li id="uid71"><p>HiPEAC is a network of excellence on High-Performance Embedded
Architectures and Compilers. It involves more than 70 European
researchers from 10 countries and 6 companies, including ST,
Infineon and ARM. The goal of HiPEAC is to steer European research
on future processor architectures and compilers to key issues,
relevant to the European embedded industry. Olivier Temam is a
member of the steering committee.</p></li><label>ACI Nanosys</label><li id="uid72"><p>French Minister of Research grant to study
the impact of alternative technologies, particularly nanotubes,
on future computing circuits and architectures. With a large array
of French laboratories in VLSI and architecture design.</p></li><label>RNTL COP</label><li id="uid73"><p>The purpose of the project was to bring iterative
optimization techniques to general-purpose and embedded
processors. With STMicroelectronics, HP, CEA and University of
Toulouse. 01/2003–01/2006.</p></li></descriptionlist></subsection></contrats><international id="uid74"><bodyTitle>Other Grants and Activities</bodyTitle><subsection id="uid75"><bodyTitle>Informal collaborations</bodyTitle><descriptionlist><label>University of Princeton</label><li id="uid76"><p>We have an active
collaboration with the Liberty group (David August) at University
of Princeton in the past year. The goal is to unify our approach
in modular simulation within the UNISIM framework
and thus increase the likelihood that a joint environment
be adopted by the wider community. This interaction is further
synchronized with the Common Simulation Platform activity of the
HiPEAC network. Starting January 2005, we obtained an ``Joint
Team'' grant called MODSIM, together with the Liberty group at
University of Princeton.</p></li><label>University of California Santa Cruz</label><li id="uid77"><p>Thanks to a
France-Berkeley travel grant, We are starting a collaboration with the
group of Jose Renau, thanks to a 2006-2007 France-Berkeley grant. The
topics are close to the infrastructure work of Alchemy: fast and
accurate simulation of multi-core processors, and support for a modern
parallelisation infrastructure in GCC. Jose Renau is a member of the
OpenSparc consortium and contributed to major advances in architecture
and compiler support for thread-level speculation.</p></li><label>University of Edinburgh</label><li id="uid78"><p>For the past 2 years, we had a very active
cooperation with University of Edinburgh on iterative optimization;
Grigori Fursin, postdoc in our group, got his PhD from University Edinburgh.
This collaboration has resulted in a series of joint articles <ref xlink:href="#bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>, <ref xlink:href="#bid73" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p></li><label>University of Illinois</label><li id="uid79"><p>We have a regular collaboration with the
group of David Padua, Urbana-Champaign, Illinois, which started 6
years ago, with multiple joint publications and travel grants
(CNRS-UIUC). Research focused on high-performance Java, dependence
and alias analysis, processors in memory, and currently on adaptive
program generation and machine learning compilers.</p></li><label>Texas A&amp;M University</label><li id="uid80"><p>We started a regular exchange of ideas
and personnel with the Parasol laboratory, led by Lawrence
Rauchwerger, a reference in parallel language compilation and
architecture support. ProfṘauchwerger visited Alchemy for a total
of 5 months in the last 3 years, and many of us visited TAMU for
shorter periods. The collaboration led to numerous advances in the
understanding of the main challenges and pitfals in scalable parallel
processing, and also facilites the organization of multiple academic
events (e.g., the upcoming PACT'07)</p></li><label>UPC</label><li id="uid81"><p>We have a regular collaboration with UPC, Barcelona, which started 7 years ago,
with several groups on topics ranging from program optimization to
micro-architecture, resulting in several publications, joint contracts.</p></li><label>University of Passau</label><li id="uid82"><p>We have a regular collaboration with the
group of Christian Lengauer and Martin Griebl, Passau, Germany,
which started 10 years ago, with multiple joint publications and
travel grants (Procope, Ministry of Foreign Affairs). Our
collaboration focused on polyhedral compilation techniques and
recently headed towards domain-specific program generation and
metaprogramming.</p></li><label>Lal-LPT, University of Paris Sud</label><li id="uid83"><p>We have started a collaboration
with physicists working on LQCD (Lattice Quantic Chromo
Dynamics). We focus on the next generation of computer that would
gain an order of magnitude speedup over their current APE-next
processor (sustained 300 GFlops).</p></li><label>Paris 6 University</label><li id="uid84"><p>The properties of biological neural networks that are of direct interest to architecture research are in part due to the intrinsic properties of the individual neurons. We are collaborating with the neuroscience research lab ANIM (INSERM U742) to develop simulation and modelling studies of specific properties of individual biological neurons such as time handling or plasticity and memory properties <ref xlink:href="#bid72" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="911584917021"/>.</p></li><label>Project-Team TAO, INRIA Futurs</label><li id="uid85"><p>We started a collaboration with Marc Schoenauer on evolutionary algorithms for optimization of complex systems. More precisely, we study evolutionary methods to optimize the complex structure of large size neural networks. The aim is to find wether there exists optimal organizations for the interconnect network of such large systems. This collaboration grounds F. Jiang's Ph.D. work, which is co-supervised and co-founded by the two groups.</p></li><label>CEA List</label><li id="uid86"><p>For the past 6 years, we had a regular collaboration
with the <i>Laboratoire Sûreté du Logiciel</i> (Software Safety
Lab) at CEA LIST on two topics: processor simulation and program
optimization. Simulation of complex processor architectures is
necessary for the development of software test of complex systems
investigated at CEA. Program optimization is more a way to factor
in the CEA expertise in static analysis and develop new
applications. CEA has funded two scholarships in our group until 2004 and 2005
respectively.</p></li><label>Others</label><li id="uid87"><p>We also have regular contacts with several foreign research groups:
the CAPSL group at University of
Delaware; and the PASCAL group at University of California Irvine
(NSF-INRIA grant).</p><p>Hugues Berry collaborates with Bruno Cessac (Institut Non Linéaire de
Nice, UMR 6618 CNRS / Université Nice-Sophia Antipolis), Bruno Delord
(ANIM, UMR 742 Inserm / Université Pierre et Marie Curie, Paris),
Stéphane Genet (ANIM, UMR 742 Inserm / Université Pierre et Marie
Curie, Paris), Mathias Quoy (ETIS, UMR 8051 CNRS / Université de
Cergy-Pontoise / ENSEA), Olivier Michel (Ibisc, Université d'Evry),
Marc Schoenauer (TAO, INRIA Futurs, Orsay), Nazim Fates (MAIA, INRIA Loraine, Nancy).</p></li></descriptionlist></subsection><subsection id="uid88"><bodyTitle>Seminar and invited scientists</bodyTitle><p><span class="smallcap" align="left">Alchemy</span> organizes a joint seminar with CRI (Centre
de Recherches en Informatique, Ecole des Mines de Paris), LRI
(Laboratoire de Recherches en Informatique, University of Paris-Sud) and
PriSM ( University of Versailles-Saint-Quentin).
Talks of 2006 are given below.</p><simplelist><li id="uid89"><p>januray 23rd, 2006, <i>Hybrid Optimization</i>, John Cavazos,
University of Edinburgh, UK.</p></li><li id="uid90"><p>february 24th, 2006, <i>Temporal Memory Streaming</i>, Babak
Falsafi, Carnegie Mellon University.</p></li><li id="uid91"><p>april 28th, 2006, <i>Dynamic selective compilation and scheduling of
Byte-Code</i>, Prof. Stefano Crespi-Reghizzi, Politecnico di Milano.</p></li><li id="uid92"><p>may 5th, 2006, <i>Efficiently Exploring Architectural Design
Spaces via Predictive Modeling</i>, Sally A. McKee, Cornell University
Computer Systems Lab.</p></li><li id="uid93"><p>june 2nd, 2006, <i>The Tensor Contraction Engine (TCE): A
High-Level Approach to Synthesizing High-Performance Codes for
Quantum Chemistry</i>, J. Ramanujam, Distinguished Professor, Louisiana
State University.</p></li><li id="uid94"><p>june 14th, 2006, <i>A fresh look at the design of high-end
parallel computing systems</i>, Guang R. R. Gao, Endowed Distinguished
Professor, University of Delaware.</p></li><li id="uid95"><p>november 7th, 2006, <i>Evolution, Fractals and Complex
interactions</i>, Evelyne Lutton, COMPLEX Team manager, INRIA.</p></li><li id="uid96"><p>november 14th, 2006, <i>Conception, Semantics and
Implementation of ReactiveML</i>, Louis Mandel, MOSCOVA team, INRIA.</p></li><li id="uid97"><p>december 12th, 2006, <i>Extracting coarse-grained parallelism
with the slicing framework</i>, Anna Beletska, Politecnico di Milano.</p></li></simplelist><p>Erven Rohou (ST-MicroElectronics, Lugano, Switzerland), visited
<span class="smallcap" align="left">Alchemy</span> twice for one week in 2006.</p><p>Marc Duranton (Philips NXP, Eindhoven, Netherlands) visits <span class="smallcap" align="left">Alchemy</span> regularly.</p><p>Lawrence Rauchwerger from Texas A&amp;M University spent two months in
our group, first as a invited professor supported by LRI in July 2006, and
again as an invited professor supported by INRIA Futurs in December 2006.</p></subsection></international><diffusion id="uid98"><bodyTitle>Dissemination</bodyTitle><subsection id="uid99"><bodyTitle>Leadership within scientific community</bodyTitle><descriptionlist><label>Cédric Bastoul</label><li id="uid100"><p> </p><simplelist><li id="uid101"><p>Member of the LRI department committee at the
University of Paris-Sud of Paris-Sud since 2006.</p></li><li id="uid102"><p>Member of the Orsay Technology Institute (IUT D'Orsay)
Computer Science department committee since 2006.</p></li></simplelist></li><label>Albert Cohen</label><li id="uid103"><p> </p><simplelist><li id="uid104"><p>HiPEAC Summer School course on GCC (55-65 attendees). The support material for the courses and tutorials is freely available
(public domain or GPL license) and has been contributed to the main
GCC site (<tt>gcc.gnu.org</tt>, Wiki section; see also
<tt>www.hipeac.net/gcc-tutorial</tt>).</p></li><li id="uid105"><p>HiPEAC GCC Tutorial in Grenoble (France), in May 2006. A second HiPEAC GCC Tutorial will be associated with the second HiPEAC International
Conference, taking place in Ghent (Belgium) in January 2007.</p></li><li id="uid106"><p>Founding member of IFIP WG 2.11.</p></li><li id="uid107"><p>Recruiting committee for INRIA Futurs research scientists, 2004
and 2006.</p></li><li id="uid108"><p>Competitive oral examination, Écoles Normales Supérieures (TIPE
d'informatique), 2004–2006.</p></li></simplelist></li><label>Christine Eisenbeis</label><li id="uid109"><p> </p><simplelist><li id="uid110"><p>member of IFIP WG 10.3.</p></li></simplelist></li><label>Olivier Temam</label><li id="uid111"><p> </p><simplelist><li id="uid112"><p>ANR Future Processor Architectures grants evaluation committee, 2006.</p></li><li id="uid113"><p>HiPEAC Summer School course on UNISIM in 2005, tutorials at UPC in 2006 and scheduled at HiPEAC
Conference in 2007.</p></li></simplelist></li></descriptionlist><p rend="flushed-left"><span class="smallcap" align="left">Program Committees:</span></p><descriptionlist><label>Albert Cohen</label><li id="uid114"><p> </p><simplelist><li id="uid115"><p>Co-organizer of Dagstuhl seminar 07361,
September 2007, with Sam Midkiff (Purdue), Maria-Jesus Garzaran
(University of Illinois at Urbana-Champaign), and Christian Lengauer
(Passau University).</p></li><li id="uid116"><p>Workshop chair for IEEE Conference on Parallel Architectures and
Compilation Techniques (PACT'06, 4 associated workshops).</p></li><li id="uid117"><p>Editorial committee of ACM Transactions on Embedded Systems
(TECS, special issue on software and compilers).</p></li><li id="uid118"><p>Program committee member of the ACM symp. on Principles and
Practice of Parallel Programming (PPoPP'07).</p></li><li id="uid119"><p>Program committee member of the ACM symp. on
Partial Evaluation and Program Manipulation (PEPM'07).</p></li></simplelist></li><label>Christine Eisenbeis</label><li id="uid120"><p> </p><simplelist><li id="uid121"><p>reviewer of the PhDs of Bénédicte Kenmei, Université de
Strasbourg, june 27th, 2006, Mauricio Araya, Université de Nice and Inria Sophia-Antipolis,
november 24th, 2006, and Rachid Seghir, Université de
Strasbourg, december 7th, 2006.</p></li><li id="uid122"><p>Software and Compilers for Embedded Systems, SCOPES' 2007,
April 2007, Nice.</p></li><li id="uid123"><p>IFIP International Conference on Network and Parallel Computing
(NPC 2007), September 2007, China.</p></li></simplelist></li><label>Frédéric Gruau</label><li id="uid124"><p> </p><simplelist><li id="uid125"><p>Co-organizer (with Jean-Louis Giavitto, LaMI, Evry and André
Dehon, University of Pennsylvania) of the Dagstuhl seminar on ``Spatial Computing'', September, 2006.</p></li></simplelist></li><label>Olivier Temam</label><li id="uid126"><p> </p><simplelist><li id="uid127"><p>ISCA, International Symposium on Computer Architecture, 2007.</p></li><li id="uid128"><p>SMART, Workshop on Statistical and Machine learning approaches applied to ARchitectures and compilaTion, 2007.</p></li><li id="uid129"><p>CGO, ACM/IEEE International Symposium on Code Generation and Optimization, 2007.</p></li><li id="uid130"><p>HPCA, High-Performance Computer Architecture, 2007.</p></li><li id="uid131"><p>MoBS, Workshop on Modeling, Benchmarking and Simulation, 2006.</p></li><li id="uid132"><p>ISCA, International Symposium on Computer Architecture, 2006.</p></li><li id="uid133"><p>HiPEAC'07, International Conference on High-Performance Embedded Architectures and Compilers, 2007.</p></li><li id="uid134"><p>DATE, Design and Automation and Test in Europe, 2006.</p></li></simplelist></li></descriptionlist></subsection><subsection id="uid135"><bodyTitle>Teaching at university</bodyTitle><p>Hugues Berry gave two courses :</p><descriptionlist><label>April 13th, 2006,</label><li id="uid136"><p>UFR des Sciences Pharmaceutiques de Caen: "Apport de la modélisation mathématique à l'étude de la dynamique des systèmes cellulaires", Cours (3 heures) dans le cadre de l'UE "Biologie moleculaire de la cellule" du Master Sciences Biologiques et Médicales (4ème année des étude de pharmacie).</p></li><label>November 20th, 2006,</label><li id="uid137"><p>Université de Cergy Pontoise: Cours (3
heures) dans le cadre de la seconde année du Master Recherche
"Matière Organisée et Systèmes Vivants".</p></li></descriptionlist><p>Olivier Temam teaches a computer architecture course at Ecole
Polytechnique to 3rd-year students on computer architectures (appr. 35
hours).
He also teaches a course on novel
processor architectures at University of Paris Sud to Master's
students.</p></subsection><subsection id="uid138"><bodyTitle>Workshops, seminars, invitations</bodyTitle><p>The project-team members have given the following talks and attended
the following conferences:</p><descriptionlist><label>Hugues Berry</label><li id="uid139"><p> </p><simplelist><li id="uid140"><p>Complex dynamics of microprocessor performances during program execution: regularity, chaos, and others, Conference NKS 2006, Washington D.C., USA, 2006.</p></li><li id="uid141"><p>Structure complexe et émergence dans les réseaux de
neurones biologiques, Workshop AMINA, Monastir, Tunisia, 2006. Chairman of the session ``Implantations Parallèles''.</p></li><li id="uid142"><p>Complex biological systems and computing systems, Evry University &amp; Genopole center, France, 2006.</p></li><li id="uid143"><p>Caractérisation de la performance des microprocesseurs pendant l'exécution de programmes, 9emes Rencontres du Non Linéaire, Paris, France, 2006.</p></li><li id="uid144"><p>Atelier d'épigénomique, Génopole, Evry, 27 janvier 2006.</p></li><li id="uid145"><p>Séminaires de l'unité INSERM ANIM, U472, Université P. et
M. Curie, february 1st, 2006.</p></li><li id="uid146"><p>Séminaires de l'équipe ``Bio-informatique'', L.R.I, Orsay,
february 23rd, 2006.</p></li><li id="uid147"><p>Journée Digiteo Labs ``Architecture'', CEA, Saclay, april 27th,
2006.</p></li><li id="uid148"><p>Séminaires de l'ACI ``Nanosys'', ENST, Paris, october 6th, 2006.</p></li></simplelist></li><label>Christine Eisenbeis</label><li id="uid149"><p> </p><simplelist><li id="uid150"><p>Lal-LRI meeting, march 21st, 2006.</p></li><li id="uid151"><p>Pérenniser la loi de Moore?, Cinquièmes Journées Informatique
de l'IN2P3 et du DAPNIA, september, 2006.</p></li><li id="uid152"><p>Dagstuhl seminar on ``Spatial Computing'', September, 2006;
talk on ``N-synchronous Kahn networks''.</p></li></simplelist></li><label>Sylvain Girbal</label><li id="uid153"><p> </p><simplelist><li id="uid154"><p>First UNISIM tutorial: Learning the Basics of UNISIM. 5 day tutorial at Barcelona UPC in February 2006.</p></li><li id="uid155"><p>Second UNISIM Tutorial: Prise en main de l'environnement de simulation structurelle UNISIM. Tutoriel d'une journée présenté le 3 octobre 2006 à Sympa'06, Perpignan France.</p></li><li id="uid156"><p>UNISIM tutorial at Philips NXP. 3 days tutorial in Eindhoven, Netherland on December 18-20 2006.</p></li></simplelist></li><label>Frédéric Gruau</label><li id="uid157"><p> </p><simplelist><li id="uid158"><p>Dagstuhl seminar on ``Spatial Computing'', September, 2006;
talk on ``Blob computing''.</p></li></simplelist></li><label>Pierre Palatin</label><li id="uid159"><p> </p><simplelist><li id="uid160"><p>Talk at Micro-39 (9–13 Decembre 2006, Orlando, Florida, USA); "CAPSULE:
Hardware-Assisted Parallel Execution of Component-Based Programs".</p></li><li id="uid161"><p>Talk at Hipeac 1st Industrial Workshop (11th May 2006, Grenoble, France),
with ST-Microelectronics : "CAPSULE: Hardware-Assisted Parallel Execution of
Component-Based Programs".</p></li><li id="uid162"><p>Informal presentation of "Capsule" at a NANOSYS project meeting (5th
November 2006). NANOSYS is an "ACI nanosciences" project
called "Architectures pour l'intégration des nanocomposants
moléculaires".</p></li></simplelist></li></descriptionlist></subsection></diffusion><biblio id="bibliography" html="bibliography" titre="Bibliography" numero="10"><biblStruct id="bid4" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Using Machine Learning to Focus Iterative Optimization</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Agakov</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Bonilla</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Cavazos</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Franke</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Thomson</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Toussaint</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">C.</foreName><surname full="yes" TEIform="surname">Williams</surname><initial>C.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the 4th Annual International Symposium on Code Generation and Optimization (CGO)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:ABCP06</note></biblStruct><biblStruct id="bid85" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Putting Polyhedral Loop Transformations to Work</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Cédric</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Saurabh</foreName><surname full="yes" TEIform="surname">Sharma</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Workshop on Languages and Compilers for Parallel Computing (LCPC'03), College Station, Texas</title><title level="s" TEIform="title">LNCS</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">Springer-Verlag</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">October</month><year full="yes" TEIform="year">2003</year></dateStruct><biblScope type="pages" TEIform="biblScope">23–30</biblScope><ref xlink:href="http://www-rocq.inria.fr/~acohen/publications/BCGST03.ps.gz" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="4119659692025">http://www-rocq.inria.fr/~acohen/publications/BCGST03.ps.gz</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:BCGST03b</note></biblStruct><biblStruct id="bid50" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Chaos in computer performance</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Hugues</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniel</foreName><surname full="yes" TEIform="surname">Gracia Pérez</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Chaos</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">16</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">013110</biblScope><ref xlink:href="http://hal.inria.fr/inria-00000109/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="4252598866015">http://hal.inria.fr/inria-00000109/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:BGT05</note></biblStruct><biblStruct id="bid86" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">N-Sychronous Kahn Networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Marc</foreName><surname full="yes" TEIform="surname">Duranton</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Christine</foreName><surname full="yes" TEIform="surname">Eisenbeis</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Claire</foreName><surname full="yes" TEIform="surname">Pagetti</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Plateau</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Marc</foreName><surname full="yes" TEIform="surname">Pouzet</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">33th ACM Symp. on Principles of Programming Languages (PoPL'06), Charleston, South Carolina</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">January</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">180–193</biblScope><ref xlink:href="http://www-rocq.inria.fr/~acohen/publications/CDEPPP06.ps.gz" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="345719591020">http://www-rocq.inria.fr/~acohen/publications/CDEPPP06.ps.gz</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:CDEPPP06</note></biblStruct><biblStruct id="bid42" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Blob Computing</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Frederic</foreName><surname full="yes" TEIform="surname">Gruau</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Yves</foreName><surname full="yes" TEIform="surname">Lhuillier</surname><initial>Y.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Philippe</foreName><surname full="yes" TEIform="surname">Reitz</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Computing Frontiers 2004 ACM SIGMicro.</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2004</year></dateStruct><ref xlink:href="http://blob.lri.fr/publication/2004-model-blob-machine.pdf" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3535853265003">http://blob.lri.fr/publication/2004-model-blob-machine.pdf</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:blob_computing2004</note></biblStruct><biblStruct id="bid54" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">MicroLib: A Case for the Quantitative Comparison of Micro-Architecture Mechanisms</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniel Gracia</foreName><surname full="yes" TEIform="surname">Pérez</surname><initial>D. G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Gilles</foreName><surname full="yes" TEIform="surname">Mouchard</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">MICRO-37: Proceedings of the 37th International Symposium on Microarchitecture</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE Computer Society</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Dec</month><year full="yes" TEIform="year">2004</year></dateStruct><biblScope type="pages" TEIform="biblScope">43–54</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:GMT04</note></biblStruct><biblStruct id="bid87" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">On increasing architecture awareness in program optimizations to bridge the gap between peak and sustained processor performance : Matrix-Multiply revisited</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">David</foreName><surname full="yes" TEIform="surname">Parello</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jean-Marie</foreName><surname full="yes" TEIform="surname">Verdun</surname><initial>J.-M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Supercomputing</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Nov</month><year full="yes" TEIform="year">2002</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:alchemy8</note></biblStruct><biblStruct id="bid68" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Induction Variable Analysis with Delayed Abstractions</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">S.</foreName><surname full="yes" TEIform="surname">Pop</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.-A.</foreName><surname full="yes" TEIform="surname">Silber</surname><initial>G.-A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Intl. Conf. on High Performance Embedded Architectures and Compilers (HiPEAC'05), Barcelona, Spain</title><title level="s" TEIform="title">LNCS</title><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">3793</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer-Verlag</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">November</month><year full="yes" TEIform="year">2005</year></dateStruct><biblScope type="pages" TEIform="biblScope">218–232</biblScope><ref xlink:href="http://www-rocq.inria.fr/~acohen/publications/PCS05.ps.gz" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2736055840031">http://www-rocq.inria.fr/~acohen/publications/PCS05.ps.gz</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:PCS05</note></biblStruct><biblStruct id="bid29" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Violated dependence analysis</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Nicolas</foreName><surname full="yes" TEIform="surname">Vasilache</surname><initial>N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Cédric</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the ACM International Conference on Supercomputing (ICS'06), Cairns, Australia</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">ACM</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">refer</note><note type="userid" place="unspecified" anchored="yes">refercite:VBGC06</note></biblStruct><biblStruct id="bid70" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Chaos in computer performance</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Hugues</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniel</foreName><surname full="yes" TEIform="surname">Gracia Pérez</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Chaos</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">16</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">013110</biblScope><ref xlink:href="http://hal.inria.fr/inria-00000109/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="4252598866015">http://hal.inria.fr/inria-00000109/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:BGT05</note></biblStruct><biblStruct id="bid74" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Adsorption-induced fibronectin aggregation and fibrillogenesis</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Hugues</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Delphine</foreName><surname full="yes" TEIform="surname">Pellenc</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Gallet</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Journal of Colloid and Interface Science</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00001063/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3719192714025">http://hal.inria.fr/inria-00001063/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:BERRY-2006-56919</note></biblStruct><biblStruct id="bid48" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Structure and dynamics of random recurrent neural networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Quoy</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Adaptive Behavior</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">14</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">129-137</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:BQ06</note></biblStruct><biblStruct id="bid46" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Modeling Self-Developping Biological Neural Networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">O.</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Neurocomputing</title><note type="bnote" place="unspecified" anchored="yes">in press</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:BT06</note></biblStruct><biblStruct id="bid75" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">In Search of a Program Generator to Implement Generic Transformations for High-Performance Computing</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">S.</foreName><surname full="yes" TEIform="surname">Donadio</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.-J.</foreName><surname full="yes" TEIform="surname">Garzaran</surname><initial>M.-J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">C.</foreName><surname full="yes" TEIform="surname">Herrmann</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">O.</foreName><surname full="yes" TEIform="surname">Kiselyov</surname><initial>O.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">David</foreName><surname full="yes" TEIform="surname">Padua</surname><initial>D.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Science of Computer Programming</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">62</biblScope><biblScope type="number" TEIform="biblScope">1</biblScope><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">September</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">25-46</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:CDGHKP06</note></biblStruct><biblStruct id="bid73" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Quick and practical run-time evaluation of multiple program optimizations</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Grigori</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Michael F. P.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M. F. P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Trans. on High Performance Embedded Architectures and Compilers</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">1</biblScope><biblScope type="number" TEIform="biblScope">1</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">13-31</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:FCOT06</note></biblStruct><biblStruct id="bid27" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Semi-Automatic Composition of Loop Transformations for Deep Parallelism and Memory Hierarchies</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Nicolas</foreName><surname full="yes" TEIform="surname">Vasilache</surname><initial>N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Cédric</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">David</foreName><surname full="yes" TEIform="surname">Parello</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Marc</foreName><surname full="yes" TEIform="surname">Sigler</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Intl. J. of Parallel Programming</title><note type="bnote" place="unspecified" anchored="yes">Accepted with minor revisions</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:GVBCPST06</note></biblStruct><biblStruct id="bid62" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">The Practicality Dimension of Sampling</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Gracia Pérez</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">O.</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">IEEE Micro</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">26</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">14–28</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:PBT06</note></biblStruct><biblStruct id="bid76" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">An Efficient Memory Operations Optimization Technique for Vector Loops on Itanium 2 Processors</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">William</foreName><surname full="yes" TEIform="surname">Jalby</surname><initial>W.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Christophe</foreName><surname full="yes" TEIform="surname">Lemuet</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sid</foreName><surname full="yes" TEIform="surname">Touati</surname><initial>S.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Concurrency and Computation: Practice and Experience</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">11</biblScope><biblScope type="number" TEIform="biblScope">11</biblScope><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">September</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">1485–1508</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Jal06</note></biblStruct><biblStruct id="bid77" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Systematic search within an optimisation space based on Unified Transformation Framework</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">S.</foreName><surname full="yes" TEIform="surname">Long</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Accepted for the special issue of the International Journal of Computational Science and Engineering (IJCSE)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:LF2006</note></biblStruct><biblStruct id="bid78" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Using Machine Learning to Focus Iterative Optimization</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Agakov</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Bonilla</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Cavazos</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Franke</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Thomson</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Toussaint</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">C.</foreName><surname full="yes" TEIform="surname">Williams</surname><initial>C.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the 4th Annual International Symposium on Code Generation and Optimization (CGO)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:ABCP06</note></biblStruct><biblStruct id="bid79" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Beyond Iteration Vectors: Instancewise Relational Abstract Domains</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Amiranoff</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">A.</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Feautrier</surname><initial>P.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Static Analysis Symposium (SAS'06), Seoul, Corea</title><note type="bnote" place="unspecified" anchored="yes">To appear.</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">August</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:ACF06</note></biblStruct><biblStruct id="bid80" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Structure complexe et émergence dans les réseaux de neurones biologiques</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">3ème Workshop Applications Médicales de l'Informatique: Nouvelles Approches, AMINA 2006, Monastir, Tunisia</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">November</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">conference</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:AMINA2006</note></biblStruct><biblStruct id="bid71" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Caractérisation de la performance des microprocesseurs pendant l'exécution de programmes</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Gracia Pérez</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">O.</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">9emes Rencontres du Non LinÃ©aire, Paris, France</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">March</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">conference</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:RNL2006</note></biblStruct><biblStruct id="bid49" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Complex dynamics of microprocessor performances during program execution: Regularity, chaos, and others</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Gracia Pérez</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">O.</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">NKS2006 Wolfram Science Conference, Washington D.C., USA</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">conference</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:BGT06</note></biblStruct><biblStruct id="bid2" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Automatic Performance Model Construction for the Fast Software Exploration of New Hardware Designs</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">John</foreName><surname full="yes" TEIform="surname">Cavazos</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Christophe</foreName><surname full="yes" TEIform="surname">Dubach</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Felix</foreName><surname full="yes" TEIform="surname">Agakov</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Edwin</foreName><surname full="yes" TEIform="surname">Bonilla</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Michael</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Grigori</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">International Conference on Compilers, Architecture, And Synthesis For Embedded Systems (CASES 2006)</title><note type="bnote" place="unspecified" anchored="yes">To appear</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">October</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:CDAP2006</note></biblStruct><biblStruct id="bid33" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">N-Sychronous Kahn Networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Marc</foreName><surname full="yes" TEIform="surname">Duranton</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Christine</foreName><surname full="yes" TEIform="surname">Eisenbeis</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Claire</foreName><surname full="yes" TEIform="surname">Pagetti</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Plateau</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Marc</foreName><surname full="yes" TEIform="surname">Pouzet</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">33th ACM Symp. on Principles of Programming Languages (PoPL'06), Charleston, South Carolina</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">January</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">180–193</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:CDEPPP06</note></biblStruct><biblStruct id="bid81" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">The Data-Flow Equations of Checkpointing in Reverse Automatic Differentiation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Benjamin</foreName><surname full="yes" TEIform="surname">Dauvergne</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Laurent</foreName><surname full="yes" TEIform="surname">Hascoët</surname><initial>L.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Workshop on Automatic Differentiation: Tools and Applications, Reading</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">May</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Dau06</note></biblStruct><biblStruct id="bid72" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">On the propagation of Ca-dependent plateau and valley potentials in cerebellar Purkinje cells and how they drive the cell output</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">S.</foreName><surname full="yes" TEIform="surname">Genet</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Delord</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">L.</foreName><surname full="yes" TEIform="surname">Sabarly</surname><initial>L.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Guigon</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of NeuroComp'06, Pont-à-Mousson, France</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">23-24 October</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">167–170</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">conference</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:NeuroComp2006_1</note></biblStruct><biblStruct id="bid52" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Budgeted Region Sampling (BeeRS): Do Not Separate Sampling From Warm-Up, And Then Spend Wisely Your Simulation Budget</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniel</foreName><surname full="yes" TEIform="surname">Gracia Pérez</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Hugues</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">5th IEEE International Symposium on Signal Processing and Information Technology 5th IEEE International Symposium on Signal Processing and Information Technology, Athens, Greece</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00001061/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="596145299025">http://hal.inria.fr/inria-00001061/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:GBT06</note></biblStruct><biblStruct id="bid40" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Capsule : Hardware-Assisted Parallel Execution of Component-Based Programs</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Palatin</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Y.</foreName><surname full="yes" TEIform="surname">Lhuillier</surname><initial>Y.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">O.</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">The 39th Annual IEEE/ACM International Symposium on Microarchitecture, 2006, Orlando, Florida</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">december</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:capsule06</note></biblStruct><biblStruct id="bid30" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">GRAPHITE: Loop optimizations based on the polyhedral model for GCC</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sébastian</foreName><surname full="yes" TEIform="surname">Pop</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">CÃ©dric</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Jouvelot</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.-A.</foreName><surname full="yes" TEIform="surname">Silber</surname><initial>G.-A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">N.</foreName><surname full="yes" TEIform="surname">Vasilache</surname><initial>N.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proc. of the 4th GCC Developper's Summit (to appear), Ottawa, Canada</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:PCBGJSV06</note></biblStruct><biblStruct id="bid82" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">The New Framework for Loop Nest Optimization in GCC: from Prototyping to Evaluation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sébastian</foreName><surname full="yes" TEIform="surname">Pop</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Jouvelot</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.-A.</foreName><surname full="yes" TEIform="surname">Silber</surname><initial>G.-A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proc. of the 12th Workshop Compilers for Parallel Computers (CPC'06), A Coruña, Spain</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">January</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://www-rocq.inria.fr/~acohen/publications/PCJS06.ps.gz" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2606392225027">http://www-rocq.inria.fr/~acohen/publications/PCJS06.ps.gz</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:PCJS06</note></biblStruct><biblStruct id="bid47" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Topological and dynamical structures induced by Hebbian learning in random neural networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Siri</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Cessac</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Delord</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Quoy</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">International Conference on Complex Systems, ICCS 2006, Boston, MA, USA</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">conference</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:SBCDQ06</note></biblStruct><biblStruct id="bid45" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Learning-induced topological effects on dynamics in neural networks</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Siri</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Cessac</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Delord</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Quoy</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">O.</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of NeuroComp'06, Pont-à-Mousson, France</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">23-24 October</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">206–209</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">conference</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:SBCDQT06</note></biblStruct><biblStruct id="bid83" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">On the Decidability of Phase Ordering Problem in Optimizing Compilation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sid</foreName><surname full="yes" TEIform="surname">Touati</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Denis</foreName><surname full="yes" TEIform="surname">Barthou</surname><initial>D.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the International Conference on Computing Frontiers, Ischia, Italy</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">ACM</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">May</month><year full="yes" TEIform="year">2006</year></dateStruct><ref xlink:href="http://www.prism.uvsq.fr/~touati/publis/CF06.pdf" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3566798797023">http://www.prism.uvsq.fr/~touati/publis/CF06.pdf</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Touati-CF-06</note></biblStruct><biblStruct id="bid26" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Polyhedral Code Generation in the Real World</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Nicolas</foreName><surname full="yes" TEIform="surname">Vasilache</surname><initial>N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Cédric</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the International Conference on Compiler Construction (ETAPS CC'06), Vienna, Austria</title><title level="s" TEIform="title">LNCS</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">Springer-Verlag</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">March</month><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">185–201</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:VBC06</note></biblStruct><biblStruct id="bid84" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Violated dependence analysis</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Nicolas</foreName><surname full="yes" TEIform="surname">Vasilache</surname><initial>N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Cédric</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the ACM International Conference on Supercomputing (ICS'06), Cairns, Australia</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">ACM</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:VBGC06</note></biblStruct><biblStruct id="bid3" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Predicting Good Compiler Optimizations using Performance Counters</title><title level="m" TEIform="title">ACM International Conference on Code Generation and Optimization (CGO'07), San Jose, California</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Felix</foreName><surname full="yes" TEIform="surname">Agakov</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">John</foreName><surname full="yes" TEIform="surname">Cavazos</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Grigori</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Mike</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author><note type="bnote" place="unspecified" anchored="yes">to appear</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">March</month><year full="yes" TEIform="year">2007</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">misc</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:hardwarecounters</note></biblStruct><biblStruct id="bid5" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Iterative optimization in the polyhedral model: Part I, one-dimensional time</title><title level="m" TEIform="title">ACM International Conference on Code Generation and Optimization (CGO'07), San Jose, California</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">L.-N.</foreName><surname full="yes" TEIform="surname">Pouchet</surname><initial>L.-N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">C.</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">A.</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">N.</foreName><surname full="yes" TEIform="surname">Vasilache</surname><initial>N.</initial></persName></author><note type="bnote" place="unspecified" anchored="yes">to appear</note><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">March</month><year full="yes" TEIform="year">2007</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">misc</note><note type="from" place="unspecified" anchored="yes">year</note><note type="userid" place="unspecified" anchored="yes">cite:Pou07</note></biblStruct><biblStruct id="bid11" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Using Machine Learning to Focus Iterative Optimization</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">F.</foreName><surname full="yes" TEIform="surname">Agakov</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">E.</foreName><surname full="yes" TEIform="surname">Bonilla</surname><initial>E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Cavazos</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Franke</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Thomson</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Toussaint</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">C.</foreName><surname full="yes" TEIform="surname">Williams</surname><initial>C.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">CGO-4: The Fourth Annual International Symposium on Code Generation and Optimization</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:IC_4</note></biblStruct><biblStruct id="bid61" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Code Generation in the Polyhedral Model Is Easier Than You Think</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Cédric</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">PACT'13 IEEE International Conference on Parallel Architecture and Compilation Techniques, Juan-les-Pins</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">september</month><year full="yes" TEIform="year">2004</year></dateStruct><biblScope type="pages" TEIform="biblScope">7–16</biblScope><ref xlink:href="http://hal.ccsd.cnrs.fr/ccsd-00017260" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2237183011020">http://hal.ccsd.cnrs.fr/ccsd-00017260</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Bas2004</note></biblStruct><biblStruct id="bid60" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Putting Polyhedral Loop Transformations to Work</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Cédric</foreName><surname full="yes" TEIform="surname">Bastoul</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Saurabh</foreName><surname full="yes" TEIform="surname">Sharma</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Workshop on Languages and Compilers for Parallel Computing (LCPC'03), College Station, Texas</title><title level="s" TEIform="title">LNCS</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">Springer-Verlag</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">October</month><year full="yes" TEIform="year">2003</year></dateStruct><biblScope type="pages" TEIform="biblScope">23–30</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:BCGST03b</note></biblStruct><biblStruct id="bid13" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Aestimo: a feedback-directed optimization evaluation tool</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Berube</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.N.</foreName><surname full="yes" TEIform="surname">Amaral</surname><initial>J.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the International Symposium on Performance Analysis of Systems and Software (ISPASS)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Berube</note></biblStruct><biblStruct id="bid56" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">The M5 Simulator: Modeling Networked Systems</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Nathan L.</foreName><surname full="yes" TEIform="surname">Binkert</surname><initial>N. L.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Ronald G.</foreName><surname full="yes" TEIform="surname">Dreslinski</surname><initial>R. G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Lisa R.</foreName><surname full="yes" TEIform="surname">Hsu</surname><initial>L. R.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Kevin T.</foreName><surname full="yes" TEIform="surname">Lim</surname><initial>K. T.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Ali G.</foreName><surname full="yes" TEIform="surname">Saidi</surname><initial>A. G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Steven K.</foreName><surname full="yes" TEIform="surname">Reinhardt</surname><initial>S. K.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">IEEE Micro</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">26</biblScope><biblScope type="number" TEIform="biblScope">4</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct><biblScope type="pages" TEIform="biblScope">52–60</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:M5</note></biblStruct><biblStruct id="bid67" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Deep Jam: Conversion of Coarse-Grain Parallelism to Instruction-Level and Vector Parallelism for Irregular Applications</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Patrick</foreName><surname full="yes" TEIform="surname">Carribault</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">W.</foreName><surname full="yes" TEIform="surname">Jalby</surname><initial>W.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Parallel Architectures and Compilation Techniques (PACT'05), St-Louis, Missouri</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName type="organisation" TEIform="orgName">IEEE Computer Society<address TEIform="address"/></orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">September</month><year full="yes" TEIform="year">2005</year></dateStruct><biblScope type="pages" TEIform="biblScope">291–300</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:CCJ05</note></biblStruct><biblStruct id="bid31" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Ambient Intelligence: Impact on Embedded-System Design</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Z.</foreName><surname full="yes" TEIform="surname">Chamski</surname><initial>Z.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Duranton</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">A.</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">C.</foreName><surname full="yes" TEIform="surname">Eisenbeis</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Feautrier</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Genius</surname><initial>D.</initial></persName></author></analytic><monogr TEIform="monogr"><imprint TEIform="imprint"><biblScope type="chapter" TEIform="biblScope">Application Domain-Driven System Design for Pervasive Video Processing</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Kluwer Academic Press</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2003</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inbook</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:CDCEFG03</note></biblStruct><biblStruct id="bid32" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Multi-Periodic Process Networks: Prototyping and Verifying Stream-Processing Systems</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniela</foreName><surname full="yes" TEIform="surname">Genius</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">A.</foreName><surname full="yes" TEIform="surname">Kortebi</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Z.</foreName><surname full="yes" TEIform="surname">Chamski</surname><initial>Z.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Marc</foreName><surname full="yes" TEIform="surname">Duranton</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Paul</foreName><surname full="yes" TEIform="surname">Feautrier</surname><initial>P.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Euro-Par'02, Paderborn, Germany</title><title level="s" TEIform="title">LNCS</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">2400</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer-Verlag</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">August</month><year full="yes" TEIform="year">2002</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:CGKCDF02a</note></biblStruct><biblStruct id="bid28" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Facilitating the Search for Compositions of Program Transformations</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">David</foreName><surname full="yes" TEIform="surname">Parello</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Sigler</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Nicolas</foreName><surname full="yes" TEIform="surname">Vasilache</surname><initial>N.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">ACM Intl. Conf. on Supercomputing (ICS'05), Boston, Massachusetts</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2005</year></dateStruct><biblScope type="pages" TEIform="biblScope">151–160</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:CGPSTV05</note></biblStruct><biblStruct id="bid17" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A Polyhedral Approach to Ease the Composition of Program Transformations</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Euro-Par'04, Pisa, Italy</title><title level="s" TEIform="title">LNCS</title><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">3149</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer-Verlag</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">August</month><year full="yes" TEIform="year">2004</year></dateStruct><biblScope type="pages" TEIform="biblScope">292–303</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:CGT04</note></biblStruct><biblStruct id="bid7" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">ACME: adaptive compilation made efficient</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Keith D.</foreName><surname full="yes" TEIform="surname">Cooper</surname><initial>K. D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Alexander</foreName><surname full="yes" TEIform="surname">Grosul</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Timothy J.</foreName><surname full="yes" TEIform="surname">Harvey</surname><initial>T. J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Steven</foreName><surname full="yes" TEIform="surname">Reeves</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Devika</foreName><surname full="yes" TEIform="surname">Subramanian</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Linda</foreName><surname full="yes" TEIform="surname">Torczon</surname><initial>L.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Todd</foreName><surname full="yes" TEIform="surname">Waterman</surname><initial>T.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2005</year></dateStruct><biblScope type="pages" TEIform="biblScope">69–77</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:IC_1</note></biblStruct><biblStruct id="bid1" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Adaptive Optimizing Compilers for the 21st Century</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Keith D.</foreName><surname full="yes" TEIform="surname">Cooper</surname><initial>K. D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Devika</foreName><surname full="yes" TEIform="surname">Subramanian</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Linda</foreName><surname full="yes" TEIform="surname">Torczon</surname><initial>L.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">J. Supercomput.</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">23</biblScope><biblScope type="number" TEIform="biblScope">1</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2002</year></dateStruct><biblScope type="pages" TEIform="biblScope">7–22</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:603341</note></biblStruct><biblStruct id="bid18" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Quickly building an optimizer for complex embedded architectures</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Michaël</foreName><surname full="yes" TEIform="surname">Dupré</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Nathalie</foreName><surname full="yes" TEIform="surname">Drach</surname><initial>N.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">International Symposium on Code Generation and Optimization</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">ACM/IEEE</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Mar</month><year full="yes" TEIform="year">2004</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:DDT04</note></biblStruct><biblStruct id="bid20" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Dataflow Analysis of Array and scalar references</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Feautrier</surname><initial>P.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Int. J. of Parallel Programming</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">20</biblScope><biblScope type="number" TEIform="biblScope">1</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1991</year></dateStruct><biblScope type="pages" TEIform="biblScope">23-53</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Feau1</note></biblStruct><biblStruct id="bid21" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Some efficient solutions to the affine scheduling problem I. One-dimensional time</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Feautrier</surname><initial>P.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Int. J. of Parallel Programming</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">21</biblScope><biblScope type="number" TEIform="biblScope">5</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1992</year></dateStruct><biblScope type="pages" TEIform="biblScope">313-347</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Feau2</note></biblStruct><biblStruct id="bid22" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Some efficient solutions to the affine scheduling problem II. Multi-dimensional time</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Feautrier</surname><initial>P.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Int. J. of Parallel Programming</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">21</biblScope><biblScope type="number" TEIform="biblScope">6</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1992</year></dateStruct><biblScope type="pages" TEIform="biblScope">389-420</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Feau3</note></biblStruct><biblStruct id="bid9" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Probabilistic Source-Level Optimisation of Embedded Programs</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Franke</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.F.P.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Thomson</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2005</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:franke</note></biblStruct><biblStruct id="bid66" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Probabilistic Source-Level Optimisation of Embedded Systems Software.</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">B.</foreName><surname full="yes" TEIform="surname">Franke</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Thomson</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES'05)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">june</month><year full="yes" TEIform="year">2005</year></dateStruct><biblScope type="pages" TEIform="biblScope">pages 78-86</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:FOTF05</note></biblStruct><biblStruct id="bid6" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A Practical Method For Quickly Evaluating Program Optimizations</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Grigori</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Intl. Conf. on High Performance Embedded Architectures and Compilers (HiPEAC'05), Barcelona, Spain</title><title level="s" TEIform="title">LNCS</title><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">3793</biblScope><publisher TEIform="publisher"><orgName TEIform="orgName">Springer-Verlag</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">November</month><year full="yes" TEIform="year">2005</year></dateStruct><biblScope type="pages" TEIform="biblScope">29–46</biblScope><ref xlink:href="http://hal.inria.fr/inria-00001054/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3350526058007">http://hal.inria.fr/inria-00001054/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:FCOT05</note></biblStruct><biblStruct id="bid8" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Evaluating Iterative Compilation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.G.</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.F.P.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.M.W.</foreName><surname full="yes" TEIform="surname">Knijnenburg</surname><initial>P.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proc. Languages and Compilers for Parallel Computers (LCPC)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2002</year></dateStruct><biblScope type="pages" TEIform="biblScope">305-315</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:FOK02</note></biblStruct><biblStruct id="bid59" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">DiST: A Simple, Reliable and Scalable Method to Significantly Reduce Processor Architecture Simulation Time</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sylvain</foreName><surname full="yes" TEIform="surname">Girbal</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Gilles</foreName><surname full="yes" TEIform="surname">Mouchard</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Intl. Conf. on Measurement and Modeling of Computer Systems, ACM SIGMETRICS'03, San Diego, California</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2003</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:GMCT2003</note></biblStruct><biblStruct id="bid41" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">NanoFabrics: spatial computing using molecular electronics</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">S. C.</foreName><surname full="yes" TEIform="surname">Goldstein</surname><initial>S. C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Budiu</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the 28th annual international symposium on Computer architecture, Göteborg, Sweden</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">ACM Press</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2001</year></dateStruct><biblScope type="pages" TEIform="biblScope">178–191</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:spatialcomputing</note></biblStruct><biblStruct id="bid51" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">IDDCA: A New Clustering Approach For Sampling</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniel</foreName><surname full="yes" TEIform="surname">Gracia Pérez</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Hugues</foreName><surname full="yes" TEIform="surname">Berry</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">MoBS: Workshop on Modeling, Benchmarking, and Simulation MoBS: Workshop on Modeling, Benchmarking, and Simulation, Madison, Wisconsin</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2005</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00001062/en/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="551412829009">http://hal.inria.fr/inria-00001062/en/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:GBT05</note></biblStruct><biblStruct id="bid14" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">MiBench: A free, commercially representative embedded benchmark suite.</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Matthew R.</foreName><surname full="yes" TEIform="surname">Guthaus</surname><initial>M. R.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jeffrey S.</foreName><surname full="yes" TEIform="surname">Ringenberg</surname><initial>J. S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Dan</foreName><surname full="yes" TEIform="surname">Ernst</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Todd M.</foreName><surname full="yes" TEIform="surname">Austin</surname><initial>T. M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Trevor</foreName><surname full="yes" TEIform="surname">Mudge</surname><initial>T.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Richard B.</foreName><surname full="yes" TEIform="surname">Brown</surname><initial>R. B.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">IEEE 4th Annual Workshop on Workload Characterization, Austin, TX</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">December</month><year full="yes" TEIform="year">2001.</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:mibench</note></biblStruct><biblStruct id="bid34" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Detecting coarse-grain parallelism using an interprocedural parallelizing compiler</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Mary H.</foreName><surname full="yes" TEIform="surname">Hall</surname><initial>M. H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Saman P.</foreName><surname full="yes" TEIform="surname">Amarasinghe</surname><initial>S. P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Brian R.</foreName><surname full="yes" TEIform="surname">Murphy</surname><initial>B. R.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Shih-Wei</foreName><surname full="yes" TEIform="surname">Liao</surname><initial>S.-W.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Monica S.</foreName><surname full="yes" TEIform="surname">Lam</surname><initial>M. S.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Supercomputing '95: Proceedings of the 1995 ACM/IEEE conference on Supercomputing (CDROM), New York, NY, USA</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">ACM Press</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1995</year></dateStruct><biblScope type="pages" TEIform="biblScope">49</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:hall95detecting</note></biblStruct><biblStruct id="bid36" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Transactional Memory Coherence and Consistency</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Lance</foreName><surname full="yes" TEIform="surname">Hammond</surname><initial>L.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Vicky</foreName><surname full="yes" TEIform="surname">Wong</surname><initial>V.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Mike</foreName><surname full="yes" TEIform="surname">Chen</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Brian D.</foreName><surname full="yes" TEIform="surname">Carlstrom</surname><initial>B. D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">John D.</foreName><surname full="yes" TEIform="surname">Davis</surname><initial>J. D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Ben</foreName><surname full="yes" TEIform="surname">Hertzberg</surname><initial>B.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Manohar K.</foreName><surname full="yes" TEIform="surname">Prabhu</surname><initial>M. K.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Honggo</foreName><surname full="yes" TEIform="surname">Wijaya</surname><initial>H.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Christos</foreName><surname full="yes" TEIform="surname">Kozyrakis</surname><initial>C.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Kunle</foreName><surname full="yes" TEIform="surname">Olukotun</surname><initial>K.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the 31st Annual International Symposium on Computer Architecture</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE Computer Society</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">2004</year></dateStruct><biblScope type="pages" TEIform="biblScope">102</biblScope><ref xlink:href="http://tcc.stanford.edu/publications/tcc_isca2004.pdf" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3799788131001">http://tcc.stanford.edu/publications/tcc_isca2004.pdf</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">incollection</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:hammond:tcc:isca:2004</note></biblStruct><biblStruct id="bid12" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">On the Impact of Data Input Sets on Statistical Compiler Tuning</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">Haneda</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.M.W.</foreName><surname full="yes" TEIform="surname">Knijnenburg</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">H.A.G.</foreName><surname full="yes" TEIform="surname">Wijshoff</surname><initial>H.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Workshop on Performance Optimization for High-Level Languages and Libraries (POHLL)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Haneda</note></biblStruct><biblStruct id="bid35" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Debugging Parallel Systems: A State of the Art Report</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Joel</foreName><surname full="yes" TEIform="surname">Huselius</surname><initial>J.</initial></persName></author><note type="typdoc" place="unspecified" anchored="yes">Technical report</note><imprint TEIform="imprint"><biblScope type="number" TEIform="biblScope">63</biblScope><publisher TEIform="publisher"><orgName type="institution" TEIform="orgName">Mälardalen University, Department of Computer Science and Engineering</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">September</month><year full="yes" TEIform="year">2002</year></dateStruct><ref xlink:href="citeseer.ist.psu.edu/huselius02debugging.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="599237378000">citeseer.ist.psu.edu/huselius02debugging.html</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">techreport</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:huselius_2002</note></biblStruct><biblStruct id="bid10" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Fast searches for effective optimization phase sequence</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Kulkarni</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">S.</foreName><surname full="yes" TEIform="surname">Hines</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Hiser</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Whalley</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.</foreName><surname full="yes" TEIform="surname">Davidson</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">D.</foreName><surname full="yes" TEIform="surname">Jones</surname><initial>D.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proc. ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2004</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:kulkarni2004</note></biblStruct><biblStruct id="bid39" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">AP+SOMT: AgentProgramming SelfOrganized</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Yves</foreName><surname full="yes" TEIform="surname">Lhuillier</surname><initial>Y.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">International Workshop on Complexity-Effective Design, Munich, Germany</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">ISCA</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">May</month><year full="yes" TEIform="year">2004</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:LT04</note></biblStruct><biblStruct id="bid65" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A heuristic search algorithm based on Unified Transformation Framework</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Shun</foreName><surname full="yes" TEIform="surname">Long</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Grigori</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the 7th International Workshop on High Performance Scientific and Engineering Computing (HPSEC-05)</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">june</month><year full="yes" TEIform="year">2005</year></dateStruct><biblScope type="pages" TEIform="biblScope">pages 137-144</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:LoFu05</note></biblStruct><biblStruct id="bid37" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">High Performance Fortran</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">David B.</foreName><surname full="yes" TEIform="surname">Loveman</surname><initial>D. B.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">IEEE Parallel Distrib. Technol.</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">1</biblScope><biblScope type="number" TEIform="biblScope">1</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1993</year></dateStruct><biblScope type="pages" TEIform="biblScope">25–42</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:613797</note></biblStruct><biblStruct id="bid57" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Simics: A Full System Simulation Platform</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Peter S.</foreName><surname full="yes" TEIform="surname">Magnusson</surname><initial>P. S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Magnus</foreName><surname full="yes" TEIform="surname">Christensson</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Jesper</foreName><surname full="yes" TEIform="surname">Eskilson</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniel</foreName><surname full="yes" TEIform="surname">Forsgren</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Gustav</foreName><surname full="yes" TEIform="surname">Hallberg</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Johan</foreName><surname full="yes" TEIform="surname">Hogberg</surname><initial>J.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Fredrik</foreName><surname full="yes" TEIform="surname">Larsson</surname><initial>F.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Andreas</foreName><surname full="yes" TEIform="surname">Moestedt</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Bengt</foreName><surname full="yes" TEIform="surname">Werner</surname><initial>B.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Computer</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">35</biblScope><biblScope type="number" TEIform="biblScope">2</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2002</year></dateStruct><biblScope type="pages" TEIform="biblScope">50-58</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:simics</note></biblStruct><biblStruct id="bid24" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Efficient and Exact Data Dependency Analysis</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Dror E.</foreName><surname full="yes" TEIform="surname">Maydan</surname><initial>D. E.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">John L.</foreName><surname full="yes" TEIform="surname">Hennessy</surname><initial>J. L.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Monica S.</foreName><surname full="yes" TEIform="surname">Lam</surname><initial>M. S.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">June</month><year full="yes" TEIform="year">1991</year></dateStruct><biblScope type="pages" TEIform="biblScope">1-14</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Maydan91</note></biblStruct><biblStruct id="bid64" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">FastSysC: A Fast Simulation Engine</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Gilles</foreName><surname full="yes" TEIform="surname">Mouchard</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniel</foreName><surname full="yes" TEIform="surname">Gracia Pérez</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Design, Automation and Test in Europe (DATE), Paris, France</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2004</year></dateStruct><ref xlink:href="http://hal.inria.fr/inria-00001108" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="1242554980031">http://hal.inria.fr/inria-00001108</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:MGT04</note></biblStruct><biblStruct id="bid58" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">PowerPC G3 simulator</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.</foreName><surname full="yes" TEIform="surname">Mouchard</surname><initial>G.</initial></persName></author><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2002</year></dateStruct><ref xlink:href="http://www.microlib.org" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="777443085019">http://www.microlib.org</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">misc</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:ppc</note></biblStruct><biblStruct id="bid0" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Feedback Assisted Iterative Compiplation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.</foreName><surname full="yes" TEIform="surname">O'Boyle</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Knijnenburg</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.</foreName><surname full="yes" TEIform="surname">Fursin</surname><initial>G.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Parallel Architectures and Compilation Techniques (PACT'01)</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName type="organisation" TEIform="orgName">IEEE Computer Society Press</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">October</month><year full="yes" TEIform="year">2001</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:OKF01</note></biblStruct><biblStruct id="bid63" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">MicroLib: A Case for the Quantitative Comparison of Micro-Architecture Mechanisms</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Daniel Gracia</foreName><surname full="yes" TEIform="surname">Pérez</surname><initial>D. G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Gilles</foreName><surname full="yes" TEIform="surname">Mouchard</surname><initial>G.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">MICRO-37: Proceedings of the 37th International Symposium on Microarchitecture</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">IEEE Computer Society</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Dec</month><year full="yes" TEIform="year">2004</year></dateStruct><biblScope type="pages" TEIform="biblScope">43–54</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:GMT04</note></biblStruct><biblStruct id="bid16" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Towards a Systematic, Pragmatic and Architecture-Aware Program Optimization Process for Complex Processors</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">David</foreName><surname full="yes" TEIform="surname">Parello</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.-M.</foreName><surname full="yes" TEIform="surname">Verdun</surname><initial>J.-M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">ACM Supercomputing'04, Pittsburgh, Pennsylvania</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">November</month><year full="yes" TEIform="year">2004</year></dateStruct><biblScope type="pages" TEIform="biblScope">15</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:PTCV04</note></biblStruct><biblStruct id="bid15" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">On increasing architecture awareness in program optimizations to bridge the gap between peak and sustained processor performance: matrix-multiply revisited.</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">David</foreName><surname full="yes" TEIform="surname">Parello</surname><initial>D.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">J.-M.</foreName><surname full="yes" TEIform="surname">Verdun</surname><initial>J.-M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">SC</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2002</year></dateStruct><biblScope type="pages" TEIform="biblScope">1-11</biblScope><ref xlink:href="http://gala.univ-perp.fr/~dparello/publis/on_increasing_architecture_awareness.pdf" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3179649690016">http://gala.univ-perp.fr/~dparello/publis/on_increasing_architecture_awareness.pdf</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:PTV2002</note></biblStruct><biblStruct id="bid44" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">Machine Learning, Machine Vision, and the Brain</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Thomas</foreName><surname full="yes" TEIform="surname">Poggio</surname><initial>T.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Christian R.</foreName><surname full="yes" TEIform="surname">Shelton</surname><initial>C. R.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">The AI Magazine</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">20</biblScope><biblScope type="number" TEIform="biblScope">3</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1999</year></dateStruct><biblScope type="pages" TEIform="biblScope">37–55</biblScope><ref xlink:href="citeseer.ist.psu.edu/poggio99machine.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2821945244006">citeseer.ist.psu.edu/poggio99machine.html</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:poggio99machine</note></biblStruct><biblStruct id="bid69" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">The New Framework for Loop Nest Optimization in GCC: from Prototyping to Evaluation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sébastian</foreName><surname full="yes" TEIform="surname">Pop</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Albert</foreName><surname full="yes" TEIform="surname">Cohen</surname><initial>A.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">P.</foreName><surname full="yes" TEIform="surname">Jouvelot</surname><initial>P.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">G.-A.</foreName><surname full="yes" TEIform="surname">Silber</surname><initial>G.-A.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">Proc. of the 12th Workshop Compilers for Parallel Computers (CPC'06), A Coruña, Spain</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">January</month><year full="yes" TEIform="year">2006</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:PCJS06</note></biblStruct><biblStruct id="bid23" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">The Omega test: A fast and practical integer programming algorithm for dependence analysis</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">W.</foreName><surname full="yes" TEIform="surname">Pugh</surname><initial>W.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">Comm. of the ACM</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">8</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1992</year></dateStruct><biblScope type="pages" TEIform="biblScope">102-114</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:Pugh</note></biblStruct><biblStruct id="bid43" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Semiconductor Industry Association 2005 roadmap, section on Emerging Research Devices</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName"/><surname full="yes" TEIform="surname">SIA</surname><initial/></persName></author><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2005</year></dateStruct><ref xlink:href="http://www.sia-online.org/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="72354117014">http://www.sia-online.org/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">misc</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:sia2005</note></biblStruct><biblStruct id="bid55" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">SystemC v2.0.1 Language Reference Manual</title><imprint TEIform="imprint"><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2003</year></dateStruct><ref xlink:href="http://www.systemc.org/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="3292270039007">http://www.systemc.org/</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">misc</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:systemc</note></biblStruct><biblStruct id="bid38" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">Component Software: Beyond Object-Oriented Programming</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Clemens</foreName><surname full="yes" TEIform="surname">Szyperski</surname><initial>C.</initial></persName></author><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">Addison-Wesley Longman Publishing Co., Inc.<address TEIform="address"><addrLine TEIform="addrLine">Boston, MA, USA</addrLine></address></orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">2002</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">book</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:515228</note></biblStruct><biblStruct id="bid53" default="NO" TEIform="biblStruct"><monogr TEIform="monogr"><title level="m" TEIform="title">UNISIM: UNIted SIMulation environment</title><imprint TEIform="imprint"><ref xlink:href="http://unisim.org" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" xmlns:xlink="http://www.w3.org/1999/xlink" xyref="2290244741021">http://unisim.org</ref></imprint></monogr><note type="classification" place="unspecified" anchored="yes">misc</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:unisim</note></biblStruct><biblStruct id="bid25" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">A loop transformation theory and an algorithm to maximize parallelism</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.E.</foreName><surname full="yes" TEIform="surname">Wolf</surname><initial>M.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">M.S.</foreName><surname full="yes" TEIform="surname">Lam</surname><initial>M.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="j" TEIform="title">IEEE Transactions on Parallel and Distributed Systems</title><imprint TEIform="imprint"><biblScope type="volume" TEIform="biblScope">2</biblScope><biblScope type="number" TEIform="biblScope">4</biblScope><dateStruct full="yes" TEIform="dateStruct"><year full="yes" TEIform="year">1991</year></dateStruct><biblScope type="pages" TEIform="biblScope">430-439</biblScope></imprint></monogr><note type="classification" place="unspecified" anchored="yes">article</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:WL</note></biblStruct><biblStruct id="bid19" default="NO" TEIform="biblStruct"><analytic TEIform="analytic"><title level="a" TEIform="title">From Sequences of Dependent Instructions to Functions: a Complexity-Effective Approach for Improving Performance without ILP or Speculation</title><author TEIform="author"><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Sami</foreName><surname full="yes" TEIform="surname">Yehia</surname><initial>S.</initial></persName><persName TEIform="persName"><foreName full="yes" TEIform="foreName">Olivier</foreName><surname full="yes" TEIform="surname">Temam</surname><initial>O.</initial></persName></author></analytic><monogr TEIform="monogr"><title level="m" TEIform="title">International Workshop on Complexity-Effective Design</title><imprint TEIform="imprint"><publisher TEIform="publisher"><orgName TEIform="orgName">ISCA</orgName></publisher><dateStruct full="yes" TEIform="dateStruct"><month full="yes" TEIform="month">Jun</month><year full="yes" TEIform="year">2003</year></dateStruct></imprint></monogr><note type="classification" place="unspecified" anchored="yes">inproceedings</note><note type="from" place="unspecified" anchored="yes">foot</note><note type="userid" place="unspecified" anchored="yes">footcite:YT03</note></biblStruct></biblio></raweb>